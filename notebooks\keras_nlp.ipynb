{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "keras_nlp.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "[View in Colaboratory](https://colab.research.google.com/github/assaflehr/language-style-transfer/blob/master/notebooks/keras_nlp.ipynb)"
      ]
    },
    {
      "metadata": {
        "id": "vR_wGTR6szDb",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Keras accuracy/performace limitations\n",
        "\n",
        "### CuDNNLSTM vs LSTM \n",
        "The former trains very fast on GPU, but does not support the attributes: dropout,recurrent_dropout,which are the STOA regulaizers. This is cuda problem, and even native TF does not support it\n",
        "\n",
        "### Tip to self:\n",
        "* manually check loss value on one sample (predict vs gt). From doing this, I saw <s> was not given one-hot-value"
      ]
    },
    {
      "metadata": {
        "id": "OrKzdh71sBKm",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        ""
      ]
    },
    {
      "metadata": {
        "id": "UbJwZjyhsDvP",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# adaptation of: https://blog.keras.io/a-ten-minute-introduction-to-sequence-to-sequence-learning-in-keras.html\n",
        "# first Dataset class to load bible-data\n",
        "# then copy of the model, but working with words instead of chars"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "PcPSCDUrx3B8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 565
        },
        "outputId": "47935a74-8b27-49e2-9353-38c8bfdb7a2c"
      },
      "cell_type": "code",
      "source": [
        "## NLP preprocessing for text\n",
        "# has few parts:\n",
        "# 1. load zip files and then use glob to filter part of them (data/*/*.txt)\n",
        "# 2. parse each row into (x,y) by passing a parser method. it can be simple as lambda line:line:x, or if you use tab delimited lambda line: line.split(',')[4]\n",
        "# 3. tokenize - split by spaces, but also by ., and be smart about it.  ('...' should be one token , \"ai'nt\" one token. then; should be two 'token' and ';')\n",
        "#    you should also build vocabulary, keep X words and throw away rare ones, they will be replaced by <oov> flag.\n",
        "# 4. transform text to sequences for the result. for words there are usually two different types: ['s>','hello', 'world'] -> [0,5,6] but there is also \n",
        "#     a one-hot-econding version where 5 is actaully a vector of size voc-length full of zeros, with 5th index==1.\n",
        "#    The one-hot ecoding is used as output for text-generation and has a HUGE MEMORY requirement.  100K sentences of size 20 words need 2M floats = 8MB\n",
        "#    But for the one-hot-encoding multiply this by vocab-size. for char-encoding it's ~30 , for good vocab of 10K words, we need 80GB(!)\n",
        "#    The simple, and only , way to solve this , is to never keep one-hot-encoding in memory, just use a generator to make it one-hot in runtime\n",
        "\n",
        "\n",
        "\n",
        "from __future__ import print_function\n",
        "\n",
        "import numpy as np\n",
        "import os\n",
        "import glob\n",
        "import csv, json\n",
        "from collections import namedtuple\n",
        "from zipfile import ZipFile\n",
        "from os.path import expanduser, exists\n",
        "from keras.utils.data_utils import get_file\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.utils.data_utils import get_file\n",
        "from keras.utils import to_categorical\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "\n",
        "TVT = namedtuple('TVT',['train','val','test'])\n",
        "\n",
        "class Dataset:\n",
        "  #Dataset for COPY encoder-decoder\n",
        "  # to David: generator x,y where x is batch,max-words of type integer. (            <s>   hello word)\n",
        "  #                               y is batch,max-words,one-hot-encoding (offset one: hello world <end>)\n",
        "  # tokenizer is currently very bad. replace it\n",
        "  # vocabulary (training-only) , don't use 666 , use large number (10K?)\n",
        "  \n",
        "  # Dataset2 for style, x is sentence + STYLE(one-hot-encoding of integer) , y is one hot encoding \n",
        "  \n",
        "  # Dataset3 for classifier: x is sentence + STYLE(one-hot-encoding of integer),  output: STYLE(one-hot-encoding of integer)\n",
        "  \n",
        "  \n",
        "  \n",
        "  def __init__(self,unique_name,url,extract,cache_dir,pattern=None,validation=0.1,test=0.1):\n",
        "    '''\n",
        "    unique_name will be used for the dataset source(or zip) file. \n",
        "    pattern need to include path inside zip (including zip root)\n",
        "    extract - is it zipped/tarred or not\n",
        "    cache_dir - under which the files be downloaded <cache_dir>/datasets/<unique_name>\n",
        "    pattern - glob will be done to choose only those files ,for example data*.txt. This should incldude both train and test\n",
        "    validation - subset glob pattern to use. If it's a float like 0.1, use it as split of one file\n",
        "    test - see above\n",
        "    '''\n",
        "    if not extract and pattern:\n",
        "      raise ValueError('pattern must be empty if extract=False chooses a subset of the files (data/*.txt). but you downloaded only one file')\n",
        "\n",
        "    if not os.path.exists(cache_dir):\n",
        "       os.makedirs(cache_dir)\n",
        "\n",
        "    fpath=get_file(unique_name, url,extract=True, cache_dir=cache_dir)\n",
        "    print ('fpath',fpath)\n",
        "    files = [fpath] if not pattern else glob.glob(f'{cache_dir}/datasets/{pattern}')\n",
        "\n",
        "    lines = [line.rstrip() for f in files for line in open(f).readlines()] \n",
        "    print (files,'#lines',len(lines),'first 3 lines')\n",
        "    print (lines[0],'\\n',lines[1],'\\n',lines[2])\n",
        "    \n",
        "    if isinstance(validation,float) and isinstance(test,float):\n",
        "      test_count = int(len(lines)*(1-test))\n",
        "      val_count =  int(len(lines)*(1-test-validation))\n",
        "      self.tvt_lines = TVT(lines[:val_count],lines[val_count:test_count],lines[test_count:])\n",
        "    \n",
        "    print ('train:',len(self.tvt_lines.train),'val',len(self.tvt_lines.val),'test',len(self.tvt_lines.test))\n",
        "  \n",
        "  def parse(self,row_parser,skip_first=False):\n",
        "    self.parsed=[]\n",
        "    for i,lines in enumerate(self.tvt_lines):\n",
        "      self.parsed.append([row_parser(line) for line in lines[1 if skip_first else 0:]])\n",
        "    self.parsed= TVT(*self.parsed)\n",
        "    print ('\\nrow_parser train:',self.parsed.train[0],'test:',self.parsed.test[0])\n",
        "    \n",
        "  def fit(self):\n",
        "    \"\"\" the current implementation is quite bad, hello world! will be 2 tokens world! is the second. \n",
        "    \"\"\"\n",
        "    print ('limiting num_words in Tokenizer due to MEMORY BOUNDS')  #num_words =100*1000\n",
        "\n",
        "    \n",
        "    # I use here tokenizer only to count freq. of words, then manually choose most freq. and manually split\n",
        "    # this is bad. There are better ways to do it (probably library/code which do it in one line)\n",
        "    print ('\\nREPLACE ME . BAD TOKENIZER!!!')\n",
        "    self.tokenizer = Tokenizer(num_words=100000, filters='', lower=False, split=' ', char_level=False, oov_token='<oov>')\n",
        "    \n",
        "    print (type(self.parsed.train),self.parsed.train[0][0])\n",
        "    self.tokenizer.fit_on_texts([x for x,y in self.parsed.train])\n",
        "    \n",
        "    print ('\\n word_index',len(self.tokenizer.word_index),'<oov>',self.tokenizer.word_index['<oov>'])\n",
        "    print ('common',list(self.tokenizer.word_index.items())[:15])\n",
        "    print ('uncommon',list(self.tokenizer.word_index.items())[-15:])\n",
        "  \n",
        "    num_words= 2000\n",
        "    print ('keeping only ',num_words,'of',len(self.tokenizer.word_index))\n",
        "           \n",
        "           \n",
        "    word2index = dict(list(self.tokenizer.word_index.items())[:num_words-2])\n",
        "    word2index['<s>']=0  #keras tokenizer keeps 0 unused\n",
        "    word2index['<oov>']=num_words-1\n",
        "    #FOR NOW the start and end are both ZERO. maybe not good???\n",
        "    \n",
        "    num_encoder_tokens = num_decoder_tokens= num_words # len(self.tokenizer.word_index)\n",
        "    self.word2index = word2index\n",
        "    self.index2word = {index:word for (word,index) in self.word2index.items()}\n",
        "    self.MAX_SEQUENCE_LENGTH=8\n",
        "    \n",
        "    verbose=5\n",
        "    result = []\n",
        "    for rows in self.parsed:\n",
        "      input_texts = [x for x,y in rows]\n",
        "      encoder_input_data  = np.zeros( (len(input_texts), self.MAX_SEQUENCE_LENGTH),    dtype='float32')\n",
        "      decoder_input_data  = np.zeros( (len(input_texts), self.MAX_SEQUENCE_LENGTH),    dtype='float32') # shifted by 1\n",
        "      decoder_target_data = np.zeros((len(input_texts),  self.MAX_SEQUENCE_LENGTH, num_decoder_tokens),    dtype='float32')\n",
        "      \n",
        "      #input to decoder   <s> hello world\n",
        "      #target of decoder: hello world <s>\n",
        "      \n",
        "      for i, input_text in enumerate(input_texts):\n",
        "        input_text = input_text.split(' ') #BUG: we need to use tokenizer here!!!!\n",
        "        #pad with end token  hello world <end> <end> <end>\n",
        "        end_token='<s>'\n",
        "        input_text += [end_token for _ in range(self.MAX_SEQUENCE_LENGTH - len(input_text)+1)]\n",
        "        if verbose:\n",
        "          print ('input_text',input_text)\n",
        "          verbose-=1\n",
        "        # out : hello  world  <end>  (MAX_SEQUENCE_LENGTH=2)  <-encoder_input+ decoder_output(but one-hot)\n",
        "        #\n",
        "        # in: : <s>   hello   world  <- decoder-input\n",
        "          \n",
        "        for t, word in enumerate((['<s>']+input_text)[:self.MAX_SEQUENCE_LENGTH]):\n",
        "            one_hot = word2index['<oov>'] if word not in word2index else word2index[word]\n",
        "            decoder_input_data[i, t ] = one_hot\n",
        "            \n",
        "        for t,word in enumerate(input_text[:self.MAX_SEQUENCE_LENGTH]):  #last must be <end>=<s> token\n",
        "            one_hot = word2index['<oov>'] if word not in word2index else word2index[word]\n",
        "            encoder_input_data[i,t]=one_hot\n",
        "            decoder_target_data[i, t, one_hot] = 1. \n",
        "      print (decoder_target_data.sum(),len(input_texts)*self.MAX_SEQUENCE_LENGTH)\n",
        "      assert int(decoder_target_data.sum())==len(input_texts)*self.MAX_SEQUENCE_LENGTH #one-hot-encoding must always include one\n",
        "      \n",
        "      result.append( (encoder_input_data,decoder_input_data,decoder_target_data))\n",
        "\n",
        "    self.result= TVT(*result)\n",
        "\n",
        "  def one_x_as_text(self,x):\n",
        "    \"\"\" 1x20 or 20 input\"\"\"\n",
        "    if len(x.shape)==2: \n",
        "      assert x.shape[0] ==1  #can only work on batch of 1\n",
        "      x= x[0]\n",
        "    return [self.index2word[index] for index in x]\n",
        "\n",
        "  def one_y_as_text(self,y):\n",
        "    \"\"\" 1x20x2000 or 20x2000 input, in case of first will work on y[0]\"\"\"\n",
        "    if len(y.shape)==3: \n",
        "      assert y.shape[0] ==1  #can only work on batch of 1\n",
        "      y=y[0]\n",
        "      \n",
        "    best_token = np.argmax(y,1)\n",
        "    return [self.index2word[index] for index in best_token]\n",
        "\n",
        "  \n",
        "cache_dir='cache' \n",
        "#dataset('quora_dups','http://qim.ec.quoracdn.net/quora_duplicate_questions.tsv',False,cache_dir) \n",
        "#dataset('bible4','https://codeload.github.com/keithecarlson/Zero-Shot-Style-Transfer/zip/master',extract=True,cache_dir=cache_dir\n",
        "#       pattern=('Zero-Shot-Style-Transfer-master/Data/Bibles/ASV/*/*.txt','Zero-Shot-Style-Transfer-master/Data/Bibles/BBE/*/*.txt')\n",
        "\n",
        "dataset = Dataset('bible_csv','https://codeload.github.com/ashual/style-transfer/zip/master',extract=True,cache_dir=cache_dir,pattern='style-transfer-master/datasets/bible-corpus/t_a*.csv')        \n",
        "row_parser= lambda line: (line.split(',')[4],line.split(',')[4]) #map x to x\n",
        "dataset.parse(row_parser,skip_first=True)\n",
        "dataset.fit()        \n",
        "x_train, x_train_d, y_train = dataset.result.train\n",
        "x_val, x_val_d,y_val = dataset.result.val\n",
        "x_test,x_test_d,y_test = dataset.result.test\n",
        "\n",
        "print ('train',x_train.shape,x_train_d.shape,y_train.shape)\n",
        "print('val',x_val.shape,y_val.shape)\n",
        "print ('train in MB x,y',x_train.nbytes/1e6,y_train.nbytes/1e6)\n",
        "\n",
        "\n",
        " \n",
        "\n",
        "  "
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://codeload.github.com/ashual/style-transfer/zip/master\n",
            "6414336/Unknown - 2s 0us/step"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "21372928/Unknown - 6s 0us/stepfpath cache/datasets/bible_csv\n",
            "['cache/datasets/style-transfer-master/datasets/bible-corpus/t_asv.csv'] #lines 31104 first 3 lines\n",
            "id,b,c,v,t \n",
            " 1001001,1,1,1,In the beginning God created the heavens and the earth. \n",
            " 1001002,1,1,2,And the earth was waste and void; and darkness was upon the face of the deep: and the Spirit of God moved upon the face of the waters.\n",
            "train: 24883 val 3110 test 3111\n",
            "\n",
            "row_parser train: ('In the beginning God created the heavens and the earth.', 'In the beginning God created the heavens and the earth.') test: ('\"Much every way: first of all', '\"Much every way: first of all')\n",
            "limiting num_words in Tokenizer due to MEMORY BOUNDS\n",
            "\n",
            "REPLACE ME . BAD TOKENIZER!!!\n",
            "<class 'list'> In the beginning God created the heavens and the earth.\n",
            "\n",
            " word_index 13075 <oov> 13075\n",
            "common [('the', 1), ('of', 2), ('\"And', 3), ('and', 4), ('to', 5), ('unto', 6), ('in', 7), ('shall', 8), ('that', 9), ('he', 10), ('a', 11), ('his', 12), ('Jehovah', 13), ('they', 14), ('I', 15)]\n",
            "uncommon [('marvelled.', 13061), (\"do'\", 13062), ('purple', 13063), ('myrrh:', 13064), ('superscription', 13065), ('robbers;', 13066), ('scripture', 13067), ('bottom.', 13068), ('afar:', 13069), ('Arimathaea', 13070), ('already', 13071), ('dead:', 13072), (\"`mother'\", 13073), ('Joses', 13074), ('<oov>', 13075)]\n",
            "keeping only  2000 of 13075\n",
            "input_text ['In', 'the', 'beginning', 'God', 'created', 'the', 'heavens', 'and', 'the', 'earth.']\n",
            "input_text ['And', 'the', 'earth', 'was', 'waste', 'and', 'void;', 'and', 'darkness', 'was', 'upon', 'the', 'face', 'of', 'the', 'deep:', 'and', 'the', 'Spirit', 'of', 'God', 'moved', 'upon', 'the', 'face', 'of', 'the', 'waters.']\n",
            "input_text ['\"And', 'God', 'said', '<s>', '<s>', '<s>', '<s>', '<s>', '<s>']\n",
            "input_text ['\"And', 'God', 'saw', 'the', 'light', '<s>', '<s>', '<s>', '<s>']\n",
            "input_text ['\"And', 'God', 'called', 'the', 'light', 'Day', '<s>', '<s>', '<s>']\n",
            "199056.0 199056\n",
            "24872.0 24872\n",
            "24880.0 24880\n",
            "train (24882, 8) (24882, 8) (24882, 8, 2000)\n",
            "val (3109, 8) (3109, 8, 2000)\n",
            "train in MB x,y 0.796224 1592.448\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "S_v9vKqIcTn6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        },
        "outputId": "f3d493f9-a33a-4935-d329-0b6112a1215e"
      },
      "cell_type": "code",
      "source": [
        "#show a sample of x_train\n",
        "for i in range(1150,1152):\n",
        "  print ('\\ntokens  :' , x_train[i])\n",
        "  print ('as words:',[dataset.index2word[index] for index in x_train[i] ])\n",
        "  print ('original:',dataset.parsed.train[i][0].split(' '))\n",
        "  print (dataset.one_x_as_text(x_train[i]))\n",
        "  print (dataset.one_y_as_text(y_train[i]))"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "tokens  : [  3. 218.  20. 114. 109.   5. 826.   4.]\n",
            "as words: ['\"And', 'Joseph', 'was', 'brought', 'down', 'to', 'Egypt;', 'and']\n",
            "original: ['\"And', 'Joseph', 'was', 'brought', 'down', 'to', 'Egypt;', 'and', 'Potiphar']\n",
            "['\"And', 'Joseph', 'was', 'brought', 'down', 'to', 'Egypt;', 'and']\n",
            "['\"And', 'Joseph', 'was', 'brought', 'down', 'to', 'Egypt;', 'and']\n",
            "\n",
            "tokens  : [  3.  13.  20.  21. 218.   0.   0.   0.]\n",
            "as words: ['\"And', 'Jehovah', 'was', 'with', 'Joseph', '<s>', '<s>', '<s>']\n",
            "original: ['\"And', 'Jehovah', 'was', 'with', 'Joseph']\n",
            "['\"And', 'Jehovah', 'was', 'with', 'Joseph', '<s>', '<s>', '<s>']\n",
            "['\"And', 'Jehovah', 'was', 'with', 'Joseph', '<s>', '<s>', '<s>']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "BWVEcaeF6DBR",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Model defintion\n"
      ]
    },
    {
      "metadata": {
        "id": "kqkLdFGl0FMB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 545
        },
        "outputId": "f0ce5bab-6509-4cf4-c74a-8b776c07d22c"
      },
      "cell_type": "code",
      "source": [
        "from keras.models import Model\n",
        "from keras.layers import Input, LSTM, Dense, Embedding,CuDNNLSTM,Bidirectional,Concatenate\n",
        "\n",
        "# size of tokenizer indexes\n",
        "\n",
        "num_decoder_tokens = num_encoder_tokens = len(dataset.word2index) \n",
        "\n",
        "embedding_dim=300\n",
        "latent_dim = 256\n",
        "batch_size=64\n",
        "epochs=30\n",
        "\n",
        "bidi_encoder=True\n",
        "cuddlstm=False  #on bidi , diff in time is 20s vs 32 se\n",
        "\n",
        "# Define an input sequence and process it.\n",
        "encoder_inputs = Input(shape=(None,))\n",
        "\n",
        "shared_embedding = Embedding(num_encoder_tokens, \n",
        "                     embedding_dim, \n",
        "                     #weights=[word_embedding_matrix], if there is one\n",
        "                     #trainable=False,                            \n",
        "                     #input_length=MAX_SEQUENCE_LENGTH, if there is one\n",
        "                     )\n",
        "x = shared_embedding(encoder_inputs) \n",
        "if (cuddlstm):\n",
        "  encoder_lstm=CuDNNLSTM(latent_dim, return_state=True)\n",
        "else:\n",
        "  #need to tune the dropout values (maybe fast.ai tips) , just invented those value\n",
        "  encoder_lstm=LSTM(latent_dim, return_state=True,dropout=0.1,recurrent_dropout=0.1)\n",
        "if (bidi_encoder):\n",
        "  encoder_lstm=Bidirectional(encoder_lstm,merge_mode='concat')\n",
        "  x, forward_h, forward_c, backward_h, backward_c = encoder_lstm(x) #output,h1,c1,h2,c2\n",
        "  state_h = Concatenate()([forward_h, backward_h])\n",
        "  state_c = Concatenate()([forward_c, backward_c])\n",
        "else:  \n",
        "  \n",
        "  x, state_h, state_c = encoder_lstm(x)\n",
        "\n",
        "encoder_states = [state_h, state_c]\n",
        "\n",
        "# Set up the decoder, using `encoder_states` as initial state.\n",
        "decoder_inputs = Input(shape=(None,))\n",
        "\n",
        "decoder_latent_dim = latent_dim*2 if bidi_encoder else latent_dim #bi-di pass merge of h1+h2, c1+c2\n",
        "if (cuddlstm):\n",
        "  decoder_lstm = CuDNNLSTM(decoder_latent_dim, return_sequences=True,return_state=True) #returned state used in inference\n",
        "else:\n",
        "  decoder_lstm = LSTM(decoder_latent_dim, return_sequences=True,return_state=True)\n",
        "decoder_outputs, _, _  = decoder_lstm(shared_embedding(decoder_inputs), initial_state=encoder_states)\n",
        "decoder_dense  = Dense(num_decoder_tokens, activation='softmax')\n",
        "decoder_outputs = decoder_dense(decoder_outputs)\n",
        "\n",
        "\n",
        "# Define the model that will turn\n",
        "# `encoder_input_data` & `decoder_input_data` into `decoder_target_data`\n",
        "model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
        "\n",
        "# Compile & run training\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy')  #30peocs loss: 0.2836 - val_loss: 0.4428\n",
        "print (model.summary())\n",
        "\n",
        "# now for the INFER models (re-arrangement of the prev one)\n",
        "# Remember that the training model varaibles were:\n",
        "#                                        decoder_outputs\n",
        "#encoder   --->    encoder_states  -->   decoder_lstm  \n",
        "#shared_embedding                        shared_embeddings  \n",
        "#encoder_inputs                          decdoer_inputs                  \n",
        "encoder_model = Model(encoder_inputs, encoder_states)\n",
        "\n",
        "decoder_states_inputs = [Input(shape=(decoder_latent_dim,)), Input(shape=(decoder_latent_dim,))]\n",
        "\n",
        "decoder_outputs, state_h, state_c = decoder_lstm(shared_embedding(decoder_inputs), initial_state=decoder_states_inputs)\n",
        "\n",
        "decoder_states = [state_h, state_c]\n",
        "decoder_outputs = decoder_dense(decoder_outputs)\n",
        "\n",
        "decoder_model = Model(\n",
        "    [decoder_inputs] + decoder_states_inputs,\n",
        "    [decoder_outputs] + decoder_states)\n",
        "\n"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_2 (InputLayer)            (None, None)         0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_1 (InputLayer)            (None, None)         0                                            \n",
            "__________________________________________________________________________________________________\n",
            "embedding_1 (Embedding)         (None, None, 300)    600000      input_1[0][0]                    \n",
            "                                                                 input_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "bidirectional_1 (Bidirectional) [(None, 512), (None, 1140736     embedding_1[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_1 (Concatenate)     (None, 512)          0           bidirectional_1[0][1]            \n",
            "                                                                 bidirectional_1[0][3]            \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_2 (Concatenate)     (None, 512)          0           bidirectional_1[0][2]            \n",
            "                                                                 bidirectional_1[0][4]            \n",
            "__________________________________________________________________________________________________\n",
            "lstm_2 (LSTM)                   [(None, None, 512),  1665024     embedding_1[1][0]                \n",
            "                                                                 concatenate_1[0][0]              \n",
            "                                                                 concatenate_2[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dense_1 (Dense)                 (None, None, 2000)   1026000     lstm_2[0][0]                     \n",
            "==================================================================================================\n",
            "Total params: 4,431,760\n",
            "Trainable params: 4,431,760\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "C2cufjsW_9Zw",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        ""
      ]
    },
    {
      "metadata": {
        "id": "_ZC94QpK1bcw",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "max_decoder_seq_length=dataset.MAX_SEQUENCE_LENGTH\n",
        "\n",
        "\n",
        "def decode_sequence(input_seq,verbose=False):\n",
        "    assert input_seq.shape == (1, max_decoder_seq_length )\n",
        "    if verbose: print ('input_seq',input_seq.shape)\n",
        "    # Encode the input as state vectors.\n",
        "    states_value = encoder_model.predict(input_seq)\n",
        "    if verbose: print ('encoder result states_value','h',states_value[0].shape,states_value[0].mean(),'c',states_value[1].shape,states_value[1].mean())\n",
        "    \n",
        "    # Generate empty target sequence of length 1.\n",
        "    #                      batch,word-number value is token (0 /122)\n",
        "    target_seq = np.zeros((1, 1))\n",
        "    # Populate the first character of target sequence with the start character.\n",
        "    target_seq[0, 0] = dataset.word2index['<s>']\n",
        "\n",
        "    # Sampling loop for a batch of sequences\n",
        "    # (to simplify, here we assume a batch of size 1).\n",
        "    stop_condition = False\n",
        "    decoded_sentence = []\n",
        "    while not stop_condition:\n",
        "        #start with encoder-state then change to self state\n",
        "        output_tokens, h, c = decoder_model.predict( [target_seq] + states_value) \n",
        "        if verbose: print ('output_tokens',output_tokens.shape,output_tokens.mean(),'h',h.shape,'c',c.shape)\n",
        "\n",
        "        # Sample a token\n",
        "        sampled_token_index = np.argmax(output_tokens)# [0, -1, :])\n",
        "        if verbose: print ('sampled_token_index',sampled_token_index.shape,output_tokens.max(),sampled_token_index)\n",
        "        decoded_sentence.append(sampled_token_index)\n",
        "\n",
        "        # Exit condition: either hit max length\n",
        "        # or find stop character.\n",
        "        if (sampled_token_index == dataset.word2index['<s>'] or\n",
        "           len(decoded_sentence) > max_decoder_seq_length):\n",
        "          stop_condition = True\n",
        "\n",
        "        # Update the target sequence (of length 1).\n",
        "        target_seq = np.zeros((1, 1))\n",
        "        target_seq[0, 0] = sampled_token_index\n",
        "\n",
        "        # Update states\n",
        "        states_value = [h, c]\n",
        "\n",
        "    res= np.array(decoded_sentence) #[dataset.index2word[index] for index in decoded_sentence]\n",
        "    return res\n",
        "\n",
        "\n",
        "def show_sample(data_type='val',teacher_forcing=False,range_start=2000,range_count=1):\n",
        "  \"\"\" \n",
        "    teacher_forcing : should we simulate training and feed the input. default False, as for test\n",
        "  \"\"\"\n",
        "  for i in range(range_start,range_start+range_count):\n",
        "      data={'train': dataset.result.train,'val':dataset.result.val , 'test':dataset.result.test}\n",
        "      one_x= data[data_type][0][i:i+1]\n",
        "      one_y= data[data_type][2][i:i+1]\n",
        "      if one_x.shape[0]==0:\n",
        "        print ('one_x',one_x.shape,'your range_start',range_start,' is more than size of data ',data[data_type][0].shape)\n",
        "      print ('\\ngold  x: ',dataset.one_x_as_text(one_x))\n",
        "      #print ('gold y: ',dataset.one_y_as_text(one_y))\n",
        "      if teacher_forcing:\n",
        "        p = model.predict([one_x,one_x])\n",
        "        print ('actual y:',dataset.one_y_as_text(p))   \n",
        "      else:\n",
        "        p = decode_sequence(one_x,verbose=False)\n",
        "        print ('actual y:',dataset.one_x_as_text(p))   \n",
        "\n",
        "     \n",
        "\n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "9s0-8EJi6AG1",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# TRAINING"
      ]
    },
    {
      "metadata": {
        "id": "0_0G8_Dr2bMM",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import keras\n",
        "from keras.callbacks import ReduceLROnPlateau\n",
        "class LossHistory(keras.callbacks.Callback):\n",
        "    def __init__(self):\n",
        "      self.losses = {'loss':[],'val_loss':[]}\n",
        "      \n",
        "    #def on_train_begin(self, logs={}):\n",
        "    #  pass  \n",
        "    \n",
        "    def on_epoch_end(self, batch, logs={}):\n",
        "      for loss in ['loss','val_loss']:\n",
        "        self.losses[loss].append(logs.get(loss))\n",
        "        \n",
        "        \n",
        "loss_history = LossHistory()\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Sm05AY862pem",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 328
        },
        "outputId": "cf349b2b-2f65-439a-889b-8b0d7d2b900f"
      },
      "cell_type": "code",
      "source": [
        "from keras import backend as K\n",
        "epochs = 10 \n",
        "for i in range(5):\n",
        "  print ('lr',K.eval(model.optimizer.lr))\n",
        "  #test model with teadcher-forcing\n",
        "  model.fit([x_train, x_train_d], y_train,\n",
        "            batch_size=batch_size,\n",
        "            epochs=epochs,\n",
        "            validation_data=([x_val, x_val_d], y_val),callbacks=[loss_history,\n",
        "                                                                ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=2, verbose=1, mode='auto', min_delta=0.0001, cooldown=3)])\n",
        "  show_sample('val',range_count=3)      \n",
        "  #show_sample('val',False) "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "lr 0.001\n",
            "Train on 24882 samples, validate on 3109 samples\n",
            "Epoch 1/10\n",
            "24882/24882 [==============================] - 36s 1ms/step - loss: 3.6192 - val_loss: 2.5646\n",
            "Epoch 2/10\n",
            "12032/24882 [=============>................] - ETA: 16s - loss: 2.2126"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "24882/24882 [==============================] - 34s 1ms/step - loss: 1.9372 - val_loss: 1.4798\n",
            "Epoch 3/10\n",
            "24882/24882 [==============================] - 34s 1ms/step - loss: 1.0925 - val_loss: 0.9194\n",
            "Epoch 4/10\n",
            " 4096/24882 [===>..........................] - ETA: 27s - loss: 0.7248"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "24882/24882 [==============================] - 34s 1ms/step - loss: 0.6289 - val_loss: 0.6135\n",
            "Epoch 5/10\n",
            "24882/24882 [==============================] - 34s 1ms/step - loss: 0.3477 - val_loss: 0.4367\n",
            "Epoch 6/10\n",
            " 2112/24882 [=>............................] - ETA: 30s - loss: 0.2038"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "24882/24882 [==============================] - 34s 1ms/step - loss: 0.1839 - val_loss: 0.3245\n",
            "Epoch 7/10\n",
            "23040/24882 [==========================>...] - ETA: 2s - loss: 0.0982"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "R_OBmX182djj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 376
        },
        "outputId": "c2f6cb93-f34c-4358-eb97-65f1ab317ba8"
      },
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# summarize history for loss\n",
        "plt.plot(loss_history.losses['loss'][3:])\n",
        "plt.plot(loss_history.losses['val_loss'][3:])\n",
        "plt.title('model loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'val'], loc='upper left')\n",
        "plt.show()"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAe8AAAFnCAYAAACPasF4AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAAAASUVORK5CYII=\n",
            "text/plain": [
              "<matplotlib.figure.Figure at 0x7fd7c7f1e828>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "I2NGxSQb2dxD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 290
        },
        "outputId": "658aad70-9acb-4e30-e16d-d3bb3b9d6625"
      },
      "cell_type": "code",
      "source": [
        "#print ('eval on train:',model.evaluate([x_train, x_train_d], y_train))\n",
        "#print ('eval on val:',model.evaluate([x_val, x_val_d], y_val))\n",
        "\n",
        "s=20\n",
        "e=s+1\n",
        "print ('score',model.evaluate([x_train[s:e], x_train_d[s:e]], y_train[s:e],batch_size=batch_size,verbose=0))\n",
        "\n",
        "show_sample('train',False,s) \n",
        "\n",
        "\n",
        "print ('\\n COMPARE TO VAL:\\n')\n",
        "print('score',model.evaluate([x_val[s:e], x_val_d[s:e]], y_val[s:e],batch_size=batch_size,verbose=0))\n",
        "show_sample('val',False,s) \n"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "24882/24882 [==============================] - 6s 254us/step\n",
            "eval on train: 0.0014381707628753815\n",
            "3109/3109 [==============================] - 1s 262us/step\n",
            "eval on val: 0.14587134541748958\n",
            "score 0.00023495724599342793\n",
            "\n",
            "gold  x:  ['\"And', 'God', 'created', 'the', 'great', '<oov>', '<s>', '<s>']\n",
            "actual y: ['\"And', 'God', 'created', 'the', 'great', '<oov>', '<s>']\n",
            "\n",
            " COMPARE TO VAL:\n",
            "\n",
            "score 0.0432426780462265\n",
            "\n",
            "gold  x:  ['And', 'the', 'whole', 'multitude', 'of', 'the', 'people', 'were']\n",
            "actual y: ['And', 'the', 'whole', 'multitude', 'of', 'the', 'people', 'were', '<s>']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "XvIkFOWy55ov",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Error analysis"
      ]
    },
    {
      "metadata": {
        "id": "TkFXxinr0fNo",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 244
        },
        "outputId": "ca2b21c9-21a8-43e6-ea99-da33e1b5c0d3"
      },
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "#a= model.predict([x_train[s:e], x_train_d[s:e]])\n",
        "#for i in range(dataset.MAX_SEQUENCE_LENGTH):\n",
        "#  best=np.argmax(a[0,i])\n",
        "#  print (i,best,dataset.index2word[best],a[0,i,best],a[0,i,0])\n",
        "\n",
        "from keras.losses import categorical_crossentropy\n",
        "p=model.predict([x_val,x_val_d])\n",
        "scores=K.eval(K.sum(categorical_crossentropy(K.constant(p), K.constant(y_val) ),axis=1))\n",
        "worse_10 = scores.argsort()[::-1][:10]\n",
        "\n",
        "for i in range(len(worse_10)):\n",
        "  bad=worse_10[i]\n",
        "  print (i,'arg',bad,'score',scores[bad],show_sample('val',False,bad))\n",
        "  \n"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-1e4d70dec522>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlosses\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcategorical_crossentropy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx_val\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mx_val_d\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mscores\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcategorical_crossentropy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconstant\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconstant\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_val\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mworse_10\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscores\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margsort\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "ffg4n5Ol53DJ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# New Section"
      ]
    },
    {
      "metadata": {
        "id": "beDWv50D8MYj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "02de9f03-653f-4e4b-e252-c78ebe740f5b"
      },
      "cell_type": "code",
      "source": [
        "scores"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(3109,)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 53
        }
      ]
    }
  ]
}
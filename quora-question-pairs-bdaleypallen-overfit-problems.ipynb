{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "quora-question-pairs-data-prep.ipynb",
      "version": "0.3.2",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "-5wzZxtNpvYr",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Quora question pairs: data preparation"
      ]
    },
    {
      "metadata": {
        "id": "NYYm9ELXpvYs",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Import packages"
      ]
    },
    {
      "metadata": {
        "id": "1VPo7wSHpvYt",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "77e4f941-2816-47fa-f55e-0407f53d4784"
      },
      "cell_type": "code",
      "source": [
        "from __future__ import print_function\n",
        "\n",
        "import numpy as np\n",
        "import csv, json\n",
        "from zipfile import ZipFile\n",
        "from os.path import expanduser, exists\n",
        "\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.utils.data_utils import get_file"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "-gP3t_dZpvYy",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Initialize global variables"
      ]
    },
    {
      "metadata": {
        "id": "Ex9Du58spvYz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "ee7901c0-8d58-4e40-f10d-cee06a401d82"
      },
      "cell_type": "code",
      "source": [
        "KERAS_DATASETS_DIR = expanduser('~/.keras/datasets/')\n",
        "QUESTION_PAIRS_FILE_URL = 'http://qim.ec.quoracdn.net/quora_duplicate_questions.tsv'\n",
        "QUESTION_PAIRS_FILE = 'quora_duplicate_questions.tsv'\n",
        "GLOVE_ZIP_FILE_URL = 'http://nlp.stanford.edu/data/glove.840B.300d.zip'\n",
        "GLOVE_ZIP_FILE = 'glove.840B.300d.zip'\n",
        "GLOVE_FILE = 'glove.840B.300d.txt'\n",
        "Q1_TRAINING_DATA_FILE = 'q1_train.npy'\n",
        "Q2_TRAINING_DATA_FILE = 'q2_train.npy'\n",
        "LABEL_TRAINING_DATA_FILE = 'label_train.npy'\n",
        "WORD_EMBEDDING_MATRIX_FILE = 'word_embedding_matrix.npy'\n",
        "NB_WORDS_DATA_FILE = 'nb_words.json'\n",
        "MAX_NB_WORDS = 200000\n",
        "MAX_SEQUENCE_LENGTH = 25\n",
        "EMBEDDING_DIM = 300"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "metadata": {
        "id": "PNvqCclEpvY3",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Download and extract questions pairs data"
      ]
    },
    {
      "metadata": {
        "id": "cv_kfmuCpvY4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        },
        "outputId": "23bfe88b-cc44-4438-8477-2d70c777fd64"
      },
      "cell_type": "code",
      "source": [
        "if not exists(KERAS_DATASETS_DIR + QUESTION_PAIRS_FILE):\n",
        "    get_file(QUESTION_PAIRS_FILE, QUESTION_PAIRS_FILE_URL)\n",
        "\n",
        "print(\"Processing\", QUESTION_PAIRS_FILE)\n",
        "\n",
        "question1 = []\n",
        "question2 = []\n",
        "is_duplicate = []\n",
        "with open(KERAS_DATASETS_DIR + QUESTION_PAIRS_FILE, encoding='utf-8') as csvfile:\n",
        "    reader = csv.DictReader(csvfile, delimiter='\\t')\n",
        "    for row in reader:\n",
        "        question1.append(row['question1'])\n",
        "        question2.append(row['question2'])\n",
        "        is_duplicate.append(row['is_duplicate'])\n",
        "\n",
        "print('Question pairs: %d' % len(question1))"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from http://qim.ec.quoracdn.net/quora_duplicate_questions.tsv\n",
            "58179584/58176133 [==============================] - 0s 0us/step\n",
            "Processing quora_duplicate_questions.tsv\n",
            "Question pairs: 404290\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "25rcv1dSpvY8",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Build tokenized word index"
      ]
    },
    {
      "metadata": {
        "id": "7Y2M2_1fpvY9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "def493e9-deda-4a63-cb9e-666c97d6fa13"
      },
      "cell_type": "code",
      "source": [
        "questions = question1 + question2\n",
        "tokenizer = Tokenizer(num_words=MAX_NB_WORDS)\n",
        "tokenizer.fit_on_texts(questions)\n",
        "question1_word_sequences = tokenizer.texts_to_sequences(question1)\n",
        "question2_word_sequences = tokenizer.texts_to_sequences(question2)\n",
        "word_index = tokenizer.word_index\n",
        "\n",
        "print(\"Words in index: %d\" % len(word_index))"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Words in index: 95596\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "G3Pe0BqlpvZA",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Download and process GloVe embeddings"
      ]
    },
    {
      "metadata": {
        "id": "UcJkzvpGpvZB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 110
        },
        "outputId": "0a59fa6c-5100-4ec2-d44a-93d87e7ce8f9"
      },
      "cell_type": "code",
      "source": [
        "if not exists(KERAS_DATASETS_DIR + GLOVE_ZIP_FILE):\n",
        "    zipfile = ZipFile(get_file(GLOVE_ZIP_FILE, GLOVE_ZIP_FILE_URL))\n",
        "    zipfile.extract(GLOVE_FILE, path=KERAS_DATASETS_DIR)\n",
        "    \n",
        "print(\"Processing\", GLOVE_FILE)\n",
        "\n",
        "embeddings_index = {}\n",
        "with open(KERAS_DATASETS_DIR + GLOVE_FILE, encoding='utf-8') as f:\n",
        "    for line in f:\n",
        "        values = line.split(' ')\n",
        "        word = values[0]\n",
        "        embedding = np.asarray(values[1:], dtype='float32')\n",
        "        embeddings_index[word] = embedding\n",
        "\n",
        "print('Word embeddings: %d' % len(embeddings_index))"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from http://nlp.stanford.edu/data/glove.840B.300d.zip\n",
            "1059217408/2176768927 [=============>................] - ETA: 59s"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2176770048/2176768927 [==============================] - 115s 0us/step\n",
            "Processing glove.840B.300d.txt\n",
            "Word embeddings: 2196016\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "xsdZkTd_pvZI",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Prepare word embedding matrix"
      ]
    },
    {
      "metadata": {
        "id": "AgsYUai0pvZJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "9fbed4f6-e94b-4fd0-c135-7a7e61935886"
      },
      "cell_type": "code",
      "source": [
        "nb_words = min(MAX_NB_WORDS, len(word_index))\n",
        "word_embedding_matrix = np.zeros((nb_words + 1, EMBEDDING_DIM))\n",
        "for word, i in word_index.items():\n",
        "    if i > MAX_NB_WORDS:\n",
        "        continue\n",
        "    embedding_vector = embeddings_index.get(word)\n",
        "    if embedding_vector is not None:\n",
        "        word_embedding_matrix[i] = embedding_vector\n",
        "\n",
        "print('Null word embeddings: %d' % np.sum(np.sum(word_embedding_matrix, axis=1) == 0))"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Null word embeddings: 29276\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "0eSMu4x2pvZO",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Prepare training data tensors"
      ]
    },
    {
      "metadata": {
        "id": "VZRLTCoGpvZP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "outputId": "d62cbb8f-ae4f-43da-8836-ed48f5ef4acc"
      },
      "cell_type": "code",
      "source": [
        "q1_data = pad_sequences(question1_word_sequences, maxlen=MAX_SEQUENCE_LENGTH)\n",
        "q2_data = pad_sequences(question2_word_sequences, maxlen=MAX_SEQUENCE_LENGTH)\n",
        "labels = np.array(is_duplicate, dtype=int)\n",
        "print('Shape of question1 data tensor:', q1_data.shape)\n",
        "print('Shape of question2 data tensor:', q2_data.shape)\n",
        "print('Shape of label tensor:', labels.shape)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Shape of question1 data tensor: (404290, 25)\n",
            "Shape of question2 data tensor: (404290, 25)\n",
            "Shape of label tensor: (404290,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "lBs_tgivpvZU",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Persist training and configuration data to files"
      ]
    },
    {
      "metadata": {
        "id": "P7IRDRq2pvZW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "6a2a49d4-f742-4598-ddaa-2910921724cf"
      },
      "cell_type": "code",
      "source": [
        "np.save(open(Q1_TRAINING_DATA_FILE, 'wb'), q1_data)\n",
        "np.save(open(Q2_TRAINING_DATA_FILE, 'wb'), q2_data)\n",
        "np.save(open(LABEL_TRAINING_DATA_FILE, 'wb'), labels)\n",
        "np.save(open(WORD_EMBEDDING_MATRIX_FILE, 'wb'), word_embedding_matrix)\n",
        "with open(NB_WORDS_DATA_FILE, 'w') as f:\n",
        "    json.dump({'nb_words': nb_words}, f)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "metadata": {
        "id": "L5dRefMYsASI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 145
        },
        "outputId": "8cfc8420-c361-44c6-a889-343fa56880c1"
      },
      "cell_type": "code",
      "source": [
        "!ls -lh"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "total 300M\r\n",
            "drwxr-xr-x 3 root root 4.0K Jul  2 16:56 datalab\r\n",
            "-rw-r--r-- 1 root root 3.1M Jul  4 09:44 label_train.npy\r\n",
            "-rw-r--r-- 1 root root   19 Jul  4 09:44 nb_words.json\r\n",
            "-rw-r--r-- 1 root root  39M Jul  4 09:44 q1_train.npy\r\n",
            "-rw-r--r-- 1 root root  39M Jul  4 09:44 q2_train.npy\r\n",
            "-rw-r--r-- 1 root root 219M Jul  4 09:44 word_embedding_matrix.npy\r\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "gezIPbGssNLu",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "1Emf3a2rsNOk",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "7bz2GGppsNR0",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "4KfPjhrRp1WK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "96fb0042-5d94-45a9-fb56-18347f73cb1a"
      },
      "cell_type": "code",
      "source": [
        "%matplotlib inline\n",
        "from __future__ import print_function\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import datetime, time, json\n",
        "from keras.models import Model\n",
        "from keras.layers import Input, TimeDistributed, Dense, Lambda, concatenate, Dropout, BatchNormalization\n",
        "from keras.layers.embeddings import Embedding\n",
        "from keras.regularizers import l2\n",
        "from keras.callbacks import Callback, ModelCheckpoint\n",
        "from keras import backend as K\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "metadata": {
        "id": "UA6no2Rxp1WP",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Initialize global variables"
      ]
    },
    {
      "metadata": {
        "id": "ozz2ixJ4p1WQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "d5b50c35-a85d-4221-8a02-273835449543"
      },
      "cell_type": "code",
      "source": [
        "Q1_TRAINING_DATA_FILE = 'q1_train.npy'\n",
        "Q2_TRAINING_DATA_FILE = 'q2_train.npy'\n",
        "LABEL_TRAINING_DATA_FILE = 'label_train.npy'\n",
        "WORD_EMBEDDING_MATRIX_FILE = 'word_embedding_matrix.npy'\n",
        "NB_WORDS_DATA_FILE = 'nb_words.json'\n",
        "MODEL_WEIGHTS_FILE = 'question_pairs_weights.h5'\n",
        "MAX_SEQUENCE_LENGTH = 25\n",
        "EMBEDDING_DIM = 300\n",
        "VALIDATION_SPLIT = 0.1\n",
        "TEST_SPLIT = 0.1\n",
        "RNG_SEED = 13371447\n",
        "NB_EPOCHS = 25\n",
        "DROPOUT = 0.1\n",
        "BATCH_SIZE = 32"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "metadata": {
        "id": "tbaQimg4p1WU",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Load the dataset, embedding matrix and word count"
      ]
    },
    {
      "metadata": {
        "id": "IHTzrkxyp1WV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "355b4f09-6a99-49c2-c3ce-7d4d111156a8"
      },
      "cell_type": "code",
      "source": [
        "q1_data = np.load(open(Q1_TRAINING_DATA_FILE, 'rb'))\n",
        "q2_data = np.load(open(Q2_TRAINING_DATA_FILE, 'rb'))\n",
        "labels = np.load(open(LABEL_TRAINING_DATA_FILE, 'rb'))\n",
        "word_embedding_matrix = np.load(open(WORD_EMBEDDING_MATRIX_FILE, 'rb'))\n",
        "with open(NB_WORDS_DATA_FILE, 'r') as f:\n",
        "    nb_words = json.load(f)['nb_words']"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Owg8BnpPp1WZ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Partition the dataset into train and test sets"
      ]
    },
    {
      "metadata": {
        "id": "K41KLHlDp1WZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "b7bd1384-b9d2-4a61-c7a0-cba40dc48fd4"
      },
      "cell_type": "code",
      "source": [
        "X = np.stack((q1_data, q2_data), axis=1)\n",
        "y = labels\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=TEST_SPLIT, random_state=RNG_SEED)\n",
        "Q1_train = X_train[:,0]\n",
        "Q2_train = X_train[:,1]\n",
        "Q1_test = X_test[:,0]\n",
        "Q2_test = X_test[:,1]"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ciGIzdbBp1Wd",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Define the model"
      ]
    },
    {
      "metadata": {
        "id": "UZlsbLb_p1Wd",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "ec48219f-f75f-49a2-90e3-b5d875b16043"
      },
      "cell_type": "code",
      "source": [
        "question1 = Input(shape=(MAX_SEQUENCE_LENGTH,))\n",
        "question2 = Input(shape=(MAX_SEQUENCE_LENGTH,))\n",
        "\n",
        "q1 = Embedding(nb_words + 1, \n",
        "                 EMBEDDING_DIM, \n",
        "                 weights=[word_embedding_matrix], \n",
        "                 input_length=MAX_SEQUENCE_LENGTH, \n",
        "                 trainable=False)(question1)\n",
        "q1 = TimeDistributed(Dense(EMBEDDING_DIM, activation='relu'))(q1)\n",
        "q1 = Lambda(lambda x: K.max(x, axis=1), output_shape=(EMBEDDING_DIM, ))(q1)\n",
        "\n",
        "q2 = Embedding(nb_words + 1, \n",
        "                 EMBEDDING_DIM, \n",
        "                 weights=[word_embedding_matrix], \n",
        "                 input_length=MAX_SEQUENCE_LENGTH, \n",
        "                 trainable=False)(question2)\n",
        "q2 = TimeDistributed(Dense(EMBEDDING_DIM, activation='relu'))(q2)\n",
        "q2 = Lambda(lambda x: K.max(x, axis=1), output_shape=(EMBEDDING_DIM, ))(q2)\n",
        "\n",
        "merged = concatenate([q1,q2])\n",
        "#merged = Dense(200, activation='relu')(merged)\n",
        "#merged = Dropout(DROPOUT)(merged)\n",
        "#merged = BatchNormalization()(merged)\n",
        "#merged = Dense(200, activation='relu')(merged)\n",
        "#merged = Dropout(DROPOUT)(merged)\n",
        "#merged = BatchNormalization()(merged)\n",
        "#merged = Dense(200, activation='relu')(merged)\n",
        "#merged = Dropout(DROPOUT)(merged)\n",
        "#merged = BatchNormalization()(merged)\n",
        "merged = Dense(200, activation='relu')(merged)\n",
        "merged = Dropout(DROPOUT)(merged)\n",
        "#merged = BatchNormalization()(merged)\n",
        "\n",
        "is_duplicate = Dense(1, activation='sigmoid')(merged)\n",
        "\n",
        "model = Model(inputs=[question1,question2], outputs=is_duplicate)\n",
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "metadata": {
        "id": "NL88Ce64p1Wg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 599
        },
        "outputId": "d3119465-e7e6-4956-cdcf-c2885859c636"
      },
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_7 (InputLayer)            (None, 25)           0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_8 (InputLayer)            (None, 25)           0                                            \n",
            "__________________________________________________________________________________________________\n",
            "embedding_7 (Embedding)         (None, 25, 300)      28679100    input_7[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "embedding_8 (Embedding)         (None, 25, 300)      28679100    input_8[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "time_distributed_7 (TimeDistrib (None, 25, 300)      90300       embedding_7[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "time_distributed_8 (TimeDistrib (None, 25, 300)      90300       embedding_8[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "lambda_7 (Lambda)               (None, 300)          0           time_distributed_7[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "lambda_8 (Lambda)               (None, 300)          0           time_distributed_8[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_4 (Concatenate)     (None, 600)          0           lambda_7[0][0]                   \n",
            "                                                                 lambda_8[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "dense_21 (Dense)                (None, 200)          120200      concatenate_4[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_10 (Dropout)            (None, 200)          0           dense_21[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "dense_22 (Dense)                (None, 1)            201         dropout_10[0][0]                 \n",
            "==================================================================================================\n",
            "Total params: 57,659,201\n",
            "Trainable params: 301,001\n",
            "Non-trainable params: 57,358,200\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "DsJ_jgbap1Wl",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Train the model, checkpointing weights with best validation accuracy"
      ]
    },
    {
      "metadata": {
        "id": "OMfzV9tsp1Wn",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 163
        },
        "outputId": "734769a0-aa97-467d-ffd7-5da7609fdb85"
      },
      "cell_type": "code",
      "source": [
        "print(\"Starting training at\", datetime.datetime.now())\n",
        "t0 = time.time()\n",
        "callbacks = [ModelCheckpoint(MODEL_WEIGHTS_FILE, monitor='val_acc', save_best_only=True)]\n",
        "S= int(len(Q1_train)/2)\n",
        "print (f'training on a subset of size {S}')\n",
        "history = model.fit([Q1_train[:S], Q2_train[:S]],\n",
        "                    y_train[:S],\n",
        "                    epochs=NB_EPOCHS,\n",
        "                    validation_split=VALIDATION_SPLIT,\n",
        "                    verbose=2,\n",
        "                    batch_size=BATCH_SIZE,\n",
        "                    callbacks=callbacks)\n",
        "t1 = time.time()\n",
        "print(\"Training ended at\", datetime.datetime.now())\n",
        "print(\"Minutes elapsed: %f\" % ((t1 - t0) / 60.))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Starting training at 2018-07-04 10:02:19.251590\n",
            "training on a subset of size 181930\n",
            "Train on 163737 samples, validate on 18193 samples\n",
            "Epoch 1/25\n",
            " - 41s - loss: 0.4681 - acc: 0.7742 - val_loss: 0.4700 - val_acc: 0.7685\n",
            "Epoch 2/25\n",
            " - 41s - loss: 0.4251 - acc: 0.7966 - val_loss: 0.4642 - val_acc: 0.7760\n",
            "Epoch 3/25\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "qr1tcf64p1Wt",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Plot training and validation accuracy"
      ]
    },
    {
      "metadata": {
        "id": "XQ0wMapYp1Wt",
        "colab_type": "code",
        "colab": {},
        "outputId": "d40d4858-a174-4704-81a7-73df4685c742"
      },
      "cell_type": "code",
      "source": [
        "acc = pd.DataFrame({'epoch': [ i + 1 for i in history.epoch ],\n",
        "                    'training': history.history['acc'],\n",
        "                    'validation': history.history['val_acc']})\n",
        "ax = acc.iloc[:,:].plot(x='epoch', figsize={5,8}, grid=True)\n",
        "ax.set_ylabel(\"accuracy\")\n",
        "ax.set_ylim([0.0,1.0]);"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAfYAAAFHCAYAAABTfW5sAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nyP8H39S5XeHsry0AAAAASUVORK5CYII=\n",
            "text/plain": [
              "<matplotlib.figure.Figure at 0x7f09d3623390>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "A5oXNQaYp1Wx",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Print best validation accuracy and epoch"
      ]
    },
    {
      "metadata": {
        "id": "28HpgHa-p1Wy",
        "colab_type": "code",
        "colab": {},
        "outputId": "9e3d681d-4b86-4678-e2f4-5966d2f627df"
      },
      "cell_type": "code",
      "source": [
        "max_val_acc, idx = max((val, idx) for (idx, val) in enumerate(history.history['val_acc']))\n",
        "print('Maximum accuracy at epoch', '{:d}'.format(idx+1), '=', '{:.4f}'.format(max_val_acc))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Maximum accuracy at epoch 16 = 0.8083\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "aqBkTkNTp1W3",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Evaluate the model with best validation accuracy on the test partition"
      ]
    },
    {
      "metadata": {
        "id": "-1kp_Mztp1W4",
        "colab_type": "code",
        "colab": {},
        "outputId": "71354bc1-9022-400a-ca5d-82a526c87cd9"
      },
      "cell_type": "code",
      "source": [
        "model.load_weights(MODEL_WEIGHTS_FILE)\n",
        "loss, accuracy = model.evaluate([Q1_test, Q2_test], y_test, verbose=0)\n",
        "print('loss = {0:.4f}, accuracy = {1:.4f}'.format(loss, accuracy))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "loss = 0.4102, accuracy = 0.8110\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}
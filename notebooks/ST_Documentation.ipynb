{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ST_Documentation.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "[View in Colaboratory](https://colab.research.google.com/github/assaflehr/language-style-transfer/blob/master/notebooks/ST_Documentation.ipynb)"
      ]
    },
    {
      "metadata": {
        "id": "A8g4WTzSCHfM",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Outline of experiments\n",
        "\n",
        "## 1: find a strong-enough sentence representation and matching model\n",
        "One of the key requirements is an encoded sentence representation from which a decoder can reconstruct a sentnence with input style. A simpler requirement, is to just reconsturct the same sentence without error on one single style. Thus our model should be at least as strong.\n",
        "\n",
        "[Experiment 1 autoencoder](https://colab.research.google.com/drive/1zG2KVIpf7avf50C9E-tKKPPyQkz1iGdf#scrollTo=wAzuDhY3rgGS&uniqifier=15)\n",
        "\n",
        "## 2: condition decoder on style\n",
        "\n",
        "## 3: allign sentences close in semantic into close embedding vectors.\n",
        "\n",
        "## 4: \n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "gYGAlsc4CqLU",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        ""
      ]
    },
    {
      "metadata": {
        "id": "fEqIKuzt-Tje",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Literature : Alternative approaches\n",
        "\n",
        "\n",
        "\n",
        "**Fully unsupervised approach using skip-thought vectors**\n",
        "skip-thought vectors are an embedding for full-sentences, trained via close sentences context (similiar to word2vec but for setence level). The author, showed that a setnence embedding F(X) = semantic + style. Thus they theoraized you can take a sentence vector and do style arithmetic. If you have a mean vector for each style (calculated as mean of all setences by certain author-style), you can just do  semantic - style1_mean + style2_mean to get the same semantic in diffrent style.\n",
        "Results only compared two very different styles: short-captions-of-images VS long-sentences-from-many-romance-stroies.  Work can be seen here: https://github.com/ryankiros/neural-storyteller\n",
        "\n",
        "\n",
        "\n"
      ]
    }
  ]
}
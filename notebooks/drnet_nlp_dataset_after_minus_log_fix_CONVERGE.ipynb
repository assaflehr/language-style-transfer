{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "drnet_nlp_dataset.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "[View in Colaboratory](https://colab.research.google.com/github/assaflehr/language-style-transfer/blob/master/notebooks/drnet_nlp_dataset_after_minus_log_fix_CONVERGE.ipynb)"
      ]
    },
    {
      "metadata": {
        "id": "9DZmHoW4hbsO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 510
        },
        "outputId": "03eac100-cbc9-4153-ca42-89deb710cc96"
      },
      "cell_type": "code",
      "source": [
        "#!pip install spacy   #can take few minutes\n",
        "#!python -m spacy download en\n",
        "#!pip install git+https://github.com/fastai/fastai.git\n",
        "!pip install torch -U # 0.4 at-least\n",
        "\n",
        "!pip install torchtext  # for simpler datasets\n",
        "\n",
        "!pip install git+https://github.com/IBM/pytorch-seq2seq  #for seq2seq\n",
        "#!pip install git+https://github.com/shahsohil/stableGAN  # for AdamPre adv optimizer\n",
        "!pip install dill  #req of seq2seq\n",
        "!pip install tqdm  #req of seq2seq\n",
        "\n",
        "#!pip install revtok"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already up-to-date: torch in /usr/local/lib/python3.6/dist-packages (0.4.1)\n",
            "Requirement already satisfied: torchtext in /usr/local/lib/python3.6/dist-packages (0.2.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from torchtext) (2.18.4)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from torchtext) (4.24.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->torchtext) (2018.8.13)\n",
            "Requirement already satisfied: urllib3<1.23,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->torchtext) (1.22)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->torchtext) (3.0.4)\n",
            "Requirement already satisfied: idna<2.7,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->torchtext) (2.6)\n",
            "Collecting git+https://github.com/IBM/pytorch-seq2seq\n",
            "  Cloning https://github.com/IBM/pytorch-seq2seq to /tmp/pip-req-build-6z27d1ob\n",
            "Requirement already satisfied (use --upgrade to upgrade): seq2seq==0.1.6 from git+https://github.com/IBM/pytorch-seq2seq in /usr/local/lib/python3.6/dist-packages\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from seq2seq==0.1.6) (1.14.5)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.6/dist-packages (from seq2seq==0.1.6) (0.4.1)\n",
            "Requirement already satisfied: torchtext in /usr/local/lib/python3.6/dist-packages (from seq2seq==0.1.6) (0.2.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from torchtext->seq2seq==0.1.6) (2.18.4)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from torchtext->seq2seq==0.1.6) (4.24.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->torchtext->seq2seq==0.1.6) (2018.8.13)\n",
            "Requirement already satisfied: idna<2.7,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->torchtext->seq2seq==0.1.6) (2.6)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->torchtext->seq2seq==0.1.6) (3.0.4)\n",
            "Requirement already satisfied: urllib3<1.23,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->torchtext->seq2seq==0.1.6) (1.22)\n",
            "Building wheels for collected packages: seq2seq\n",
            "  Running setup.py bdist_wheel for seq2seq ... \u001b[?25l-\b \b\\\b \bdone\n",
            "\u001b[?25h  Stored in directory: /tmp/pip-ephem-wheel-cache-5hnk9872/wheels/98/b5/06/771c406b3ecc8ed34f07da72d7baf65b87e561bd9f808e91bd\n",
            "Successfully built seq2seq\n",
            "Requirement already satisfied: dill in /usr/local/lib/python3.6/dist-packages (0.2.8.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (4.24.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "81NtEq8xlXed",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#copied VERBATIM from  git+https://github.com/shahsohil/stableGAN (lacks setup.py)\n",
        "\n",
        "import math\n",
        "from torch.optim.optimizer import Optimizer\n",
        "\n",
        "\n",
        "class AdamPre(Optimizer):\n",
        "    \"\"\"Implements Adam algorithm with prediction step.\n",
        "    This class implements lookahead version of Adam Optimizer.\n",
        "    The structure of class is similar to Adam class in Pytorch.\n",
        "    Arguments:\n",
        "        params (iterable): iterable of parameters to optimize or dicts defining\n",
        "            parameter groups\n",
        "        lr (float, optional): learning rate (default: 1e-3)\n",
        "        betas (Tuple[float, float], optional): coefficients used for computing\n",
        "            running averages of gradient and its square (default: (0.9, 0.999))\n",
        "        eps (float, optional): term added to the denominator to improve\n",
        "            numerical stability (default: 1e-8)\n",
        "        weight_decay (float, optional): weight decay (L2 penalty) (default: 0)\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, params, lr=1e-3, betas=(0.9, 0.999), eps=1e-8,\n",
        "                 weight_decay=0, name='NotGiven'):\n",
        "        self.name = name\n",
        "        defaults = dict(lr=lr, betas=betas, eps=eps,\n",
        "                        weight_decay=weight_decay)\n",
        "        super(AdamPre, self).__init__(params, defaults)\n",
        "\n",
        "    def step(self, closure=None):\n",
        "        \"\"\"Performs a single optimization step.\n",
        "        Arguments:\n",
        "            closure (callable, optional): A closure that reevaluates the model\n",
        "                and returns the loss.\n",
        "        \"\"\"\n",
        "        loss = None\n",
        "        if closure is not None:\n",
        "            loss = closure()\n",
        "\n",
        "        for group in self.param_groups:\n",
        "            for p in group['params']:\n",
        "                if p.grad is None:\n",
        "                    continue\n",
        "                grad = p.grad.data\n",
        "\n",
        "                state = self.state[p]\n",
        "\n",
        "                # State initialization\n",
        "                if len(state) == 0:\n",
        "                    state['step'] = 0\n",
        "                    # Exponential moving average of gradient values\n",
        "                    state['exp_avg'] = grad.new().resize_as_(grad).zero_()\n",
        "                    # Exponential moving average of squared gradient values\n",
        "                    state['exp_avg_sq'] = grad.new().resize_as_(grad).zero_()\n",
        "\n",
        "                    state['oldWeights'] = p.data.clone()\n",
        "\n",
        "                exp_avg, exp_avg_sq = state['exp_avg'], state['exp_avg_sq']\n",
        "                beta1, beta2 = group['betas']\n",
        "\n",
        "                state['step'] += 1\n",
        "\n",
        "                if group['weight_decay'] != 0:\n",
        "                    grad = grad.add(group['weight_decay'], p.data)\n",
        "\n",
        "                # Decay the first and second moment running average coefficient\n",
        "                exp_avg.mul_(beta1).add_(1 - beta1, grad)\n",
        "                exp_avg_sq.mul_(beta2).addcmul_(1 - beta2, grad, grad)\n",
        "\n",
        "                denom = exp_avg_sq.sqrt().add_(group['eps'])\n",
        "\n",
        "                bias_correction1 = 1 - beta1 ** min(state['step'],1022)\n",
        "                bias_correction2 = 1 - beta2 ** min(state['step'],1022)\n",
        "                step_size = group['lr'] * math.sqrt(bias_correction2) / bias_correction1\n",
        "\n",
        "                p.data.addcdiv_(-step_size, exp_avg, denom)\n",
        "        return loss\n",
        "\n",
        "    def stepLookAhead(self, closure=None):\n",
        "        \"\"\"Performs a single optimization step.\n",
        "        Arguments:\n",
        "            closure (callable, optional): A closure that reevaluates the model\n",
        "                and returns the loss.\n",
        "        \"\"\"\n",
        "        loss = None\n",
        "        if closure is not None:\n",
        "            loss = closure()\n",
        "\n",
        "        for group in self.param_groups:\n",
        "            for p in group['params']:\n",
        "                if p.grad is None:\n",
        "                    continue\n",
        "                state = self.state[p]\n",
        "                temp_grad = p.data.sub(state['oldWeights'])\n",
        "                state['oldWeights'].copy_(p.data)\n",
        "                p.data.add_(temp_grad)\n",
        "        return loss\n",
        "\n",
        "\n",
        "    def restoreStepLookAhead(self, closure=None):\n",
        "        \"\"\"Performs a single optimization step.\n",
        "        Arguments:\n",
        "            closure (callable, optional): A closure that reevaluates the model\n",
        "                and returns the loss.\n",
        "        \"\"\"\n",
        "        loss = None\n",
        "        if closure is not None:\n",
        "            loss = closure()\n",
        "\n",
        "        for group in self.param_groups:\n",
        "            for p in group['params']:\n",
        "                if p.grad is None:\n",
        "                    continue\n",
        "                state = self.state[p]\n",
        "                p.data.copy_(state['oldWeights'])\n",
        "        return loss"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "qHWOFxkWSubZ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Dataset with torchtext"
      ]
    },
    {
      "metadata": {
        "id": "vQn5WXMiSzae",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 601
        },
        "outputId": "4171b2c7-c342-4d42-cdc6-621ec4db3452"
      },
      "cell_type": "code",
      "source": [
        "\n",
        "import random\n",
        "\n",
        "import time\n",
        "import numpy as np\n",
        "from collections import namedtuple\n",
        "import logging\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torchtext.data as data\n",
        "%matplotlib inline\n",
        "\n",
        "logger = logging.getLogger()\n",
        "logger.setLevel(logging.DEBUG)\n",
        "logging.basicConfig(format='%(asctime)s %(levelname)s:%(message)s', level=logging.DEBUG, datefmt='%I:%M:%S')\n",
        "\n",
        "random.seed(42)\n",
        "\n",
        "# on sample of the dataset\n",
        "TimeExample = namedtuple('TimeExample',['src','sent_0','sent_1','sent_x','is_x_0','sent_0_target'])\n",
        "\n",
        "class TimeStyleDataset(Dataset):\n",
        "  \n",
        "  def __init__(self,max_id,time_mod_3_result,label_smoothing=False): \n",
        "    \"\"\"\n",
        "    max_id how many samples are in this dataset. Size of one epoc!\n",
        "    time_mod_3_result - to make sure time is train/test/valid is different, pass 0,1,2\n",
        "    label_smoothing - trick from \"soumith/ganhacks\", instead of 0/1 labels, pass 0-0.3, 0.7-1.2 labels\n",
        "    \"\"\"\n",
        "    self.max_id =int(max_id)\n",
        "    #TODO : add more!!# see here: https://docs.python.org/2/library/datetime.html month can be: %b,%B,%m , year: %y,%Y\n",
        "    self.formats = [\"%b %d %Y %H:%M:%S\", \"%m/%d/%Y %H:%M:%S\", \"%d-%b-%Y %H.%M.%S.00\",\n",
        "                    \"%B %d %y %H:%M:%S\" ,\"%B %d %H:%M:%S %Y\", \"%d/%B/%Y %H:%M:%S\"]\n",
        "    self.time_mod_3_result=time_mod_3_result\n",
        "    self.label_smoothing = label_smoothing \n",
        "  \n",
        "  def __len__(self):\n",
        "    return self.max_id\n",
        "  \n",
        "  def _tvt(self,idx):\n",
        "    # for 10, if train, return 9, valid 10, test 11\n",
        "    return (idx//3) * 3 + self.time_mod_3_result #10//3 * 3 + x = 9+x\n",
        "  \n",
        "  def __getitem__(self,idx):\n",
        "    if idx > self.max_id:\n",
        "      raise IndexError(f'TimeStyleDataset {idx} is out of range {self.max_id}')\n",
        "    \n",
        "    \"\"\" x -  x[0] semantic0   , style0\n",
        "             x[1] semantic0   , style1   \n",
        "             x[2] semantic0orX, style0 (1/2 the time 0 , half X)\n",
        "    \"\"\"\n",
        "    max_time= 2*int(2e9)  #means 1970-2001\n",
        "    \n",
        "    random_ids = np.random.randint(low=0,high=max_time,size=2)\n",
        "    idx = random_ids[0] #other_idx is 50% same, 50% other\n",
        "    other_idx = random_ids[1] if np.random.randint(0,2)==0 else random_ids[0]\n",
        "\n",
        "    idx = self._tvt(idx)\n",
        "    other_idx = self._tvt(other_idx)\n",
        "   \n",
        "    # two random formats\n",
        "    random_fs= np.random.choice(len(self.formats),size=2,replace=False)\n",
        "    \n",
        "    sent_0= time.strftime(self.formats[random_fs[0]],time.gmtime(idx)) \n",
        "    sent_1= time.strftime(self.formats[random_fs[1]],time.gmtime(idx)) \n",
        "    sent_x= time.strftime(self.formats[random_fs[0]],time.gmtime(other_idx))\n",
        "    y = torch.FloatTensor(np.array([idx==other_idx],np.float32))\n",
        "    if self.label_smoothing:\n",
        "      y[y==1.0] = (0.7+0.5* np.random.rand()) \n",
        "      y[y==0.0] = (0.3 * np.random.rand())\n",
        "\n",
        "    return TimeExample(sent_0,sent_0,sent_1,sent_x,y,sent_0)\n",
        "\n",
        "def test():\n",
        "  dataset = TimeStyleDataset(1e3,1)\n",
        "  for i in range(3):\n",
        "    sample = dataset[i] ; print ('test sample',sample)  \n",
        "  #print ('len',len(dataset))\n",
        "  \n",
        "test()\n",
        "\n",
        "\n",
        "def revers_vocab(vocab,sent,seperator):\n",
        "  return seperator.join([vocab.itos[token] for token in sent])\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "from seq2seq.dataset import SourceField,TargetField\n",
        "\"\"\"\" Wrapper class of torchtext.data.Field that forces batch_first to be True \n",
        "and prepend <sos> and append <eos> to sequences in preprocessing step. \"\"\"\n",
        "TEXT_TARGET = TargetField(batch_first =True,sequential=True,use_vocab=True, lower=False, init_token=TargetField.SYM_SOS,\n",
        "                 eos_token=TargetField.SYM_EOS, tokenize=lambda x: list(x)) # fix_length=10\n",
        "TEXT = SourceField(batch_first =True,sequential=True,use_vocab=True, lower=False,\n",
        "                            tokenize=lambda x: list(x)) # fix_length=10\n",
        "LABEL= data.Field(batch_first=True,sequential=False,use_vocab=False, tensor_type =torch.FloatTensor)\n",
        "\n",
        "\n",
        "fields = [('src',TEXT),('sent_0',TEXT),('sent_1',TEXT),('sent_x',TEXT),('is_x_0',LABEL),('sent_0_target',TEXT_TARGET)] \n",
        "ds_train = data.Dataset(TimeStyleDataset(1e3,1,label_smoothing=True), fields)\n",
        "ds_eval = data.Dataset(TimeStyleDataset(1e3,2), fields)\n",
        "\n",
        "print ('printing dataset directly, before tokenizing:')\n",
        "print ('sent_0',ds_train[2].sent_0) #not processed\n",
        "print ('is_x_0',ds_train[2].is_x_0) #not processed\n",
        "\n",
        "print ('\\nbuilding vocab:')\n",
        "#TEXT.build_vocab(ds, max_size=80000)\n",
        "TEXT_TARGET.build_vocab(ds_train, max_size=80000)\n",
        "TEXT.vocab = TEXT_TARGET.vocab #same except from the added <sos>,<eos>\n",
        "\n",
        "print ('vocab TEXT: len',len(TEXT.vocab), 'common',TEXT.vocab.freqs.most_common()[:10])\n",
        "print ('vocab TEXT_TARGET:',len(TEXT_TARGET.vocab), TEXT_TARGET.vocab.freqs.most_common()[:10])\n",
        "print ('vocab ',TEXT_TARGET.SYM_SOS, TEXT_TARGET.sos_id,TEXT_TARGET.vocab.stoi[TEXT_TARGET.SYM_SOS])\n",
        "print ('vocab ',TEXT_TARGET.SYM_EOS, TEXT_TARGET.eos_id,TEXT_TARGET.vocab.stoi[TEXT_TARGET.SYM_EOS])\n",
        "print ('vocab ','out-of-vocab', TEXT_TARGET.eos_id,TEXT_TARGET.vocab.stoi['out-of-vocab'])\n",
        "\n",
        "       \n",
        "device = None if torch.cuda.is_available() else -1\n",
        "# READ:  https://github.com/mjc92/TorchTextTutorial/blob/master/01.%20Getting%20started.ipynb\n",
        "sort_within_batch=True\n",
        "train_iter = iter(data.BucketIterator( dataset=ds_train, device=device,batch_size=32, sort_within_batch=sort_within_batch,sort_key=lambda x: len(x.sent_0))) \n",
        "eval_iter =  iter(data.BucketIterator( dataset=ds_eval, device=device, batch_size=32, sort_within_batch=sort_within_batch,sort_key=lambda x: len(x.sent_0))) \n",
        "#performance note: the first next, takes 3.5s, the next are fast (10000 is 1s)\n",
        "\n",
        "\n",
        "for i in range(1):\n",
        "  b= next(train_iter)\n",
        "  # usage\n",
        "  print ('\\nb.is_x_0',b.is_x_0[0],b.is_x_0.type())\n",
        "  print ('b.src is values+len tuple',b.src[0].shape,b.src[1].shape )\n",
        "  print ('b.sent_0_target',b.sent_0_target.shape,b.sent_0_target[0],revers_vocab(TEXT_TARGET.vocab,b.sent_0_target[0],''))\n",
        "  print ('b_sent0',b.sent_0[0].shape,b.sent_0[1].shape,b.sent_0[0][0],revers_vocab(TEXT.vocab,b.sent_0[0][0],''))\n",
        "  print ('b_sent1',b.sent_1[0].shape,b.sent_1[1].shape,b.sent_1[0][0],revers_vocab(TEXT.vocab,b.sent_1[0][0],''))\n",
        "  print ('b_sentx',b.sent_x[0].shape,b.sent_x[1].shape,b.sent_x[0][0],revers_vocab(TEXT.vocab,b.sent_x[0][0],''))\n",
        "  print ('b_y',b.is_x_0.shape,b.is_x_0)\n",
        "  print (b.sent_0[1])\n",
        "\n",
        "\n"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "test sample TimeExample(src='03/30/2084 00:21:07', sent_0='03/30/2084 00:21:07', sent_1='March 30 84 00:21:07', sent_x='06/01/2013 08:11:28', is_x_0=tensor([0.]), sent_0_target='03/30/2084 00:21:07')\n",
            "test sample TimeExample(src='11/04/2066 20:07:01', sent_0='11/04/2066 20:07:01', sent_1='04/November/2066 20:07:01', sent_x='05/06/2049 17:43:55', is_x_0=tensor([0.]), sent_0_target='11/04/2066 20:07:01')\n",
            "test sample TimeExample(src='December 15 89 00:04:34', sent_0='December 15 89 00:04:34', sent_1='15-Dec-2089 00.04.34.00', sent_x='November 18 79 12:28:46', is_x_0=tensor([0.]), sent_0_target='December 15 89 00:04:34')\n",
            "printing dataset directly, before tokenizing:\n",
            "sent_0 28-Feb-2084 21.11.34.00\n",
            "is_x_0 tensor([0.0994])\n",
            "\n",
            "building vocab:\n",
            "vocab TEXT: len 45 common [('0', 2818), ('2', 2049), (' ', 1989), ('1', 1970), (':', 1636), ('3', 977), ('4', 959), ('5', 879), ('9', 831), ('/', 648)]\n",
            "vocab TEXT_TARGET: 45 [('0', 2818), ('2', 2049), (' ', 1989), ('1', 1970), (':', 1636), ('3', 977), ('4', 959), ('5', 879), ('9', 831), ('/', 648)]\n",
            "vocab  <sos> 2 2\n",
            "vocab  <eos> 3 3\n",
            "vocab  out-of-vocab 3 0\n",
            "\n",
            "b.is_x_0 tensor(1.0530, device='cuda:0') torch.cuda.FloatTensor\n",
            "b.src is values+len tuple torch.Size([32, 25]) torch.Size([32])\n",
            "b.sent_0_target torch.Size([32, 27]) tensor([ 2,  5, 16, 13, 37, 34, 38, 18, 33, 23, 18, 19, 13,  7, 12, 12, 12,  6,\n",
            "         5,  4,  8, 11, 12,  8, 10, 16,  3], device='cuda:0') <sos>26/November/1999 20:59:46<eos>\n",
            "b_sent0 torch.Size([32, 25]) torch.Size([32]) tensor([ 5, 16, 13, 37, 34, 38, 18, 33, 23, 18, 19, 13,  7, 12, 12, 12,  6,  5,\n",
            "         4,  8, 11, 12,  8, 10, 16], device='cuda:0') 26/November/1999 20:59:46\n",
            "b_sent1 torch.Size([32, 25]) torch.Size([32]) tensor([ 5, 16, 20, 37, 34, 38, 20,  7, 12, 12, 12,  6,  5,  4, 17, 11, 12, 17,\n",
            "        10, 16, 17,  4,  4,  1,  1], device='cuda:0') 26-Nov-1999 20.59.46.00<pad><pad>\n",
            "b_sentx torch.Size([32, 25]) torch.Size([32]) tensor([ 5, 16, 13, 37, 34, 38, 18, 33, 23, 18, 19, 13,  7, 12, 12, 12,  6,  5,\n",
            "         4,  8, 11, 12,  8, 10, 16], device='cuda:0') 26/November/1999 20:59:46\n",
            "b_y torch.Size([32]) tensor([1.0530, 1.1010, 0.1113, 0.0668, 0.9362, 0.2869, 0.2636, 0.0290, 0.1969,\n",
            "        1.1386, 0.7078, 0.7252, 1.1705, 0.1264, 0.0352, 0.0848, 0.9087, 0.2966,\n",
            "        0.8356, 0.2019, 0.0076, 0.0657, 0.2790, 0.7667, 0.0667, 1.0699, 0.0823,\n",
            "        0.1768, 0.9236, 1.1760, 0.7473, 0.2193], device='cuda:0')\n",
            "tensor([25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25,\n",
            "        25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25],\n",
            "       device='cuda:0')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "HUzyuMXje2i1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "a41a25b6-9ed5-4b58-ae4e-fe33e58700a1"
      },
      "cell_type": "code",
      "source": [
        "y= np.array([1,1,1])\n",
        "print (y.shape,y)\n",
        "\n",
        "y[y==0.0] = (0.3*np.random.rand(*y.shape))[y==0.0]\n",
        "print (y)\n",
        "\n"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(3,) [1 1 1]\n",
            "[1 1 1]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "PdoVxGFbP-GR",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        ""
      ]
    },
    {
      "metadata": {
        "id": "Mx_wvDraYghh",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# models define"
      ]
    },
    {
      "metadata": {
        "id": "nMc6XeMxWxha",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Documentation"
      ]
    },
    {
      "metadata": {
        "id": "wnsebPEMW0d4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 298
        },
        "outputId": "c6013828-b7ec-40b7-838e-2e02e307dfcf"
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "\n",
        "# semantic_encoder : take sentence return a vector with only semantics\n",
        "# semantic similiary objective: given a pair of sentences with the same semantics,\n",
        "#    expect their results to be close (MeanSquared)    \n",
        "\n",
        "# see idea from https://github.com/edenton/drnet-py/blob/master/models/classifiers.py\n",
        "# in her train method:\n",
        "# FRAMES: VID A: FRAME 1 x_c1 , ?x_p2? (1/2 of times)\n",
        "#                FRAME 2 x_c2 , x_p1\n",
        "#         VID B: FRAME 1      , ?x_p2? (1/2 of times)\n",
        "#  \n",
        "# x_p1,x_p2 chosen randonly from same/not-same video\n",
        "# x_c1,x_c2 are always same-video\n",
        "# c1 and p1 are same content, different pose.\n",
        "\n",
        "# train_scene_discriminator()\n",
        "# h_p1,h_p2 = netEP applied to x[0],x[1]. assumption: SAME VIDEO\n",
        "# important: detach both!\n",
        "# override half of h_p2 by random-permutations of the batch. \n",
        "#   [1,2,3,4,5,6]\n",
        "#   [2,3,1,4,5,6] after 1st half permute\n",
        "#   [1,1,1,0,0,0] set unequal the labels (1=unequal, 0 equal. does it matter? should it be 0.9,0.1?)\n",
        "# apply BCE on inpit: concat of [h_p1,h_p2] \n",
        "# run backward, and optimizer on the netC classifier ONLY! emphasize! not on the encoder\n",
        "\n",
        "\n",
        "# train()\n",
        "# h_c1,h_c2 = netEC(x_c1), netEC(x_c2)  where input is x[0],x[1] sim loss is MSE directly on the hidden content-semantics\n",
        "# h_p1,h_p2 = netEP(x_p1),netEP(x_p2) where input is x[2],x[3]\n",
        "# rec = netD([h_c1, h_p1]) h_c1 is DIFFERENT FRAME , but same content, than h_p1\n",
        "# netC is the semantic-discriminator given h_p1,h_p2, target 0.5 (max-entropy). \n",
        "# emphasize! don't optimize netC is this stage\n",
        "\n",
        "#Imp notes\n",
        "# BIDI: when using bidi-encoder, we decided to merge the two D-dim vectors using +, getting D-dim embedding. empiracally, better result than concat\n",
        "# OPTIMIZER: adv training is known to be unstable. We used the following known methods to make it more stable:\n",
        "#            ??? sensativity to lr (fail to converge on close lr)- use AdamPre optimizer instead of Adam\n",
        "#            ??? don't use ReLU layer, use Leaky instead (I used PreRELU)\n",
        "#            never allow G or D to achieve high accuracy (before the end)  \n",
        "#            IMPORTANT: noisy input via dropout\n",
        "#            IMPORTANT: label_smoothing on the ds\n",
        "# ANTI-ADVERSERTIAL LOSS FUNCTION, target is 0.5, so min value is 0.6931471805599453\n",
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "x = np.arange(1,100)/100.0\n",
        "plt.title(\"anti adv-loss with target of 0.5. min is 0.693147 \")\n",
        "plt.plot(x, -0.5*(np.log(x)+np.log(1-x)))\n",
        "#-0.5*(np.log(0.53)+np.log(1-0.53))\n",
        "\n"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7fb8de585550>]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXIAAAEHCAYAAACzy817AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nQmCC\n",
            "text/plain": [
              "<matplotlib.figure.Figure at 0x7fb8de585c18>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "2qo5XKYPW25Z",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## PARAMS"
      ]
    },
    {
      "metadata": {
        "id": "ytDrOHZtXMuc",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        ""
      ]
    },
    {
      "metadata": {
        "id": "I9CZBDxzYbt_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "bd0fcbb8-9c6b-4b3e-d7b1-9d54052d8f28"
      },
      "cell_type": "code",
      "source": [
        "import argparse\n",
        "import sys\n",
        "parser = argparse.ArgumentParser()\n",
        "\n",
        "parser.add_argument('--epocs', type=int, default=2, help='number of epochs to train for')\n",
        "parser.add_argument('--epoch_size', type=int, default=600, help='epoch size')\n",
        "parser.add_argument('--batch_size', default=32, type=int, help='batch size')\n",
        "\n",
        "parser.add_argument('--optimizer', default='adampre', help='optimizer to train with. only Adam, AdamPre supported. Without AdamPre you must pinpoint the right learning-rate, otherwise training will not converge.')\n",
        "parser.add_argument('--lr', default=0.0025, type=float, help='learning rate. source=0.002')\n",
        "parser.add_argument('--adv_disc_lr', default=0.01, type=float, help='learning rate')\n",
        "\n",
        "parser.add_argument('--beta1', default=0.5, type=float, help='momentum term for adam')\n",
        "\n",
        "parser.add_argument('--semantics_dim', type=int, default=200, help='size of the semantics vector')\n",
        "parser.add_argument('--style_dim', type=int, default=60, help='size of the style vector')\n",
        "parser.add_argument('--sd_weight', type=float, default=0.05, help='weight on adversarial loss 0.0001 originally. 0.5 is good value!')\n",
        "parser.add_argument('--sem_sim_weight', type=float, default=100, help='weight on semantic similiarity loss')\n",
        "\n",
        "parser.add_argument('--max_sent_len', type=int, default=40, help='max size of sentence. sentences typically will be shorter')\n",
        "\n",
        "\n",
        "'''\n",
        "parser.add_argument('--max_step', type=int, default=20, help='maximum distance between frames')\n",
        "parser.add_argument('--seed', default=1, type=int, help='manual seed')\n",
        "parser.add_argument('--log_dir', default='logs', help='base directory to save logs')\n",
        "parser.add_argument('--data_root', default='', help='root directory for data')\n",
        "\n",
        "parser.add_argument('--dataset', default='moving_mnist', help='dataset to train with')\n",
        "\n",
        "parser.add_argument('--sd_nf', type=int, default=100, help='number of layers')\n",
        "parser.add_argument('--content_model', default='dcgan_unet', help='model type (dcgan | dcgan_unet | vgg_unet)')\n",
        "parser.add_argument('--pose_model', default='dcgan', help='model type (dcgan | unet | resnet)')\n",
        "parser.add_argument('--data_threads', type=int, default=5, help='number of parallel data loading threads')\n",
        "parser.add_argument('--data_type', default='drnet', help='speed up data loading for drnet training')\n",
        "'''\n",
        "sys.argv=[\"nothing\"]\n",
        "opt = parser.parse_args()\n",
        "print (opt.lr,)"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.0025\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "sIvO_Nes5nSF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "efe064ee-ce59-4579-acfb-7c97c188e3a9"
      },
      "cell_type": "code",
      "source": [
        "type(np.array([2\n",
        "         ]))"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "numpy.ndarray"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "metadata": {
        "id": "DSLXyMbdX99M",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Define Encoder, Decoder"
      ]
    },
    {
      "metadata": {
        "id": "G3ghi3B0ymmk",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#   decoders"
      ]
    },
    {
      "metadata": {
        "id": "bXi51149ioGD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 163
        },
        "outputId": "268dea0f-d783-4d7f-cbfe-ea46068918dd"
      },
      "cell_type": "code",
      "source": [
        "#trn_dl = DataLoader(TimePairsDataset(1e5,1), batch_size=opt.batch_size,)\n",
        "#x,y = next(iter(trn_dl)) \n",
        "#print ('input . x is vertically stacked sentences',x.shape,'y',y.shape)\n",
        "#batch,pair,sentence_len=x.shape\n",
        "\n",
        "\n",
        "from seq2seq.models import EncoderRNN, DecoderRNN\n",
        "from torch import nn\n",
        "\n",
        "\n",
        "random.seed(42)\n",
        "\n",
        "########################## UTILS ##########################\n",
        "cuda=True\n",
        "def T(arg):\n",
        "  if cuda:\n",
        "    if type(arg)==tuple:\n",
        "      arg = tuple( t.cuda() for t in arg ) #new tuple all cuda-d\n",
        "    else:\n",
        "      arg = arg.cuda()\n",
        "  return arg\n",
        "\n",
        "def N(arg):\n",
        "  if isinstance(arg,np.ndarray) or isinstance(arg,np.float64):\n",
        "    return arg #as is\n",
        "  # to numpy\n",
        "  return arg.cpu().numpy()\n",
        "\n",
        "########################## MODELS ##########################\n",
        "class EncoderWrapper(nn.Module):\n",
        "  \"\"\" wraps encoder, accpet in forward tuple of (data,len). return last hidden\"\"\"\n",
        "  def __init__(self,encoder):\n",
        "    super(EncoderWrapper,self).__init__()\n",
        "    self.encoder = encoder\n",
        "  \n",
        "  def forward(self,inp):\n",
        "\n",
        "      #in_data,in_len = in_tuple\n",
        "      output,hidden = self.encoder(*inp)#in_data,in_len)\n",
        "      # **output** (batch, seq_len, hidden_size): tensor containing the encoded features of the input sequence\n",
        "      # **hidden** (num_layers * num_directions, batch, hidden_size): tensor containing the features in the hidden state `h`\n",
        "      #return hidden[0,:,:]\n",
        "      #return hidden[:,:,:].# view(1,hidden.size(1),-1)[0,:,:] #BUG BUG BUG O: check dim order, 2xbsxdim -> 1xbsxdim*2 ??\n",
        "      \n",
        "      #in lstm hidden is a tuple\n",
        "      return torch.sum(hidden,dim=0)\n",
        "      #TODO : BUG HERE \n",
        "\n",
        "\n",
        "\n",
        "variable_lengths = False  # True means batch is ordered. this can't be done as sent0.len!=sent1.len, to make it happen need to seperate batches!!!\n",
        "encoder_bidi=True\n",
        "decoder_bidi=True #not supported True\n",
        "encoder_layers=1  #not supported>1\n",
        "decoder_layers=1\n",
        "\n",
        "# Arch. Question How to work with bidi and multiple layers? \n",
        "# currently, encoder combines with + (sum) bidi vectors. after 8 epocs of 100 batches(100 each) less then 1 recon_loss\n",
        "# multiple layers not supported\n",
        "\n",
        "\n",
        "en_sem = EncoderWrapper(EncoderRNN(len(TEXT.vocab),opt.max_sent_len, opt.semantics_dim,variable_lengths =variable_lengths,bidirectional = encoder_bidi,n_layers=encoder_layers,\n",
        "                                   input_dropout_p = 0.1 , dropout_p =0.0 , rnn_cell='gru'))\n",
        "                                   \n",
        "en_sty = EncoderWrapper(EncoderRNN(len(TEXT.vocab),opt.max_sent_len, opt.style_dim, variable_lengths = variable_lengths,bidirectional = encoder_bidi,n_layers=encoder_layers,\n",
        "                                   input_dropout_p = 0.1 , dropout_p =0.0,rnn_cell='gru'))\n",
        "\n",
        "decoder = DecoderRNN(len(TEXT.vocab),opt.max_sent_len, (1 if encoder_bidi else 1)*(opt.semantics_dim + opt.style_dim),sos_id=TEXT_TARGET.sos_id,eos_id=TEXT_TARGET.eos_id,\n",
        "                     bidirectional = decoder_bidi,n_layers=decoder_layers,\n",
        "                     input_dropout_p = 0.1 , dropout_p =0.0,rnn_cell='gru')\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "      \n",
        "adv_disc = nn.Sequential(\n",
        "  # input concat of two style\n",
        "  nn.Linear(2*opt.style_dim,30),\n",
        "  nn.PReLU(),\n",
        "  nn.Linear(30,20),\n",
        "  nn.PReLU(),\n",
        "  nn.Linear(20,1),\n",
        "  nn.Sigmoid() #depends on what we have as loss #Must be sigmoid, we apply later BCE\n",
        ")\n",
        "\n",
        "\n",
        "\n",
        "en_sem = T(en_sem)\n",
        "en_sty = T(en_sty)\n",
        "decoder =T(decoder)\n",
        "adv_disc = T(adv_disc)\n",
        "\n",
        "def train_gen() :\n",
        "  return iter(data.BucketIterator( dataset=ds_train, device=device,batch_size=32, sort_within_batch=True,sort_key=lambda x: len(x.sent_0))) \n",
        "\n",
        "\n",
        "\n",
        "merge_dim = 1 #1 before\n",
        "def test():\n",
        "  sample = next(train_gen())\n",
        "  \n",
        "  print (type(sample.sent_0))\n",
        "  in_var,in_len=sample.sent_0\n",
        "\n",
        "  #print ('length0',sample.sent_0[1])\n",
        "  #print ('length1',sample.sent_1[1])\n",
        "  sem_out = T(en_sem(sample.sent_0))\n",
        "  print ('result of en_sem',sem_out.shape)   #[1, 32, 20]\n",
        "  sty_out = T(en_sty(sample.sent_1))\n",
        "  print ('sty_out',sty_out.shape,\n",
        "        'concat',T(torch.cat([sty_out, sty_out],dim=merge_dim)).shape)\n",
        "  \n",
        "  merged = T(torch.cat([sty_out, sty_out],dim=merge_dim))\n",
        "  print ('merged1',merged.type(),merged.shape )\n",
        "  disc_out = T(adv_disc(merged))\n",
        "  print (disc_out.shape)\n",
        "\n",
        "  merged = T(torch.cat([sem_out,sty_out],dim=merge_dim))\n",
        "  merged.unsqueeze_(0)\n",
        "  print ('merged2',merged.shape)\n",
        "  decoder_outputs, _,_ = decoder(inputs=None,  # pass not None for teacher focring  (batch, seq_len, input_size)\n",
        "                            encoder_hidden=merged, #(num_layers * num_directions, batch_size, hidden_size)\n",
        "                            encoder_outputs = None, # pass not None for attention\n",
        "                            teacher_forcing_ratio=0 #range 0..1 , must pass inputs if >0\n",
        "                           ) \n",
        "  decoder_outputs = decoder_outputs\n",
        "  #**decoder_outputs** (seq_len, batch, vocab_size): list of tensors with size (batch_size, vocab_size) containing\n",
        "  #          the outputs of the decoding function.\n",
        "  print ('decoder_outputs',len(decoder_outputs),decoder_outputs[0].shape)\n",
        "\n",
        "\n",
        "  \n",
        "  \n",
        "test()\n",
        "\n",
        "opt.optimizer= 'adam'\n",
        "\n",
        "if opt.optimizer=='adam':\n",
        "  optimizer = torch.optim.Adam\n",
        "elif opt.optimizer=='adampre':\n",
        "  optimizer = AdamPre\n",
        "\n",
        "optimizer_first_time = True  #relevant only to AdamPre\n",
        "\n",
        "optimizer_en_sem = optimizer(en_sem.parameters(), opt.lr) #(, betas=(opt.beta1, 0.999))\n",
        "optimizer_en_sty = optimizer(en_sty.parameters(), opt.lr) #), betas=(opt.beta1, 0.999))\n",
        "optimizer_decoder = optimizer(decoder.parameters(), opt.lr) #)opt.lr), betas=(opt.beta1, 0.999))\n",
        "optimizer_adv_disc = optimizer(adv_disc.parameters(), opt.adv_disc_lr) ##), betas=(opt.beta1, 0.999))\n",
        "\n",
        "print (optimizer)  \n",
        "\n",
        " "
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'tuple'>\n",
            "result of en_sem torch.Size([32, 200])\n",
            "sty_out torch.Size([32, 60]) concat torch.Size([32, 120])\n",
            "merged1 torch.cuda.FloatTensor torch.Size([32, 120])\n",
            "torch.Size([32, 1])\n",
            "merged2 torch.Size([1, 32, 260])\n",
            "decoder_outputs 40 torch.Size([32, 45])\n",
            "<class 'torch.optim.adam.Adam'>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "N9QCEv1m8iSt",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# EVAL"
      ]
    },
    {
      "metadata": {
        "id": "I1CE35zP44Ez",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 181
        },
        "outputId": "4da4e8bb-c82f-49ee-b006-1ab15da47c45"
      },
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "def eval_sample(samples=3):\n",
        "  #back to eval mode\n",
        "  en_sty.eval()  # and not eval() mode\n",
        "  en_sem.eval()\n",
        "  decoder.eval()\n",
        "  adv_disc.eval()\n",
        "\n",
        "  eval_batch_generator = iter(data.BucketIterator( dataset=ds_eval, device=device,batch_size=32, sort_within_batch=False,sort_key=lambda x: len(x.sent_0))) \n",
        "  b = next(eval_batch_generator)\n",
        "  #b = next(training_batch_generator)\n",
        "  #rec loss of 0.4 means good style, half of chars correct (but half wrong)\n",
        "\n",
        "  sent0 = T(b.sent_0)\n",
        "  sent1 = T(b.sent_1)\n",
        "  sentX = T(b.sent_x)\n",
        "  \n",
        "  recon_target = b.sent_0_target  \n",
        "\n",
        "\n",
        "  h_sem0 = en_sem(sent0)\n",
        "  h_sem1 = en_sem(sent1)\n",
        "  h_semX = en_sem(sentX)\n",
        "  \n",
        "  h_sty0 = en_sty(sent0)\n",
        "  h_sty1 = en_sty(sent1)\n",
        "  h_styX = en_sty(sentX)\n",
        "  \n",
        "  recon_sem0_sty0, _,_ = decoder(inputs=None,  # pass not None for teacher focring  (batch, seq_len, input_size)\n",
        "                        #encoder_hidden=T(torch.cat([h_sem1,h_sty0],dim=1)).unsqueeze(0), #(num_layers * num_directions, batch_size, hidden_size)\n",
        "                        encoder_hidden=T(torch.cat([h_sem0,h_sty0],dim=merge_dim)).unsqueeze(0),#(num_layers * num_directions, batch_size, hidden_size)\n",
        "                        encoder_outputs = None, # pass not None for attention\n",
        "                        teacher_forcing_ratio=0 #range 0..1 , must pass inputs if >0\n",
        "                       ) \n",
        "  \n",
        "  \n",
        "  recon_semX_sty0, _,_ = decoder(inputs=None,  # pass not None for teacher focring  (batch, seq_len, input_size)\n",
        "                        #encoder_hidden=T(torch.cat([h_sem1,h_sty0],dim=1)).unsqueeze(0), #(num_layers * num_directions, batch_size, hidden_size)\n",
        "                        encoder_hidden=T(torch.cat([h_semX,h_sty0],dim=merge_dim)).unsqueeze(0),#(num_layers * num_directions, batch_size, hidden_size)\n",
        "                        encoder_outputs = None, # pass not None for attention\n",
        "                        teacher_forcing_ratio=0 #range 0..1 , must pass inputs if >0\n",
        "                       ) \n",
        "  \n",
        "  recon_semX_sty1, _,_ = decoder(inputs=None,  # pass not None for teacher focring  (batch, seq_len, input_size)\n",
        "                        encoder_hidden=T(torch.cat([h_semX,h_sty1],dim=merge_dim)).unsqueeze(0), #(num_layers * num_directions, batch_size, hidden_size)\n",
        "                        encoder_outputs = None, # pass not None for attention\n",
        "                        teacher_forcing_ratio=0 #range 0..1 , must pass inputs if >0\n",
        "                       ) \n",
        "  \n",
        "  recon_semX_sty1_tf1, _,_ = decoder(inputs=recon_target,  # pass not None for teacher focring  (batch, seq_len, input_size)\n",
        "                        encoder_hidden=T(torch.cat([h_semX,h_sty1],dim=merge_dim)).unsqueeze(0), #(num_layers * num_directions, batch_size, hidden_size)\n",
        "                        encoder_outputs = None, # pass not None for attention\n",
        "                        teacher_forcing_ratio=1 #range 0..1 , must pass inputs if >0\n",
        "                       ) \n",
        "\n",
        "  for i in range(samples):\n",
        "    print ('\\n%20s'%'sent0:', revers_vocab(TEXT_TARGET.vocab,sent0[0][i],''))\n",
        "    print ('%20s'%'sent0_targ:',revers_vocab(TEXT_TARGET.vocab,recon_target[i],''))\n",
        "    print ('%20s'%'sent1:',revers_vocab(TEXT_TARGET.vocab,sent1[0][i],''))\n",
        "    print ('%20s'%'sentX:',revers_vocab(TEXT_TARGET.vocab,sentX[0][i],''))\n",
        "\n",
        "    # recon_sent is a list of : batch x softmax array\n",
        "    tokens= (np.array(([N(torch.argmax(l, dim=1)[i]) for l in recon_sem0_sty0])))\n",
        "    print ('%20s'%'recon_sem0_sty0:[TF=0]',revers_vocab(TEXT_TARGET.vocab,tokens,''))\n",
        "\n",
        "    tokens= (np.array(([N(torch.argmax(l, dim=1)[i]) for l in recon_semX_sty0])))\n",
        "    print ('%20s'%'recon_semX_sty0:[TF=0]',revers_vocab(TEXT_TARGET.vocab,tokens,''))\n",
        "\n",
        "    tokens= (np.array(([N(torch.argmax(l, dim=1)[i]) for l in recon_semX_sty1])))\n",
        "    print ('%20s'%'recon_semX_sty1:[TF=0]',revers_vocab(TEXT_TARGET.vocab,tokens,''))\n",
        "    \n",
        "    tokens= (np.array(([N(torch.argmax(l, dim=1)[i]) for l in recon_semX_sty1_tf1])))\n",
        "    print ('%20s'%'recon_semX_sty1:[TF=1]',revers_vocab(TEXT_TARGET.vocab,tokens,''))\n",
        "  \n",
        "  en_sty.train()  # and not eval() mode\n",
        "  en_sem.train()\n",
        "  decoder.train()\n",
        "  adv_disc.train()\n",
        "    \n",
        "  \n",
        "  \n",
        "eval_sample(1)"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "              sent0: 08/November/1985 09:07:41\n",
            "         sent0_targ: <sos>08/November/1985 09:07:41<eos>\n",
            "              sent1: 08-Nov-1985 09.07.41.00<pad><pad>\n",
            "              sentX: 27/November/2079 01:27:44<pad>\n",
            "recon_sem0_sty0:[TF=0] <pad>on<sos>S:p/6e/6iby<eos>AF1OAm9<eos>5<sos>--Sc:p6/e/u688\n",
            "recon_semX_sty0:[TF=0] S888888888888888888888888888888888888888\n",
            "recon_semX_sty1:[TF=0] S S:p6/e/u688888888888888888888888888888\n",
            "recon_semX_sty1:[TF=1] S-<sos>eey8nppn<unk><sos>Ob<eos><sos>7llpp9p0<eos>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "XnxNY67yEtTt",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "d36b602e-46ba-4043-ed43-41804e0e96bb"
      },
      "cell_type": "code",
      "source": [
        "\n",
        "np.log(0.5)"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "-0.6931471805599453"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 39
        }
      ]
    },
    {
      "metadata": {
        "id": "GaVWTeleYkWk",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Train loop"
      ]
    },
    {
      "metadata": {
        "id": "_jDD-H1faFtq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 5401
        },
        "outputId": "3f2847b6-406a-4445-ea21-b8af206c6aac"
      },
      "cell_type": "code",
      "source": [
        "# --------- training funtions ------------------------------------\n",
        "def train(b,epoch=0):\n",
        "    # x[0] semantic0   , style0\n",
        "    # x[1] semantic0   , style1   \n",
        "    # x[2] semantic0orX, style0 (1/2 the time 0 , half X)\n",
        "\n",
        "    en_sty.zero_grad() \n",
        "    en_sem.zero_grad()\n",
        "    decoder.zero_grad()\n",
        "    \n",
        "    if opt.optimizer=='adampre':\n",
        "      optimizer_adv_disc.stepLookAhead()\n",
        "  \n",
        "\n",
        "    sent0 = b.sent_0\n",
        "    sent1 = b.sent_1\n",
        "    sentX = b.sent_x\n",
        "    recon_target = b.sent_0_target  #one-hot\n",
        "    \n",
        "    logger.debug(f'sent0 {sent0[0].shape} {sent0[1].shape}')    \n",
        "\n",
        "    ######### SIM LOSS #########\n",
        "    h_sem0 = en_sem(sent0) \n",
        "    h_sem1 = en_sem(sent1) \n",
        "\n",
        "    sim_loss=0\n",
        "    '''logger.debug(f'h_sem0 shape {h_sem0.shape}')\n",
        "    # if you want to use torch criterion, you need to copy the label and set it to not requreing gradiant\n",
        "    # so below is different than nn.MSELoss()(h_sem0,h_sem1.detach()). I wonder if only one get grad updates!\n",
        "    sim_loss = torch.sum(torch.pow(h_sem0- h_sem1,2),dim=1)\n",
        "    logger.debug(f'sem_loss: {h_sem0.shape} {h_sem1.shape} {sim_loss.shape} {sim_loss}')\n",
        "    sim_loss = torch.mean(sim_loss)\n",
        "    logger.debug(f'sem_loss: {h_sem0.shape} {h_sem1.shape} {sim_loss.shape} {sim_loss}')\n",
        "    '''\n",
        "    \n",
        "    \n",
        "    \n",
        "\n",
        "    ######### RECONSTRUCTION LOSS #########\n",
        "    # reconstruct sent0 from semantics of sent1 (==sem of sent0, different style), and style of sent0.\n",
        "    h_sty0 = en_sty(sent0)\n",
        "    merged= torch.cat([h_sem1,h_sty0],dim=merge_dim)\n",
        "    merged.unsqueeze_(0) #32x25 -> 1x32x25 . 1 is for one hidden-layer (not-stacked)\n",
        "    logger.debug(f'h_sem1.h_sty0 {h_sem1.shape} {h_sty0.shape,merged.shape}')\n",
        "    \n",
        "    \n",
        "    recon_sent0, _,_ = decoder(inputs=recon_target,  # pass not None for teacher focring  (batch, seq_len, input_size)\n",
        "                          encoder_hidden=merged, #(num_layers * num_directions, batch_size, hidden_size)\n",
        "                          encoder_outputs = None, # pass not None for attention\n",
        "                          teacher_forcing_ratio=1 #in(0, 1-random.random()* epoch * 0.1) #range 0..1 , must pass inputs if >0. as epochs increase, it's lower\n",
        "                         ) \n",
        "    #print('$'*10,'recon_sent0 length',len(recon_sent0),'each',recon_sent0[0].shape)\n",
        "    #rec_loss = nn.MSELoss()(recon_sent0,sent0)\n",
        "    # see impl https://github.com/IBM/pytorch-seq2seq/blob/master/seq2seq/loss/loss.py\n",
        "    acc_loss, norm_term=0,0\n",
        "    logger.debug(f'recon_target {recon_target.shape} while decoder outputs {len(recon_sent0)}')\n",
        "    #target shape [32, 26]  batch x words , actual len of 50\n",
        "    for step, step_output in enumerate(recon_sent0):\n",
        "      batch_size = recon_target.size(0)\n",
        "      #print('step_output at step ',step,step_output.shape,type(step_output))\n",
        "      outputs = step_output #step_output.contiguous().view(batch_size, -1)\n",
        "      \n",
        "      # what to do if output is too-long? decision here is to match only relevant parts\n",
        "      if step+1>=recon_target.size(1):  \n",
        "        #print ('breaking!!! at step',step)\n",
        "        break\n",
        "      gold = recon_target[:, step + 1] #tuple [0] is data. [1] is len\n",
        "      #print('output at step ',step,outputs.shape,type(outputs),'gold',gold.shape,type(gold))\n",
        "      curr_loss = nn.NLLLoss()(outputs, gold)\n",
        "      #logger.debug(f'loss for token {norm_term},{outputs.shape}, {gold.shape}, {curr_loss}')\n",
        "      acc_loss += curr_loss\n",
        "      norm_term += 1\n",
        "    rec_loss = acc_loss/norm_term\n",
        "    \n",
        "    \n",
        "    ######### ADV LOSS #########  TODO : willl it be better to use completely different sentences?\n",
        "    h_styX = en_sty(sentX)\n",
        "    adv_disc_p =  adv_disc(torch.cat([h_sty0,h_styX],dim=merge_dim))\n",
        "    #logger.debug (N(adv_disc_p[0:3].data).T)\n",
        "    adv_target = T(torch.FloatTensor(np.full(shape =(sent0[0].shape[0],1),fill_value=0.5)))\n",
        "    # the loss below is a parabula with min at log(0.5)=0.693... see documentation above\n",
        "    adv_disc_loss = nn.BCELoss()(adv_disc_p, adv_target) \n",
        "    logger.debug(f'### adv_disc_loss {N(adv_disc_p.data[:5]).T} target={N(adv_target.data[:5]).T} bce={adv_disc_loss}')\n",
        "    adv_disc_loss += np.log(0.5)  #np.log(0.5)=-0.693 , \n",
        "    logger.debug(f'    sanity test: on first step, you expect adv_disc_loss to be near zero')\n",
        "    \n",
        "    \n",
        "    ######### BACKWARD #########\n",
        "    # full loss\n",
        "    loss = rec_loss + sim_loss*opt.sem_sim_weight + opt.sd_weight*adv_disc_loss #rec_loss + sim_loss + opt.sd_weight*adv_disc_loss\n",
        "    loss.backward()\n",
        "\n",
        "    optimizer_en_sem.step()\n",
        "    optimizer_en_sty.step()\n",
        "    optimizer_decoder.step()\n",
        "    \n",
        "    # JUST FOR DEBUG DELETE THIS#####################\n",
        "    # JUST FOR DEBUG DELETE THIS#####################\n",
        "    # JUST FOR DEBUG DELETE THIS#####################\n",
        "    sim_loss = torch.sum(torch.pow(h_sem0- h_sem1,2),dim=1)\n",
        "    logger.debug(f'sem_loss: {h_sem0.shape} {h_sem1.shape} {sim_loss.shape} {sim_loss}')\n",
        "    sim_loss = torch.mean(sim_loss)\n",
        "    \n",
        "    \n",
        "    if opt.optimizer=='adampre':\n",
        "      optimizer_adv_disc.restoreStepLookAhead()\n",
        "\n",
        "    return N(sim_loss.data)*opt.sem_sim_weight, N(rec_loss.data) ,N(adv_disc_loss.data)*opt.sd_weight\n",
        "\n",
        "  \n",
        "def train_scene_discriminator(b):\n",
        "    global optimizer_first_time\n",
        "\n",
        "    sent0 = T(b.sent_0)\n",
        "    sentX = T(b.sent_x)\n",
        "    y = T(b.is_x_0)\n",
        "      \n",
        "    \n",
        "    adv_disc.zero_grad()\n",
        "    if opt.optimizer=='adampre' and not optimizer_first_time:\n",
        "      optimizer_decoder.stepLookAhead()\n",
        "      \n",
        "\n",
        "    h_sty0    = en_sty(sent0) \n",
        "    h_sty0or2 = en_sty(sentX)  #same style, same or different semantics with random chance\n",
        "    \n",
        "    merged = torch.cat([h_sty0, h_sty0or2],dim=merge_dim)\n",
        "    \n",
        "    logger.debug(f'merged {merged.shape}') #4x32xdim\n",
        "    out = adv_disc(merged) #\n",
        "    out = out.flatten()\n",
        "\n",
        "    #TODO: #Note BCELossWithLogits is faster and more stable, to use it remove sigmoid from network end\n",
        "    logger.debug(f'out {out.shape} y {y.shape}')\n",
        "    \n",
        "    \n",
        "    \n",
        "    #bce = nn.BCELoss()(out.flatten(), y.flatten()) #should wrapp in varaible? \n",
        "    bce = nn.BCELoss()(out, y) #should wrapp in varaible? \n",
        "    logger.debug('train_scene_discriminator {out} {y}')\n",
        "    \n",
        "    \n",
        "    bce.backward()\n",
        "    optimizer_adv_disc.step()\n",
        "    \n",
        "    if opt.optimizer=='adampre' and not optimizer_first_time:\n",
        "      optimizer_decoder.restoreStepLookAhead()\n",
        "    \n",
        "    optimizer_first_time = False\n",
        "    \n",
        "    \n",
        "    #print (out.shape) #torch.Size([16, 1])\n",
        "    acc =  np.round(N(out.detach()))==np.round(N(y))  #CHECK THIS DIMENSTIONS!!! \n",
        "    logger.debug(f'adv_disc out {out.shape} is_x_0 {y.shape}')\n",
        "    logger.debug(f'out {out.flatten()} y {y.flatten()} acc {acc} bce {bce.data}')\n",
        "    #print (acc.shape) #1,16\n",
        "    acc = acc.reshape(-1)#.float()\n",
        "    acc= acc.sum()/len(acc)\n",
        "    return N(bce.data), N(acc)\n",
        "  \n",
        "  \n",
        "\n",
        "def one_epoc(epoch):\n",
        "    #iter provides new epoc generator\n",
        "    training_batch_generator = iter(data.BucketIterator( dataset=ds_train, device=device,batch_size=32, sort_within_batch=False,sort_key=lambda x: len(x.sent_0))) \n",
        "\n",
        "    epoch_sim_loss, epoch_rec_loss, epoch_anti_disc_loss, epoch_sd_loss, epoch_sd_acc = 0, 0, 0, 0, 0\n",
        "\n",
        "    #training_batch_generator = iter(data.BucketIterator( dataset=ds, batch_size=opt.batch_size, sort_within_batch=False,sort_key=lambda x: len(x.sent_0))) \n",
        "    for i in range(opt.epoch_size):\n",
        "        #if i % 100==0 : print ('batch',i,'of',opt.epoch_size)\n",
        "        b = next(training_batch_generator)\n",
        "\n",
        "        # train scene discriminator\n",
        "        logger.debug (f'b_sent_0 {b.sent_0[0].shape}{b.sent_0[1].shape}')#TEXT.reverse(b.sent_0))\n",
        "\n",
        "        sd_loss, sd_acc = train_scene_discriminator(b)\n",
        "        epoch_sd_loss += sd_loss\n",
        "        epoch_sd_acc += sd_acc\n",
        "\n",
        "\n",
        "        # train main model\n",
        "        sim_loss, rec_loss, anti_disc_loss = train(b,epoch)\n",
        "          \n",
        "        epoch_sim_loss += sim_loss\n",
        "        epoch_rec_loss += rec_loss\n",
        "        epoch_anti_disc_loss += anti_disc_loss\n",
        "        \n",
        "        logger.setLevel(logging.INFO)\n",
        "    print('[%02d] rec loss: %.4f | sim loss: %.4f | anti_disc_loss: %.4f || scene disc %.4f %.3f%% ' % (epoch, epoch_rec_loss/opt.epoch_size, \n",
        "                epoch_sim_loss/opt.epoch_size, epoch_anti_disc_loss/opt.epoch_size,\n",
        "                epoch_sd_loss/opt.epoch_size, 100*epoch_sd_acc/opt.epoch_size))\n",
        "  \n",
        "\n",
        "# --------- training loop ------------------------------------\n",
        "opt.sem_sim_weight = 1\n",
        "opt.sd_weight=1 #0.1 is relativaly ok number, beta deafult. git to 0.2 cant reproduce\n",
        "opt.epocs=300\n",
        "opt.epoch_size=100\n",
        "opt.batch_size= 32 #anti-adv-loss will be noiser\n",
        "\n",
        "\n",
        "en_sty.train()  # and not eval() mode\n",
        "en_sem.train()\n",
        "decoder.train()\n",
        "adv_disc.train()\n",
        "\n",
        "logger = logging.getLogger()\n",
        "logger.setLevel(logging.DEBUG) #not debug\n",
        "epoc_count=0\n",
        "%time one_epoc(epoc_count)    \n",
        "epoc_count+=1\n",
        "\n",
        "#opt.lr\n",
        "for lr in [opt.lr/4,opt.lr/4,opt.lr/8,opt.lr/8,opt.lr/16,opt.lr/16]:\n",
        "  print ('lr',lr,opt.beta1)\n",
        "  optimizer_en_sem = optimizer(en_sem.parameters(), lr,  betas=(opt.beta1, 0.999))\n",
        "  optimizer_en_sty = optimizer(en_sty.parameters(), lr,  betas=(opt.beta1, 0.999))\n",
        "  optimizer_decoder = optimizer(decoder.parameters(),lr, betas=(opt.beta1, 0.999))\n",
        "  optimizer_adv_disc = torch.optim.SGD(adv_disc.parameters(),lr)#,betas=(opt.beta1, 0.999))\n",
        "\n",
        "  for epoch in range(0,16): \n",
        "    one_epoc(epoc_count)\n",
        "    epoc_count+=1\n",
        "  eval_sample(3)\n",
        "    \n",
        "\n",
        "print ('training loop done')\n",
        "# TODO: save the model\n",
        "# converge to 0.5 recon, but 1.6 adv loss: sd_weight !!! for lr in [opt.lr/4,opt.lr/4,opt.lr/8,opt.lr/8,opt.lr/16,opt.lr/16]: beta=0.5\n",
        "\n",
        "print('todo discriminator too stong!!!!!')\n",
        "\n",
        "print('todo LSTMMMM!!!!')\n",
        "\n"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "08:25:46 DEBUG:b_sent_0 torch.Size([32, 25])torch.Size([32])\n",
            "08:25:46 DEBUG:merged torch.Size([32, 120])\n",
            "08:25:46 DEBUG:out torch.Size([32]) y torch.Size([32])\n",
            "08:25:46 DEBUG:train_scene_discriminator {out} {y}\n",
            "08:25:46 DEBUG:adv_disc out torch.Size([32]) is_x_0 torch.Size([32])\n",
            "08:25:46 DEBUG:out tensor([0.4630, 0.4714, 0.4577, 0.4855, 0.4589, 0.4840, 0.4727, 0.4783, 0.4586,\n",
            "        0.4853, 0.4653, 0.4629, 0.4560, 0.4723, 0.4685, 0.4754, 0.4861, 0.4822,\n",
            "        0.4789, 0.4777, 0.4743, 0.4808, 0.4963, 0.4867, 0.4806, 0.4572, 0.4839,\n",
            "        0.4595, 0.4520, 0.4546, 0.4715, 0.4787],\n",
            "       device='cuda:0', grad_fn=<AsStridedBackward>) y tensor([0.8932, 1.1565, 0.8527, 0.1054, 0.9816, 0.7512, 0.9622, 1.0963, 0.2848,\n",
            "        0.0990, 0.7458, 0.0786, 0.9464, 0.1037, 0.2828, 0.1263, 0.7247, 0.9531,\n",
            "        0.0616, 0.7353, 0.2355, 0.2518, 0.9144, 0.8133, 0.2260, 1.0396, 0.0201,\n",
            "        1.0398, 0.1762, 0.9912, 0.8211, 0.7967], device='cuda:0') acc [False False False  True False False False False  True  True False  True\n",
            " False  True  True  True False False  True False  True  True False False\n",
            "  True False  True False  True False False False] bce 0.7097387909889221\n",
            "08:25:46 DEBUG:sent0 torch.Size([32, 25]) torch.Size([32])\n",
            "08:25:46 DEBUG:h_sem1.h_sty0 torch.Size([32, 200]) (torch.Size([32, 60]), torch.Size([1, 32, 260]))\n",
            "08:25:46 DEBUG:recon_target torch.Size([32, 27]) while decoder outputs 26\n",
            "08:25:46 DEBUG:### adv_disc_loss [[0.49163738 0.5184169  0.4916825  0.48103172 0.49000114]] target=[[0.5 0.5 0.5 0.5 0.5]] bce=0.693301796913147\n",
            "08:25:46 DEBUG:    sanity test: on first step, you expect adv_disc_loss to be near zero\n",
            "08:25:46 DEBUG:sem_loss: torch.Size([32, 200]) torch.Size([32, 200]) torch.Size([32]) tensor([31.4844,  7.3306, 28.5914, 81.4153,  8.4370, 31.0230, 34.9923, 46.2108,\n",
            "        44.2435, 55.7039, 19.4903, 50.7774, 32.0846, 40.4873, 29.6837, 44.9262,\n",
            "        58.1354, 22.7799, 95.4344, 23.6141, 40.3558, 33.7461, 59.2408, 69.5504,\n",
            "         9.4753, 28.5607, 15.0667,  9.1792, 22.5610, 38.5910, 60.2061, 19.4888],\n",
            "       device='cuda:0', grad_fn=<SumBackward1>)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[00] rec loss: 1.1575 | sim loss: 65.5535 | anti_disc_loss: 0.0109 || scene disc 0.6884 50.844% \n",
            "CPU times: user 8.19 s, sys: 1.98 s, total: 10.2 s\n",
            "Wall time: 10.2 s\n",
            "lr 0.000625 0.5\n",
            "[01] rec loss: 0.7128 | sim loss: 77.7365 | anti_disc_loss: 0.0040 || scene disc 0.6787 57.688% \n",
            "[02] rec loss: 0.6637 | sim loss: 73.8774 | anti_disc_loss: 0.0017 || scene disc 0.6851 56.500% \n",
            "[03] rec loss: 0.6062 | sim loss: 66.4171 | anti_disc_loss: 0.0013 || scene disc 0.6874 55.281% \n",
            "[04] rec loss: 0.5447 | sim loss: 64.9056 | anti_disc_loss: 0.0011 || scene disc 0.6875 56.469% \n",
            "[05] rec loss: 0.5044 | sim loss: 64.8337 | anti_disc_loss: 0.0010 || scene disc 0.6889 55.531% \n",
            "[06] rec loss: 0.4484 | sim loss: 64.6431 | anti_disc_loss: 0.0010 || scene disc 0.6906 54.438% \n",
            "[07] rec loss: 0.4039 | sim loss: 64.3896 | anti_disc_loss: 0.0010 || scene disc 0.6889 55.938% \n",
            "[08] rec loss: 0.3627 | sim loss: 62.2074 | anti_disc_loss: 0.0010 || scene disc 0.6890 55.094% \n",
            "[09] rec loss: 0.3184 | sim loss: 62.4155 | anti_disc_loss: 0.0011 || scene disc 0.6879 55.750% \n",
            "[10] rec loss: 0.2881 | sim loss: 61.2584 | anti_disc_loss: 0.0010 || scene disc 0.6891 55.625% \n",
            "[11] rec loss: 0.2660 | sim loss: 62.4861 | anti_disc_loss: 0.0011 || scene disc 0.6897 54.531% \n",
            "[12] rec loss: 0.2431 | sim loss: 64.4868 | anti_disc_loss: 0.0011 || scene disc 0.6882 55.750% \n",
            "[13] rec loss: 0.2185 | sim loss: 64.0029 | anti_disc_loss: 0.0012 || scene disc 0.6891 55.469% \n",
            "[14] rec loss: 0.2053 | sim loss: 63.4091 | anti_disc_loss: 0.0012 || scene disc 0.6897 54.625% \n",
            "[15] rec loss: 0.1863 | sim loss: 63.1884 | anti_disc_loss: 0.0013 || scene disc 0.6904 52.844% \n",
            "[16] rec loss: 0.1741 | sim loss: 61.3936 | anti_disc_loss: 0.0013 || scene disc 0.6883 54.656% \n",
            "\n",
            "              sent0: 04/December/1979 19:31:59\n",
            "         sent0_targ: <sos>04/December/1979 19:31:59<eos>\n",
            "              sent1: 04-Dec-1979 19.31.59.00<pad><pad>\n",
            "              sentX: 04/December/1979 19:31:59<pad>\n",
            "recon_sem0_sty0:[TF=0] 04/December/1997 19:39:52<eos><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad>\n",
            "recon_semX_sty0:[TF=0] 04/December/1997 19:39:52<eos><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad>\n",
            "recon_semX_sty1:[TF=0] 04-Dec-1997 19.39.58.00<eos><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad>\n",
            "recon_semX_sty1:[TF=1] 04-December/1999 19:31:52<eos>\n",
            "\n",
            "              sent0: 28-Aug-2056 19.03.44.00<pad><pad>\n",
            "         sent0_targ: <sos>28-Aug-2056 19.03.44.00<eos><pad><pad>\n",
            "              sent1: August 28 56 19:03:44<pad><pad><pad><pad>\n",
            "              sentX: 09-May-2055 00.30.26.00<pad><pad><pad>\n",
            "recon_sem0_sty0:[TF=0] 28-Aug-2059 16.30.49.00<eos><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad>\n",
            "recon_semX_sty0:[TF=0] 20-May-2055 00.36.52.00<eos><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad>\n",
            "recon_semX_sty1:[TF=0] May 09 50 06:30:52<eos><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad>\n",
            "recon_semX_sty1:[TF=1] M5MMugu2055 00000.00.00<eos><pad><pad>\n",
            "\n",
            "              sent0: May 19 2041 11:06:29<pad><pad><pad><pad><pad>\n",
            "         sent0_targ: <sos>May 19 2041 11:06:29<eos><pad><pad><pad><pad><pad>\n",
            "              sent1: 19/May/2041 11:06:29<pad><pad><pad><pad><pad>\n",
            "              sentX: May 19 2041 11:06:29<pad><pad><pad><pad><pad><pad>\n",
            "recon_sem0_sty0:[TF=0] May 19 2041 16:10:19<eos><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad>\n",
            "recon_semX_sty0:[TF=0] May 19 2041 16:10:19<eos><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad>\n",
            "recon_semX_sty1:[TF=0] 19/May/2049 11:06:22<eos><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad>\n",
            "recon_semX_sty1:[TF=1] 1ay 19/2041 19:09:22<eos><pad><pad><pad><pad><pad>\n",
            "lr 0.000625 0.5\n",
            "[17] rec loss: 0.1536 | sim loss: 62.9010 | anti_disc_loss: 0.0014 || scene disc 0.6889 54.000% \n",
            "[18] rec loss: 0.1426 | sim loss: 60.3811 | anti_disc_loss: 0.0014 || scene disc 0.6880 55.094% \n",
            "[19] rec loss: 0.1368 | sim loss: 60.7555 | anti_disc_loss: 0.0015 || scene disc 0.6885 55.156% \n",
            "[20] rec loss: 0.1268 | sim loss: 61.0530 | anti_disc_loss: 0.0015 || scene disc 0.6885 55.594% \n",
            "[21] rec loss: 0.1174 | sim loss: 62.2613 | anti_disc_loss: 0.0016 || scene disc 0.6882 54.719% \n",
            "[22] rec loss: 0.1096 | sim loss: 62.4961 | anti_disc_loss: 0.0016 || scene disc 0.6890 55.031% \n",
            "[23] rec loss: 0.1055 | sim loss: 63.3897 | anti_disc_loss: 0.0016 || scene disc 0.6864 55.938% \n",
            "[24] rec loss: 0.0982 | sim loss: 61.8593 | anti_disc_loss: 0.0015 || scene disc 0.6891 54.125% \n",
            "[25] rec loss: 0.0894 | sim loss: 62.4228 | anti_disc_loss: 0.0013 || scene disc 0.6902 54.094% \n",
            "[26] rec loss: 0.0865 | sim loss: 62.8078 | anti_disc_loss: 0.0009 || scene disc 0.6891 54.250% \n",
            "[27] rec loss: 0.0848 | sim loss: 64.3035 | anti_disc_loss: 0.0009 || scene disc 0.6890 55.594% \n",
            "[28] rec loss: 0.0788 | sim loss: 63.2065 | anti_disc_loss: 0.0007 || scene disc 0.6888 54.812% \n",
            "[29] rec loss: 0.0717 | sim loss: 61.3950 | anti_disc_loss: 0.0008 || scene disc 0.6892 54.688% \n",
            "[30] rec loss: 0.0676 | sim loss: 61.1974 | anti_disc_loss: 0.0007 || scene disc 0.6880 56.562% \n",
            "[31] rec loss: 0.0675 | sim loss: 64.0805 | anti_disc_loss: 0.0009 || scene disc 0.6885 54.969% \n",
            "[32] rec loss: 0.0685 | sim loss: 62.1604 | anti_disc_loss: 0.0009 || scene disc 0.6895 53.781% \n",
            "\n",
            "              sent0: January 01 52 20:36:56<pad><pad><pad>\n",
            "         sent0_targ: <sos>January 01 52 20:36:56<eos><pad><pad><pad>\n",
            "              sent1: 01-Jan-2052 20.36.56.00<pad><pad>\n",
            "              sentX: January 01 52 20:36:56<pad><pad><pad><pad>\n",
            "recon_sem0_sty0:[TF=0] January 01 52 20:36:55<eos><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad>\n",
            "recon_semX_sty0:[TF=0] January 01 52 20:36:55<eos><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad>\n",
            "recon_semX_sty1:[TF=0] 01-Jan-2052 20.36.52.00<eos><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad>\n",
            "recon_semX_sty1:[TF=1] 00n-ar- 01 22 20:36:52<eos><pad><pad><pad>\n",
            "\n",
            "              sent0: 07/11/1993 02:02:38<pad><pad><pad><pad><pad><pad>\n",
            "         sent0_targ: <sos>07/11/1993 02:02:38<eos><pad><pad><pad><pad><pad><pad>\n",
            "              sent1: Jul 11 1993 02:02:38<pad><pad><pad><pad><pad>\n",
            "              sentX: 01/14/2022 06:11:59<pad><pad><pad><pad><pad><pad><pad>\n",
            "recon_sem0_sty0:[TF=0] 07/11/1993 02:02:38<eos><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad>\n",
            "recon_semX_sty0:[TF=0] 04/14/2015 02:13:16<eos><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad>\n",
            "recon_semX_sty1:[TF=0] Jan 14 2012 01:23:19<eos><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad>\n",
            "recon_semX_sty1:[TF=1] J4/14/2922 22:11:11<eos><pad><pad><pad><pad><pad><pad>\n",
            "\n",
            "              sent0: April 23 89 22:27:17<pad><pad><pad><pad><pad>\n",
            "         sent0_targ: <sos>April 23 89 22:27:17<eos><pad><pad><pad><pad><pad>\n",
            "              sent1: 23-Apr-1989 22.27.17.00<pad><pad>\n",
            "              sentX: April 23 89 22:27:17<pad><pad><pad><pad><pad><pad>\n",
            "recon_sem0_sty0:[TF=0] April 23 89 22:27:10<eos><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad>\n",
            "recon_semX_sty0:[TF=0] April 23 89 22:27:10<eos><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad>\n",
            "recon_semX_sty1:[TF=0] 23-Apr-1989 22.27.10.00<eos><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad>\n",
            "recon_semX_sty1:[TF=1] 2pril 23 82 22:27:10<eos><pad><pad><pad><pad><pad>\n",
            "lr 0.0003125 0.5\n",
            "[33] rec loss: 0.0501 | sim loss: 62.3068 | anti_disc_loss: 0.0009 || scene disc 0.6895 53.344% \n",
            "[34] rec loss: 0.0485 | sim loss: 63.2786 | anti_disc_loss: 0.0008 || scene disc 0.6891 54.469% \n",
            "[35] rec loss: 0.0461 | sim loss: 62.8077 | anti_disc_loss: 0.0007 || scene disc 0.6895 54.281% \n",
            "[36] rec loss: 0.0452 | sim loss: 62.1175 | anti_disc_loss: 0.0007 || scene disc 0.6887 56.031% \n",
            "[37] rec loss: 0.0431 | sim loss: 60.4238 | anti_disc_loss: 0.0008 || scene disc 0.6894 54.250% \n",
            "[38] rec loss: 0.0383 | sim loss: 59.3952 | anti_disc_loss: 0.0008 || scene disc 0.6887 54.094% \n",
            "[39] rec loss: 0.0392 | sim loss: 59.5250 | anti_disc_loss: 0.0008 || scene disc 0.6893 54.594% \n",
            "[40] rec loss: 0.0379 | sim loss: 60.1736 | anti_disc_loss: 0.0008 || scene disc 0.6892 53.219% \n",
            "[41] rec loss: 0.0379 | sim loss: 60.9245 | anti_disc_loss: 0.0009 || scene disc 0.6892 53.250% \n",
            "[42] rec loss: 0.0357 | sim loss: 61.1768 | anti_disc_loss: 0.0008 || scene disc 0.6890 53.219% \n",
            "[43] rec loss: 0.0356 | sim loss: 60.6441 | anti_disc_loss: 0.0009 || scene disc 0.6891 53.125% \n",
            "[44] rec loss: 0.0351 | sim loss: 61.3860 | anti_disc_loss: 0.0009 || scene disc 0.6884 54.406% \n",
            "[45] rec loss: 0.0334 | sim loss: 61.3130 | anti_disc_loss: 0.0009 || scene disc 0.6891 52.219% \n",
            "[46] rec loss: 0.0334 | sim loss: 60.4520 | anti_disc_loss: 0.0009 || scene disc 0.6881 53.062% \n",
            "[47] rec loss: 0.0345 | sim loss: 60.9566 | anti_disc_loss: 0.0009 || scene disc 0.6888 52.625% \n",
            "[48] rec loss: 0.0329 | sim loss: 59.8499 | anti_disc_loss: 0.0010 || scene disc 0.6883 55.156% \n",
            "\n",
            "              sent0: September 25 06 12:14:02<pad>\n",
            "         sent0_targ: <sos>September 25 06 12:14:02<eos><pad>\n",
            "              sent1: 25-Sep-2006 12.14.02.00<pad><pad><pad>\n",
            "              sentX: September 25 06 12:14:02<pad>\n",
            "recon_sem0_sty0:[TF=0] September 25 06 12:14:01<eos><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad>\n",
            "recon_semX_sty0:[TF=0] September 25 06 12:14:01<eos><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad>\n",
            "recon_semX_sty1:[TF=0] 25-Sep-2006 12.14.22.00<eos><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad>\n",
            "recon_semX_sty1:[TF=1] 2eptember 25 02:12:24:02<eos><pad>\n",
            "\n",
            "              sent0: 01/14/1982 01:35:44<pad><pad><pad><pad><pad><pad>\n",
            "         sent0_targ: <sos>01/14/1982 01:35:44<eos><pad><pad><pad><pad><pad><pad>\n",
            "              sent1: 14-Jan-1982 01.35.44.00<pad><pad><pad>\n",
            "              sentX: 06/29/2060 03:26:23<pad><pad><pad><pad><pad><pad>\n",
            "recon_sem0_sty0:[TF=0] 01/14/1982 01:35:43<eos><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad>\n",
            "recon_semX_sty0:[TF=0] 01/29/1960 02:36:46<eos><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad>\n",
            "recon_semX_sty1:[TF=0] 19-Jun-2060 06.23.34.00<eos><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad>\n",
            "recon_semX_sty1:[TF=1] 19-J962900 03:36:26<eos><pad><pad><pad><pad><pad><pad>\n",
            "\n",
            "              sent0: 06/28/2001 08:14:32<pad><pad><pad><pad><pad><pad>\n",
            "         sent0_targ: <sos>06/28/2001 08:14:32<eos><pad><pad><pad><pad><pad><pad>\n",
            "              sent1: June 28 01 08:14:32<pad><pad><pad><pad><pad><pad><pad>\n",
            "              sentX: 05/17/1988 07:59:02<pad><pad><pad><pad><pad><pad>\n",
            "recon_sem0_sty0:[TF=0] 06/28/2001 08:14:31<eos><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad>\n",
            "recon_semX_sty0:[TF=0] 07/17/2088 07:09:52<eos><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad>\n",
            "recon_semX_sty1:[TF=0] May 17 80 07:29:31<eos><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad>\n",
            "recon_semX_sty1:[TF=1] M7/M7 1088 07:29:37<eos><pad><pad><pad><pad><pad><pad>\n",
            "lr 0.0003125 0.5\n",
            "[49] rec loss: 0.0297 | sim loss: 60.5821 | anti_disc_loss: 0.0011 || scene disc 0.6881 52.500% \n",
            "[50] rec loss: 0.0294 | sim loss: 58.2890 | anti_disc_loss: 0.0010 || scene disc 0.6889 52.344% \n",
            "[51] rec loss: 0.0283 | sim loss: 59.7970 | anti_disc_loss: 0.0011 || scene disc 0.6890 51.938% \n",
            "[52] rec loss: 0.0287 | sim loss: 60.5641 | anti_disc_loss: 0.0011 || scene disc 0.6889 51.312% \n",
            "[53] rec loss: 0.0267 | sim loss: 60.3563 | anti_disc_loss: 0.0011 || scene disc 0.6886 50.906% \n",
            "[54] rec loss: 0.0267 | sim loss: 58.7482 | anti_disc_loss: 0.0011 || scene disc 0.6882 51.719% \n",
            "[55] rec loss: 0.0237 | sim loss: 60.8238 | anti_disc_loss: 0.0012 || scene disc 0.6891 50.344% \n",
            "[56] rec loss: 0.0249 | sim loss: 59.7800 | anti_disc_loss: 0.0012 || scene disc 0.6869 52.500% \n",
            "[57] rec loss: 0.0257 | sim loss: 58.4959 | anti_disc_loss: 0.0013 || scene disc 0.6865 52.219% \n",
            "[58] rec loss: 0.0249 | sim loss: 58.9895 | anti_disc_loss: 0.0015 || scene disc 0.6869 51.281% \n",
            "[59] rec loss: 0.0230 | sim loss: 60.1151 | anti_disc_loss: 0.0015 || scene disc 0.6871 50.469% \n",
            "[60] rec loss: 0.0209 | sim loss: 59.4453 | anti_disc_loss: 0.0015 || scene disc 0.6871 51.188% \n",
            "[61] rec loss: 0.0235 | sim loss: 59.0011 | anti_disc_loss: 0.0016 || scene disc 0.6870 51.562% \n",
            "[62] rec loss: 0.0207 | sim loss: 58.8833 | anti_disc_loss: 0.0017 || scene disc 0.6894 49.344% \n",
            "[63] rec loss: 0.0214 | sim loss: 60.0873 | anti_disc_loss: 0.0017 || scene disc 0.6875 50.406% \n",
            "[64] rec loss: 0.0219 | sim loss: 57.8540 | anti_disc_loss: 0.0018 || scene disc 0.6865 51.500% \n",
            "\n",
            "              sent0: Feb 08 2091 06:52:23<pad><pad><pad><pad><pad><pad>\n",
            "         sent0_targ: <sos>Feb 08 2091 06:52:23<eos><pad><pad><pad><pad><pad><pad>\n",
            "              sent1: 08-Feb-2091 06.52.23.00<pad><pad>\n",
            "              sentX: Dec 10 1980 10:13:41<pad><pad><pad><pad><pad><pad>\n",
            "recon_sem0_sty0:[TF=0] Feb 08 2091 06:52:25<eos><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad>\n",
            "recon_semX_sty0:[TF=0] Dec 10 2080 16:40:13<eos><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad>\n",
            "recon_semX_sty1:[TF=0] 08-Dec-2008 10.43.10.00<eos><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad>\n",
            "recon_semX_sty1:[TF=1] 0ebr11 1001 11:11:18<eos><pad><pad><pad><pad><pad><pad>\n",
            "\n",
            "              sent0: 06/October/2078 02:19:23<pad><pad>\n",
            "         sent0_targ: <sos>06/October/2078 02:19:23<eos><pad><pad>\n",
            "              sent1: 06-Oct-2078 02.19.23.00<pad><pad>\n",
            "              sentX: 06/October/2078 02:19:23<pad><pad>\n",
            "recon_sem0_sty0:[TF=0] 06/October/2078 02:19:23<eos><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad>\n",
            "recon_semX_sty0:[TF=0] 06/October/2078 02:19:23<eos><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad>\n",
            "recon_semX_sty1:[TF=0] 06-Oct-2078 02.19.23.00<eos><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad>\n",
            "recon_semX_sty1:[TF=1] 06-October-2078 02:19:23<eos><pad><pad>\n",
            "\n",
            "              sent0: 01-Mar-2032 12.24.32.00<pad><pad><pad>\n",
            "         sent0_targ: <sos>01-Mar-2032 12.24.32.00<eos><pad><pad><pad>\n",
            "              sent1: March 01 12:24:32 2032<pad><pad><pad>\n",
            "              sentX: 01-Mar-2032 12.24.32.00<pad><pad><pad>\n",
            "recon_sem0_sty0:[TF=0] 01-Mar-2032 12.24.31.00<eos><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad>\n",
            "recon_semX_sty0:[TF=0] 01-Mar-2032 12.24.31.00<eos><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad>\n",
            "recon_semX_sty1:[TF=0] March 01 12:24:31 2023<eos><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad>\n",
            "recon_semX_sty1:[TF=1] MMMMar-2022 12.24.31.00<eos><pad><pad><pad>\n",
            "lr 0.00015625 0.5\n",
            "[65] rec loss: 0.0176 | sim loss: 58.2708 | anti_disc_loss: 0.0017 || scene disc 0.6876 51.031% \n",
            "[66] rec loss: 0.0157 | sim loss: 58.2311 | anti_disc_loss: 0.0018 || scene disc 0.6874 50.281% \n",
            "[67] rec loss: 0.0155 | sim loss: 58.5057 | anti_disc_loss: 0.0018 || scene disc 0.6869 51.188% \n",
            "[68] rec loss: 0.0150 | sim loss: 58.5299 | anti_disc_loss: 0.0018 || scene disc 0.6874 49.812% \n",
            "[69] rec loss: 0.0134 | sim loss: 58.5562 | anti_disc_loss: 0.0017 || scene disc 0.6876 50.000% \n",
            "[70] rec loss: 0.0138 | sim loss: 57.3530 | anti_disc_loss: 0.0018 || scene disc 0.6890 49.312% \n",
            "[71] rec loss: 0.0145 | sim loss: 57.7139 | anti_disc_loss: 0.0018 || scene disc 0.6872 51.188% \n",
            "[72] rec loss: 0.0133 | sim loss: 58.0189 | anti_disc_loss: 0.0018 || scene disc 0.6855 52.438% \n",
            "[73] rec loss: 0.0127 | sim loss: 58.1571 | anti_disc_loss: 0.0018 || scene disc 0.6871 50.219% \n",
            "[74] rec loss: 0.0125 | sim loss: 58.1065 | anti_disc_loss: 0.0018 || scene disc 0.6881 49.719% \n",
            "[75] rec loss: 0.0130 | sim loss: 58.2540 | anti_disc_loss: 0.0018 || scene disc 0.6874 50.281% \n",
            "[76] rec loss: 0.0125 | sim loss: 57.9477 | anti_disc_loss: 0.0018 || scene disc 0.6876 50.094% \n",
            "[77] rec loss: 0.0128 | sim loss: 56.8939 | anti_disc_loss: 0.0017 || scene disc 0.6880 49.906% \n",
            "[78] rec loss: 0.0124 | sim loss: 56.7674 | anti_disc_loss: 0.0018 || scene disc 0.6869 50.781% \n",
            "[79] rec loss: 0.0127 | sim loss: 57.5065 | anti_disc_loss: 0.0018 || scene disc 0.6881 49.719% \n",
            "[80] rec loss: 0.0128 | sim loss: 57.0623 | anti_disc_loss: 0.0018 || scene disc 0.6877 49.750% \n",
            "\n",
            "              sent0: 04/12/1971 07:21:53<pad><pad><pad><pad><pad><pad>\n",
            "         sent0_targ: <sos>04/12/1971 07:21:53<eos><pad><pad><pad><pad><pad><pad>\n",
            "              sent1: 12-Apr-1971 07.21.53.00<pad><pad>\n",
            "              sentX: 03/19/2056 05:34:41<pad><pad><pad><pad><pad><pad><pad>\n",
            "recon_sem0_sty0:[TF=0] 04/12/1971 07:21:55<eos><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad>\n",
            "recon_semX_sty0:[TF=0] 01/19/1956 05:12:43<eos><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad>\n",
            "recon_semX_sty1:[TF=0] 19-Mar-1956 05.12.43.00<eos><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad>\n",
            "recon_semX_sty1:[TF=1] 11-M9-M955 05:25:55<eos><pad><pad><pad><pad><pad><pad>\n",
            "\n",
            "              sent0: Aug 04 1978 21:35:08<pad><pad><pad><pad><pad>\n",
            "         sent0_targ: <sos>Aug 04 1978 21:35:08<eos><pad><pad><pad><pad><pad>\n",
            "              sent1: 08/04/1978 21:35:08<pad><pad><pad><pad><pad><pad>\n",
            "              sentX: Aug 04 1978 21:35:08<pad><pad><pad><pad><pad><pad>\n",
            "recon_sem0_sty0:[TF=0] Aug 04 1978 21:35:07<eos><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad>\n",
            "recon_semX_sty0:[TF=0] Aug 04 1978 21:35:07<eos><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad>\n",
            "recon_semX_sty1:[TF=0] 08/04/1978 21:35:07<eos><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad>\n",
            "recon_semX_sty1:[TF=1] 0ug 04 1978 21:35:07<eos><pad><pad><pad><pad><pad>\n",
            "\n",
            "              sent0: June 13 93 02:49:44<pad><pad><pad><pad><pad><pad>\n",
            "         sent0_targ: <sos>June 13 93 02:49:44<eos><pad><pad><pad><pad><pad><pad>\n",
            "              sent1: Jun 13 2093 02:49:44<pad><pad><pad><pad><pad>\n",
            "              sentX: August 05 15 19:45:02<pad><pad><pad><pad><pad>\n",
            "recon_sem0_sty0:[TF=0] June 13 93 02:49:49<eos><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad>\n",
            "recon_semX_sty0:[TF=0] August 05 15 19:40:55<eos><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad>\n",
            "recon_semX_sty1:[TF=0] Aug 05 2015 19:40:55<eos><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad>\n",
            "recon_semX_sty1:[TF=1] Aul  00 22 11:41:55<eos><pad><pad><pad><pad><pad><pad>\n",
            "lr 0.00015625 0.5\n",
            "[81] rec loss: 0.0118 | sim loss: 57.5466 | anti_disc_loss: 0.0018 || scene disc 0.6870 50.500% \n",
            "[82] rec loss: 0.0116 | sim loss: 58.1737 | anti_disc_loss: 0.0018 || scene disc 0.6870 49.812% \n",
            "[83] rec loss: 0.0121 | sim loss: 57.7232 | anti_disc_loss: 0.0019 || scene disc 0.6864 51.781% \n",
            "[84] rec loss: 0.0113 | sim loss: 57.2060 | anti_disc_loss: 0.0019 || scene disc 0.6869 50.594% \n",
            "[85] rec loss: 0.0109 | sim loss: 57.4076 | anti_disc_loss: 0.0019 || scene disc 0.6894 48.219% \n",
            "[86] rec loss: 0.0103 | sim loss: 57.6613 | anti_disc_loss: 0.0018 || scene disc 0.6873 50.812% \n",
            "[87] rec loss: 0.0105 | sim loss: 58.9928 | anti_disc_loss: 0.0020 || scene disc 0.6862 51.062% \n",
            "[88] rec loss: 0.0103 | sim loss: 57.8152 | anti_disc_loss: 0.0019 || scene disc 0.6868 50.281% \n",
            "[89] rec loss: 0.0098 | sim loss: 56.6795 | anti_disc_loss: 0.0020 || scene disc 0.6865 50.906% \n",
            "[90] rec loss: 0.0118 | sim loss: 57.1790 | anti_disc_loss: 0.0020 || scene disc 0.6875 50.250% \n",
            "[91] rec loss: 0.0108 | sim loss: 56.8327 | anti_disc_loss: 0.0021 || scene disc 0.6868 50.375% \n",
            "[92] rec loss: 0.0102 | sim loss: 56.4528 | anti_disc_loss: 0.0020 || scene disc 0.6879 49.344% \n",
            "[93] rec loss: 0.0115 | sim loss: 56.4072 | anti_disc_loss: 0.0021 || scene disc 0.6869 50.281% \n",
            "[94] rec loss: 0.0099 | sim loss: 56.3643 | anti_disc_loss: 0.0022 || scene disc 0.6882 49.375% \n",
            "[95] rec loss: 0.0095 | sim loss: 56.5277 | anti_disc_loss: 0.0022 || scene disc 0.6877 49.531% \n",
            "[96] rec loss: 0.0098 | sim loss: 56.9541 | anti_disc_loss: 0.0022 || scene disc 0.6876 49.406% \n",
            "\n",
            "              sent0: February 22 05:50:56 2016\n",
            "         sent0_targ: <sos>February 22 05:50:56 2016<eos>\n",
            "              sent1: Feb 22 2016 05:50:56<pad><pad><pad><pad><pad>\n",
            "              sentX: September 05 20:44:11 2075\n",
            "recon_sem0_sty0:[TF=0] February 22 05:50:58 2061<eos><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad>\n",
            "recon_semX_sty0:[TF=0] September 05 20:44:16 2075<eos><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad>\n",
            "recon_semX_sty1:[TF=0] Sep 05 2075 20:44:19<eos><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad>\n",
            "recon_semX_sty1:[TF=1] Seb  ary 00 07 42 44414444\n",
            "\n",
            "              sent0: 03/06/2005 07:12:02<pad><pad><pad><pad><pad><pad>\n",
            "         sent0_targ: <sos>03/06/2005 07:12:02<eos><pad><pad><pad><pad><pad><pad>\n",
            "              sent1: 06-Mar-2005 07.12.02.00<pad><pad>\n",
            "              sentX: 03/06/2005 07:12:02<pad><pad><pad><pad><pad><pad><pad>\n",
            "recon_sem0_sty0:[TF=0] 03/06/2005 07:12:01<eos><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad>\n",
            "recon_semX_sty0:[TF=0] 03/06/2005 07:12:01<eos><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad>\n",
            "recon_semX_sty1:[TF=0] 06-Mar-2005 07.12.01.00<eos><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad>\n",
            "recon_semX_sty1:[TF=1] 06-M6-2005 07:12:01<eos><pad><pad><pad><pad><pad><pad>\n",
            "\n",
            "              sent0: Feb 23 2004 19:44:05<pad><pad><pad><pad><pad>\n",
            "         sent0_targ: <sos>Feb 23 2004 19:44:05<eos><pad><pad><pad><pad><pad>\n",
            "              sent1: 02/23/2004 19:44:05<pad><pad><pad><pad><pad><pad>\n",
            "              sentX: Feb 23 2004 19:44:05<pad><pad><pad><pad><pad><pad>\n",
            "recon_sem0_sty0:[TF=0] Feb 23 2004 19:44:04<eos><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad>\n",
            "recon_semX_sty0:[TF=0] Feb 23 2004 19:44:04<eos><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad>\n",
            "recon_semX_sty1:[TF=0] 02/23/2004 19:44:04<eos><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad>\n",
            "recon_semX_sty1:[TF=1] 0eb 23 2004 19:44:04<eos><pad><pad><pad><pad><pad>\n",
            "training loop done\n",
            "todo discriminator too stong!!!!!\n",
            "todo LSTMMMM!!!!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "m5aLVfuOvoMU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 973
        },
        "outputId": "9b869364-f834-4e03-99fb-85200e2c9aa7"
      },
      "cell_type": "code",
      "source": [
        "en_sty.train()  # and not eval() mode\n",
        "en_sem.train()\n",
        "decoder.train()\n",
        "adv_disc.train()\n",
        "for lr in [opt.lr/16,opt.lr/16]:\n",
        "  print ('lr',lr)\n",
        "  optimizer_en_sem = optimizer(en_sem.parameters(), lr) #(, betas=(opt.beta1, 0.999))\n",
        "  optimizer_en_sty = optimizer(en_sty.parameters(), lr) #), betas=(opt.beta1, 0.999))\n",
        "  optimizer_decoder = optimizer(decoder.parameters(), lr) #)opt.lr), betas=(opt.beta1, 0.999))\n",
        "  optimizer_adv_disc = optimizer(adv_disc.parameters(), lr=lr )#opt.adv_disc_lr) ##), betas=(opt.beta1, 0.999))\n",
        "\n",
        "  for epoch in range(0,8): \n",
        "    #NOT ADV\n",
        "    #0.01 from high to .4 in few epocs\n",
        "    #0.0025 from 0.4 down to 0.2 rec-loss (30 epocs of 100)\n",
        "    #0.00125 from 0.2 down to 0.158  rec-loss (30 epocs of 100)\n",
        "    #0.000625 from 0.158 to 0.135\n",
        "    \n",
        "    #ADV: \n",
        "    #0.01 till 0.67\n",
        "    #0.0025 till 0.58\n",
        "    #0.00125 till 0.5\n",
        "    #0.000625 till \n",
        "    \n",
        "    one_epoc(epoc_count)\n",
        "    epoc_count+=1"
      ],
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "lr 0.000625\n",
            "[18] rec loss: 0.2826 | sim loss: 0.0000 | anti_disc_loss: 0.1819 || scene disc 0.3959 93.312% \n",
            "[19] rec loss: 0.2787 | sim loss: 0.0000 | anti_disc_loss: 0.1815 || scene disc 0.4076 93.812% \n",
            "[20] rec loss: 0.2809 | sim loss: 0.0000 | anti_disc_loss: 0.1807 || scene disc 0.3995 92.969% \n",
            "[21] rec loss: 0.2778 | sim loss: 0.0000 | anti_disc_loss: 0.1821 || scene disc 0.3969 93.656% \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-81-4dc306f6e3ec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0;31m#0.000625 till\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m     \u001b[0mone_epoc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoc_count\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m     \u001b[0mepoc_count\u001b[0m\u001b[0;34m+=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-80-365d90735cb7>\u001b[0m in \u001b[0;36mone_epoc\u001b[0;34m(epoch)\u001b[0m\n\u001b[1;32m    157\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    158\u001b[0m         \u001b[0;31m# train main model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 159\u001b[0;31m         \u001b[0msim_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrec_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0manti_disc_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    160\u001b[0m         \u001b[0mepoch_sim_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0msim_loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    161\u001b[0m         \u001b[0mepoch_rec_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mrec_loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-80-365d90735cb7>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(b, epoch)\u001b[0m\n\u001b[1;32m     41\u001b[0m                           \u001b[0mencoder_hidden\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmerged\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;31m#(num_layers * num_directions, batch_size, hidden_size)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m                           \u001b[0mencoder_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;31m# pass not None for attention\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m                           \u001b[0mteacher_forcing_ratio\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;31m#in(0, 1-random.random()* epoch * 0.1) #range 0..1 , must pass inputs if >0. as epochs increase, it's lower\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     44\u001b[0m                          ) \n\u001b[1;32m     45\u001b[0m     \u001b[0;31m#print('$'*10,'recon_sent0 length',len(recon_sent0),'each',recon_sent0[0].shape)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    475\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    476\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 477\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    478\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    479\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/seq2seq/models/DecoderRNN.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, inputs, encoder_hidden, encoder_outputs, function, teacher_forcing_ratio)\u001b[0m\n\u001b[1;32m    149\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    150\u001b[0m                     \u001b[0mstep_attn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 151\u001b[0;31m                 \u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstep_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstep_attn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    152\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    153\u001b[0m             \u001b[0mdecoder_input\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/seq2seq/models/DecoderRNN.py\u001b[0m in \u001b[0;36mdecode\u001b[0;34m(step, step_output, step_attn)\u001b[0m\n\u001b[1;32m    126\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muse_attention\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    127\u001b[0m                 \u001b[0mret_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mDecoderRNN\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mKEY_ATTN_SCORE\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep_attn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 128\u001b[0;31m             \u001b[0msymbols\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdecoder_outputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtopk\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    129\u001b[0m             \u001b[0msequence_symbols\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msymbols\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "B_EFr6PYZBnc",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        ""
      ]
    },
    {
      "metadata": {
        "id": "qTXN1yzzZB7n",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        ""
      ]
    },
    {
      "metadata": {
        "id": "uDNCzdrLZCLy",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        ""
      ]
    },
    {
      "metadata": {
        "id": "ZVLOrOIYp3d4",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# end of train"
      ]
    },
    {
      "metadata": {
        "id": "ARPHhHtNit6k",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 528
        },
        "outputId": "b2e96e5e-f6f0-4643-f731-91ce7d0f1ecf"
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "              sent0: Aug 23 2047 06:49:08<pad><pad><pad><pad><pad><pad>\n",
            "         sent0_targ: <sos>Aug 23 2047 06:49:08<eos><pad><pad><pad><pad><pad><pad>\n",
            "              sent1: August 23 47 06:49:08<pad><pad><pad><pad>\n",
            "              sentX: Aug 23 2047 06:49:08<pad><pad><pad><pad><pad><pad>\n",
            "recon_sem0_sty0:[TF=0] Aug 23 2046 07:00:46<eos><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad>\n",
            "recon_semX_sty0:[TF=0] Aug 23 2046 07:00:46<eos><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad>\n",
            "recon_semX_sty1:[TF=0] Aug 23 2046 07:00:46<eos><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad>\n",
            "recon_semX_sty1:[TF=1] Aug 23 2046 06:00:44<eos><pad><pad><pad><pad><pad><pad>\n",
            "\n",
            "              sent0: 07/24/2023 23:20:17<pad><pad><pad><pad><pad><pad><pad>\n",
            "         sent0_targ: <sos>07/24/2023 23:20:17<eos><pad><pad><pad><pad><pad><pad><pad>\n",
            "              sent1: Jul 24 2023 23:20:17<pad><pad><pad><pad><pad>\n",
            "              sentX: 07/24/2023 23:20:17<pad><pad><pad><pad><pad><pad><pad>\n",
            "recon_sem0_sty0:[TF=0] 07/23/2032 20:23:19<eos><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad>\n",
            "recon_semX_sty0:[TF=0] 07/23/2032 20:23:19<eos><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad>\n",
            "recon_semX_sty1:[TF=0] 07/23/2032 20:23:19<eos><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad>\n",
            "recon_semX_sty1:[TF=1] 07/23/2032 22:27:19<eos><pad><pad><pad><pad><pad><pad><pad>\n",
            "\n",
            "              sent0: 16-Mar-2081 11.46.32.00<pad><pad><pad>\n",
            "         sent0_targ: <sos>16-Mar-2081 11.46.32.00<eos><pad><pad><pad>\n",
            "              sent1: Mar 16 2081 11:46:32<pad><pad><pad><pad><pad>\n",
            "              sentX: 24-Sep-2074 21.18.35.00<pad><pad><pad>\n",
            "recon_sem0_sty0:[TF=0] 16-Mar-2081 18.26.43.00<eos><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad>\n",
            "recon_semX_sty0:[TF=0] 14-Sep-2078 18.25.37.00<eos><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad>\n",
            "recon_semX_sty1:[TF=0] 24-Sep-2074 21.50.37.00<eos><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad>\n",
            "recon_semX_sty1:[TF=1] 24-Sar-2077 17.47.37.00<eos><pad><pad><pad>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "hp_41_yw0vpK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "5237e5c6-05b8-425f-cf89-2d1b1676fe43"
      },
      "cell_type": "code",
      "source": [
        "''' BCE dynamics\n",
        "bce=lambda a,p: nn.BCELoss()(torch.tensor(a),torch.tensor(p)).numpy()\n",
        "#p= np.array([[0.5001803,  0.50018024, 0.5001803 ]])\n",
        "p = np.array([[1.0,1.0,1.0]]); a = np.array([[0.0,0.0,0.0]]); loss = bce(p,a) ; print (a,p,loss)\n",
        "p = np.array([[1.0,1.0,1.0]]); a = np.array([[1.0,0.0,0.0]]); loss = bce(p,a) ; print (a,p,loss)\n",
        "p = np.array([[1.0,1.0,0.0]]); a = np.array([[0.5,0.5,0.5]]); loss = bce(p,a) ; print (a,p,loss)\n",
        "p = np.array([[0.5,0.5,0.5]]); a = np.array([[0.5,0.5,0.5]]); loss = bce(p,a) ; print (a,p,loss)\n",
        "p = np.array([[0.6,0.4,0.5]]); a = np.array([[0.5,0.5,0.5]]); loss = bce(p,a) ; print (a,p,loss)\n",
        "\n",
        "#       -1*( y* log(p) + (1-y) log(1-p) )\n",
        "#p=0.5  -1   y* 0.693  + (1-y)* 0.693  == -0.693 (y+1-y) = -0.693\n",
        "\n",
        "#a=0.5  -1* (0.5*log(p)+ 0.5*log(1-p)) = -0.5(log(p)+log(1-p))\n",
        "'''\n",
        "1"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "metadata": {
        "id": "GSPSoEXTgVV_",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#from here: http://anie.me/On-Torchtext/\n",
        "from torchtext.data import Field\n",
        "import torch\n",
        "import torch.nn\n",
        "\n",
        "class SplitReversibleField(Field):\n",
        "\n",
        "    def __init__(self, untokenize_char='', **kwargs):\n",
        "        super(SplitReversibleField, self).__init__(**kwargs)\n",
        "        self.untokenize_char = untokenize_char\n",
        "        \n",
        "\n",
        "    def reverse(self, batch):\n",
        "\n",
        "        if not self.batch_first:\n",
        "            batch = batch.t()\n",
        "        with torch.cuda.device_of(batch):\n",
        "            batch = batch.tolist()\n",
        "        batch = [[self.vocab.itos[ind] for ind in ex] for ex in batch]  # denumericalize\n",
        "\n",
        "        def trim(s, t):\n",
        "            sentence = []\n",
        "            for w in s:\n",
        "                if w == t:\n",
        "                    break\n",
        "                sentence.append(w)\n",
        "            return sentence\n",
        "\n",
        "        batch = [trim(ex, self.eos_token) for ex in batch]  # trim past frst eos\n",
        "\n",
        "        def filter_special(tok):\n",
        "            return tok not in (self.init_token, self.pad_token)\n",
        "\n",
        "        batch = [filter(filter_special, ex) for ex in batch]\n",
        "        return [self.untokenize_char.join(ex) for ex in batch]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "sQLllWeCXlrK",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Fx9wR-zaDxTc",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# MY EncoderRNN self made buggy start of result"
      ]
    },
    {
      "metadata": {
        "id": "lRy7otShNctN",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        ""
      ]
    },
    {
      "metadata": {
        "id": "vAVE29Z8hgHf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "139999cb-22e4-48ec-c033-df4d34f4cc82"
      },
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "%matplotlib inline\n",
        "\n",
        "sample = next(train_iter)\n",
        "device='cpu'\n",
        "'''\n",
        "class MyEncoderRNN(nn.Module):  #see https://pytorch.org/tutorials/intermediate/seq2seq_translation_tutorial.html\n",
        "    def __init__(self, vocab_size, hidden_size):\n",
        "        super(EncoderRNN, self).__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "        self.embedding = nn.Embedding(vocab_size, hidden_size)\n",
        "        self.gru = nn.GRU(hidden_size, hidden_size)\n",
        "\n",
        "    def forward(self, input, hidden):\n",
        "        \"\"\" input:  1xbs :  example: 1   x 32\n",
        "            hidden: hxbs :  example: 100 x 32\n",
        "        \"\"\"\n",
        "        print ('EncoderRNN input',input.shape, 'hidden',hidden.shape)\n",
        "        assert input.shape[1]==hidden.shape[1] # batch\n",
        "        assert input.shape[0]==1\n",
        "        assert hidden.shape[0]==self.hidden_size\n",
        "        \n",
        "        \n",
        "        embedded = self.embedding(input).view(1, input.shape[1], -1)\n",
        "        print (embedded.shape)\n",
        "        output, hidden = self.gru(embedded, hidden) #input must be 3 dimension\n",
        "        return output, hidden\n",
        "\n",
        "    def init_hidden(self,batch_size):\n",
        "        return torch.zeros( 1, self.hidden_size,batch_size, device=device)  \n",
        "\n",
        "class Encoder(nn.Module):\n",
        "    def __init__(self, encoder_rnn):\n",
        "        \"\"\" wrapper around EncoderRNN running on a full sequence in one fwd pass \"\"\"\n",
        "        super(Encoder, self).__init__()\n",
        "        self.encoder_rnn = encoder_rnn\n",
        "    \n",
        "    def forward(self, input):\n",
        "        print (input.shape)\n",
        "        sen_len, batch_size = input.shape\n",
        "        h= self.encoder_rnn.init_hidden(batch_size)\n",
        "        for i in range(sen_len):\n",
        "          o,h = self.encoder_rnn(input[i:i+1], h)\n",
        "        return h\n",
        "\n",
        "\n",
        "class MyDecoderRNN(nn.Module):\n",
        "    def __init__(self, input_hidden_size, output_vocab_size):\n",
        "        super(DecoderRNN, self).__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "\n",
        "        self.embedding = nn.Embedding(output_size, hidden_size)\n",
        "        self.gru = nn.GRU(hidden_size, hidden_size)\n",
        "        self.out = nn.Linear(hidden_size, output_vocab_size)\n",
        "        self.softmax = nn.LogSoftmax(dim=1)\n",
        "\n",
        "    def forward(self, input, hidden):\n",
        "        output = self.embedding(input).view(1, 1, -1)\n",
        "        output = F.relu(output)\n",
        "        output, hidden = self.gru(output, hidden)\n",
        "        output = self.softmax(self.out(output[0]))\n",
        "        return output, hidden\n",
        "\n",
        "    def initHidden(self):\n",
        "        return torch.zeros(1, 1, self.hidden_size, device=device)\n",
        "      \n",
        "      \n",
        "#decoder= MyDecoderRNN(opt.semantics_dim+opt.style_dim)   \n",
        "\n",
        "\n",
        "en_sem = Encoder(EncoderRNN(len(TEXT.vocab), opt.semantics_dim))\n",
        "en_sty = Encoder(EncoderRNN(len(TEXT.vocab), opt.style_dim))\n",
        "\n",
        "en_sem(sample.sent_0)\n",
        "'''\n",
        "1"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 64
        }
      ]
    },
    {
      "metadata": {
        "id": "PLIjIkZpNdxR",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# where this code came from?"
      ]
    },
    {
      "metadata": {
        "id": "IKcrmDmgLnJS",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "\n",
        "'''\n",
        "      \n",
        "en_sem = nn.Sequential(\n",
        "  # expect sentence_len,so from outside, cut a pair into x[0],x[1] and pass seperatly each\n",
        "  nn.Linear(sentence_len,19),\n",
        "  nn.ReLU(inplace=True), \n",
        "  nn.Linear(19,opt.semantics_dim),\n",
        "  #nn.Tanh()\n",
        ")\n",
        "\n",
        "en_sty= nn.Sequential(\n",
        "  nn.Linear(sentence_len,19),\n",
        "  nn.ReLU(inplace=True),\n",
        "  nn.Linear(19,opt.style_dim),\n",
        "  #nn.Tanh()\n",
        ")\n",
        "decoder = nn.Sequential(\n",
        "  # input concat of semantic and style\n",
        "  # output sentence_len , each word/char has currently value in range 0..1\n",
        "  nn.Linear(opt.semantics_dim+opt.style_dim,19),\n",
        "  nn.ReLU(inplace=True),\n",
        "  nn.Linear(19,60),\n",
        "  nn.ReLU(inplace=True),\n",
        "  nn.Linear(60,sentence_len),\n",
        "  # we apply MSE on this\n",
        ")\n",
        "adv_disc = nn.Sequential(\n",
        "  # input concat of two style\n",
        "  nn.Linear(2*opt.style_dim,6),\n",
        "  nn.ReLU(inplace=True),\n",
        "  nn.Linear(6,1),\n",
        "  nn.Sigmoid()  #Must be sigmoid, we apply later BCE\n",
        ")\n",
        "'''"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "XTYtFITBzdaC",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "jKl-9BxXNgvU",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "teacher_forcing_ratio = 0.5\n",
        "\n",
        "\n",
        "def train(input_tensor, target_tensor, encoder, decoder, encoder_optimizer, decoder_optimizer, criterion, max_length=MAX_LENGTH):\n",
        "    encoder_hidden = encoder.initHidden()\n",
        "\n",
        "    encoder_optimizer.zero_grad()\n",
        "    decoder_optimizer.zero_grad()\n",
        "\n",
        "    input_length = input_tensor.size(0)\n",
        "    target_length = target_tensor.size(0)\n",
        "\n",
        "    encoder_outputs = torch.zeros(max_length, encoder.hidden_size, device=device)\n",
        "\n",
        "    loss = 0\n",
        "\n",
        "    for ei in range(input_length):\n",
        "        encoder_output, encoder_hidden = encoder(\n",
        "            input_tensor[ei], encoder_hidden)\n",
        "        encoder_outputs[ei] = encoder_output[0, 0]\n",
        "\n",
        "    decoder_input = torch.tensor([[SOS_token]], device=device)\n",
        "\n",
        "    decoder_hidden = encoder_hidden\n",
        "\n",
        "    use_teacher_forcing = True if random.random() < teacher_forcing_ratio else False\n",
        "\n",
        "    if use_teacher_forcing:\n",
        "        # Teacher forcing: Feed the target as the next input\n",
        "        for di in range(target_length):\n",
        "            decoder_output, decoder_hidden, decoder_attention = decoder(\n",
        "                decoder_input, decoder_hidden, encoder_outputs)\n",
        "            loss += criterion(decoder_output, target_tensor[di])\n",
        "            decoder_input = target_tensor[di]  # Teacher forcing\n",
        "\n",
        "    else:\n",
        "        # Without teacher forcing: use its own predictions as the next input\n",
        "        for di in range(target_length):\n",
        "            decoder_output, decoder_hidden, decoder_attention = decoder(\n",
        "                decoder_input, decoder_hidden, encoder_outputs)\n",
        "            topv, topi = decoder_output.topk(1)\n",
        "            decoder_input = topi.squeeze().detach()  # detach from history as input\n",
        "\n",
        "            loss += criterion(decoder_output, target_tensor[di])\n",
        "            if decoder_input.item() == EOS_token:\n",
        "                break\n",
        "\n",
        "    loss.backward()\n",
        "\n",
        "    encoder_optimizer.step()\n",
        "    decoder_optimizer.step()\n",
        "\n",
        "    return loss.item() / target_length"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "crjmKimmLijT",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "'''from torch.utils.data import Dataset#, DataLoader\n",
        "import numpy as np\n",
        "import time\n",
        "\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import numpy as np\n",
        "%matplotlib inline\n",
        "\n",
        "class TimePairsDataset(Dataset):\n",
        "  \n",
        "  def __init__(self,length,time_mod_3_result): #1e9 means 1970-2001\n",
        "    \"\"\"\n",
        "    time_mod_3_result - to make sure time is train/test/valid is different, pass\n",
        "    a different result here.\n",
        "    \"\"\"\n",
        "    #super().__init__()\n",
        "    self.length = length\n",
        "    self.formats = [\"%b %d %Y %H:%M:%S\", \"%m/%b/%Y %H:%M:%S\"] # STAY WITH 2 STYLES, DISCRIMINATOR SIMPLER #\"%d %b %Y %H:%M:%S\",\n",
        "    self.time_mod_3_result=time_mod_3_result\n",
        "  \n",
        "  \n",
        "  def __len__(self):\n",
        "    return int(self.length)\n",
        "  \n",
        "  def _choose(self,idx,style):\n",
        "    st = time.strftime(self.formats[style],time.gmtime(idx))\n",
        "    return np.array([ord(c) for c in list(st)][:24],np.float32)/120 #chars are up to that\n",
        "  \n",
        "  def untokenize_sample(self,sample):\n",
        "    \"\"\" sample x and y, x contains multiple sentences\"\"\"\n",
        "    x,y = sample\n",
        "    out=[] \n",
        "    for tokens in x:    \n",
        "      out.append(self.untokenize_tokens(tokens) )\n",
        "    return out,y\n",
        "\n",
        "  def untokenize_tokens(self,tokens):\n",
        "    \"\"\" one sentence\"\"\"\n",
        "    if type(tokens)==torch.Tensor:\n",
        "      tokens = tokens.detach().numpy()\n",
        "    return ''.join([chr(int(round(token*120))) for token in tokens])\n",
        "  \n",
        "  \n",
        "  def _tvt(self,idx):\n",
        "    # for 10, if train, return 9, valid 10, test 11\n",
        "    return (idx//3) * 3 + self.time_mod_3_result #10//3 * 3 + x = 9+x\n",
        "  \n",
        "  def __getitem__(self,idx):\n",
        "    \"\"\" x -  x[0] semantic0   , style0\n",
        "             x[1] semantic0   , style1   \n",
        "             x[2] semantic0orX, style0 (1/2 the time 0 , half X)\n",
        "    \"\"\"\n",
        "    \n",
        "    #other_idx is 50% same, 50% other\n",
        "    other_idx = (idx + np.random.randint(0,2)*(np.random.randint(10,self.length))) %self.length\n",
        "    #print (idx,other_idx)\n",
        "    idx = self._tvt(idx)\n",
        "    other_idx = self._tvt(other_idx)\n",
        "    #print (idx,other_idx)\n",
        "    \n",
        "    # two random formats\n",
        "    random_fs= np.random.choice(len(self.formats),size=2,replace=False)\n",
        "    #print (random_fs)\n",
        "    x_list = []\n",
        "    x_list.append(self._choose(idx,random_fs[0]))\n",
        "    x_list.append(self._choose(idx,random_fs[1]))\n",
        "    x_list.append(self._choose(other_idx,random_fs[0]))\n",
        "    \n",
        "    y = np.array([idx==other_idx],np.float32)\n",
        "    \n",
        "   \n",
        "    return  (np.vstack(x_list), y)\n",
        "\n",
        "def test():\n",
        "  dataset = TimePairsDataset(1e9,1)\n",
        "  sample = dataset[9] ;#print (sample)\n",
        "  print (dataset.untokenize_sample(sample))\n",
        "  print ('shapes x,y',sample[0].shape,sample[1].shape)\n",
        "  \n",
        "test()\n",
        "'''"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "NswxRK1Pzexq",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "a66fouEILpSz",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Seq2Seq Sanity"
      ]
    },
    {
      "metadata": {
        "id": "i9Q6pVYxLr7n",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 406
        },
        "outputId": "7f96da18-e47e-4b92-c3e4-95c4f4607287"
      },
      "cell_type": "code",
      "source": [
        "import os\n",
        "import argparse\n",
        "import logging\n",
        "\n",
        "import torch\n",
        "from torch.optim.lr_scheduler import StepLR\n",
        "import torchtext\n",
        "\n",
        "import seq2seq\n",
        "from seq2seq.trainer import SupervisedTrainer\n",
        "from seq2seq.models import EncoderRNN, DecoderRNN, Seq2seq\n",
        "from seq2seq.loss import Perplexity\n",
        "from seq2seq.optim import Optimizer\n",
        "from seq2seq.dataset import SourceField, TargetField\n",
        "from seq2seq.evaluator import Predictor\n",
        "\n",
        "\n",
        "\n",
        "# Prepare dataset\n",
        "src = SourceField()\n",
        "tgt = TargetField()\n",
        "max_len = 20\n",
        "src = TEXT\n",
        "tgt = TEXT_TARGET\n",
        "input_vocab = src.vocab\n",
        "output_vocab = tgt.vocab\n",
        "train = ds\n",
        "dev = ds_eval\n",
        "\n",
        "# NOTE: If the source field name and the target field name\n",
        "# are different from 'src' and 'tgt' respectively, they have\n",
        "# to be set explicitly before any training or inference\n",
        "seq2seq.src_field_name = 'sent_0'\n",
        "seq2seq.tgt_field_name = 'sent_0_target'\n",
        "\n",
        "# Prepare loss\n",
        "weight = torch.ones(len(tgt.vocab))\n",
        "pad = tgt.vocab.stoi[tgt.pad_token]\n",
        "loss = Perplexity(weight, pad)\n",
        "if torch.cuda.is_available():\n",
        "    loss.cuda()\n",
        "\n",
        "seq2seq = None\n",
        "optimizer = None\n",
        "# Initialize model\n",
        "hidden_size=128\n",
        "bidirectional = True\n",
        "encoder = EncoderRNN(len(src.vocab), max_len, hidden_size,\n",
        "                     bidirectional=bidirectional, variable_lengths=True)\n",
        "decoder = DecoderRNN(len(tgt.vocab), max_len, hidden_size * 2 if bidirectional else hidden_size,\n",
        "                     dropout_p=0.2, use_attention=True, bidirectional=bidirectional,\n",
        "                     eos_id=tgt.eos_id, sos_id=tgt.sos_id)\n",
        "seq2seq = Seq2seq(encoder, decoder)\n",
        "if torch.cuda.is_available():\n",
        "    seq2seq.cuda()\n",
        "\n",
        "for param in seq2seq.parameters():\n",
        "    param.data.uniform_(-0.08, 0.08)\n",
        "\n",
        "# Optimizer and learning rate scheduler can be customized by\n",
        "# explicitly constructing the objects and pass to the trainer.\n",
        "#\n",
        "# optimizer = Optimizer(torch.optim.Adam(seq2seq.parameters()), max_grad_norm=5)\n",
        "# scheduler = StepLR(optimizer.optimizer, 1)\n",
        "# optimizer.set_scheduler(scheduler)\n",
        "\n",
        "# train\n",
        "import logging\n",
        "logger = logging.getLogger()\n",
        "logger.setLevel(logging.INFO)\n",
        "\n",
        "\n",
        "logging.basicConfig(format='%(asctime)s %(levelname)s:%(message)s', level=logging.DEBUG, datefmt='%I:%M:%S')\n",
        "\n",
        "t = SupervisedTrainer(loss=loss, batch_size=32,\n",
        "                    checkpoint_every=50,\n",
        "                    print_every=10, expt_dir='.')\n",
        "\n",
        "seq2seq = t.train(seq2seq, train,\n",
        "                  num_epochs=2, dev_data=dev,\n",
        "                  optimizer=optimizer,\n",
        "                  teacher_forcing_ratio=0.5,\n",
        "                  resume=False,)\n",
        "\n",
        "predictor = Predictor(seq2seq, input_vocab, output_vocab)\n",
        "seq_str = \"November 21 77 14:07:40\" #raw_input(\"Type in a source sequence:\")\n",
        "seq = seq_str.strip().split()\n",
        "''.join(predictor.predict(\"NoveMBer 21 77 14:07:40\"))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:52: UserWarning: size_average and reduce args will be deprecated, please use reduction='sum' instead.\n",
            "  warnings.warn(warning.format(ret))\n",
            "/usr/local/lib/python3.6/dist-packages/torch/nn/modules/rnn.py:38: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n",
            "  \"num_layers={}\".format(dropout, num_layers))\n",
            "02:08:29 INFO:Optimizer: Adam (\n",
            "Parameter Group 0\n",
            "    amsgrad: False\n",
            "    betas: (0.9, 0.999)\n",
            "    eps: 1e-08\n",
            "    lr: 0.001\n",
            "    weight_decay: 0\n",
            "), Scheduler: None\n",
            "/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:995: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
            "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n",
            "/usr/local/lib/python3.6/dist-packages/torchtext/data/field.py:321: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n",
            "  return Variable(arr, volatile=not train), lengths\n",
            "/usr/local/lib/python3.6/dist-packages/torchtext/data/field.py:322: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n",
            "  return Variable(arr, volatile=not train)\n",
            "02:08:32 INFO:Finished epoch 1: Train Perplexity: 40.7963, Dev Perplexity: 33.6183, Accuracy: 0.1151\n",
            "02:08:35 INFO:Finished epoch 2: Train Perplexity: 30.6331, Dev Perplexity: 23.3884, Accuracy: 0.1210\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'00000000000000000000'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    }
  ]
}
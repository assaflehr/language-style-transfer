{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "drnet_nlp_dataset.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [
        "nMc6XeMxWxha",
        "2qo5XKYPW25Z"
      ],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "[View in Colaboratory](https://colab.research.google.com/github/assaflehr/language-style-transfer/blob/master/notebooks/drnet_nlp_dataset.ipynb)"
      ]
    },
    {
      "metadata": {
        "id": "9DZmHoW4hbsO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 904
        },
        "outputId": "bde77eca-3124-4c28-cc27-9f00e66c3e3e"
      },
      "cell_type": "code",
      "source": [
        "#!pip install spacy   #can take few minutes\n",
        "#!python -m spacy download en\n",
        "#!pip install git+https://github.com/fastai/fastai.git\n",
        "!pip install torch -U # 0.4 at-least\n",
        "\n",
        "!pip install torchtext  # for simpler datasets\n",
        "\n",
        "!pip install git+https://github.com/IBM/pytorch-seq2seq  #for seq2seq\n",
        "!pip install dill  #req of seq2seq\n",
        "!pip install tqdm  #req of seq2seq\n",
        "\n",
        "#!pip install revtok"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting torch\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/49/0e/e382bcf1a6ae8225f50b99cc26effa2d4cc6d66975ccf3fa9590efcbedce/torch-0.4.1-cp36-cp36m-manylinux1_x86_64.whl (519.5MB)\n",
            "\u001b[K    100% |████████████████████████████████| 519.5MB 23kB/s \n",
            "tcmalloc: large alloc 1073750016 bytes == 0x592ae000 @  0x7f15d160a1c4 0x46d6a4 0x5fcbcc 0x4c494d 0x54f3c4 0x553aaf 0x54e4c8 0x54f4f6 0x553aaf 0x54efc1 0x54f24d 0x553aaf 0x54efc1 0x54f24d 0x553aaf 0x54efc1 0x54f24d 0x551ee0 0x54e4c8 0x54f4f6 0x553aaf 0x54efc1 0x54f24d 0x551ee0 0x54efc1 0x54f24d 0x551ee0 0x54e4c8 0x54f4f6 0x553aaf 0x54e4c8\n",
            "\u001b[?25hInstalling collected packages: torch\n",
            "Successfully installed torch-0.4.1\n",
            "Collecting torchtext\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/78/90/474d5944d43001a6e72b9aaed5c3e4f77516fbef2317002da2096fd8b5ea/torchtext-0.2.3.tar.gz (42kB)\n",
            "\u001b[K    100% |████████████████████████████████| 51kB 3.5MB/s \n",
            "\u001b[?25hCollecting tqdm (from torchtext)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7d/e6/19dfaff08fcbee7f3453e5b537e65a8364f1945f921a36d08be1e2ff3475/tqdm-4.24.0-py2.py3-none-any.whl (43kB)\n",
            "\u001b[K    100% |████████████████████████████████| 51kB 5.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from torchtext) (2.18.4)\n",
            "Requirement already satisfied: idna<2.7,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->torchtext) (2.6)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->torchtext) (2018.4.16)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->torchtext) (3.0.4)\n",
            "Requirement already satisfied: urllib3<1.23,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->torchtext) (1.22)\n",
            "Building wheels for collected packages: torchtext\n",
            "  Running setup.py bdist_wheel for torchtext ... \u001b[?25l-\b \b\\\b \bdone\n",
            "\u001b[?25h  Stored in directory: /content/.cache/pip/wheels/42/a6/f4/b267328bde6bb680094a0c173e8e5627ccc99543abded97204\n",
            "Successfully built torchtext\n",
            "Installing collected packages: tqdm, torchtext\n",
            "Successfully installed torchtext-0.2.3 tqdm-4.24.0\n",
            "Collecting git+https://github.com/IBM/pytorch-seq2seq\n",
            "  Cloning https://github.com/IBM/pytorch-seq2seq to /tmp/pip-req-build-ymw4nwv0\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from seq2seq==0.1.6) (1.14.5)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.6/dist-packages (from seq2seq==0.1.6) (0.4.1)\n",
            "Requirement already satisfied: torchtext in /usr/local/lib/python3.6/dist-packages (from seq2seq==0.1.6) (0.2.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from torchtext->seq2seq==0.1.6) (4.24.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from torchtext->seq2seq==0.1.6) (2.18.4)\n",
            "Requirement already satisfied: urllib3<1.23,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->torchtext->seq2seq==0.1.6) (1.22)\n",
            "Requirement already satisfied: idna<2.7,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->torchtext->seq2seq==0.1.6) (2.6)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->torchtext->seq2seq==0.1.6) (2018.4.16)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->torchtext->seq2seq==0.1.6) (3.0.4)\n",
            "Building wheels for collected packages: seq2seq\n",
            "  Running setup.py bdist_wheel for seq2seq ... \u001b[?25l-\b \b\\\b \bdone\n",
            "\u001b[?25h  Stored in directory: /tmp/pip-ephem-wheel-cache-wipqvxzc/wheels/98/b5/06/771c406b3ecc8ed34f07da72d7baf65b87e561bd9f808e91bd\n",
            "Successfully built seq2seq\n",
            "Installing collected packages: seq2seq\n",
            "Successfully installed seq2seq-0.1.6\n",
            "Collecting dill\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/6f/78/8b96476f4ae426db71c6e86a8e6a81407f015b34547e442291cd397b18f3/dill-0.2.8.2.tar.gz (150kB)\n",
            "\u001b[K    100% |████████████████████████████████| 153kB 7.0MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: dill\n",
            "  Running setup.py bdist_wheel for dill ... \u001b[?25l-\b \b\\\b \bdone\n",
            "\u001b[?25h  Stored in directory: /content/.cache/pip/wheels/e2/5d/17/f87cb7751896ac629b435a8696f83ee75b11029f5d6f6bda72\n",
            "Successfully built dill\n",
            "Installing collected packages: dill\n",
            "Successfully installed dill-0.2.8.2\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (4.24.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "qHWOFxkWSubZ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Dataset with torchtext"
      ]
    },
    {
      "metadata": {
        "id": "vQn5WXMiSzae",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 315
        },
        "outputId": "bfef438e-b6ee-48e8-e018-d608eca2112f"
      },
      "cell_type": "code",
      "source": [
        "from torch.utils.data import Dataset#, DataLoader\n",
        "import numpy as np\n",
        "import time\n",
        "\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import numpy as np\n",
        "%matplotlib inline\n",
        "import torchtext.data as data\n",
        "from collections import namedtuple\n",
        "\n",
        "\n",
        "TimeExample = namedtuple('TimeExample',['src','sent_0','sent_1','sent_x','is_x_0','sent_0_target'])\n",
        "\n",
        "class TimeStyleDataset(Dataset):\n",
        "  \n",
        "  def __init__(self,max_id,time_mod_3_result): \n",
        "    \"\"\"\n",
        "    max_id how many samples are in this dataset. Size of one epoc!\n",
        "    time_mod_3_result - to make sure time is train/test/valid is different, pass 0,1,2\n",
        "    \"\"\"\n",
        "    self.max_id =int(max_id)\n",
        "    #TODO : add more!!# see here: https://docs.python.org/2/library/datetime.html month can be: %b,%B,%m , year: %y,%Y\n",
        "    self.formats = [\"%b %d %Y %H:%M:%S\", \"%m/%d/%Y %H:%M:%S\", \"%d-%b-%Y %H.%M.%S.00\",\n",
        "                    \"%B %d %y %H:%M:%S\" ,\"%B %d %H:%M:%S %Y\", \"%d/%B/%Y %H:%M:%S\"]\n",
        "    self.time_mod_3_result=time_mod_3_result\n",
        "  \n",
        "  def __len__(self):\n",
        "    return self.max_id\n",
        "  \n",
        "  def _tvt(self,idx):\n",
        "    # for 10, if train, return 9, valid 10, test 11\n",
        "    return (idx//3) * 3 + self.time_mod_3_result #10//3 * 3 + x = 9+x\n",
        "  \n",
        "  def __getitem__(self,idx):\n",
        "    if idx > self.max_id:\n",
        "      raise IndexError(f'TimeStyleDataset {idx} is out of range {self.max_id}')\n",
        "    \n",
        "    \"\"\" x -  x[0] semantic0   , style0\n",
        "             x[1] semantic0   , style1   \n",
        "             x[2] semantic0orX, style0 (1/2 the time 0 , half X)\n",
        "    \"\"\"\n",
        "    max_time= 2*int(2e9)  #means 1970-2001\n",
        "    \n",
        "    random_ids = np.random.randint(low=0,high=max_time,size=2)\n",
        "    idx = random_ids[0] #other_idx is 50% same, 50% other\n",
        "    other_idx = random_ids[1] if np.random.randint(0,2)==0 else random_ids[0]\n",
        "\n",
        "    idx = self._tvt(idx)\n",
        "    other_idx = self._tvt(other_idx)\n",
        "   \n",
        "    # two random formats\n",
        "    random_fs= np.random.choice(len(self.formats),size=2,replace=False)\n",
        "    \n",
        "    sent_0= time.strftime(self.formats[random_fs[0]],time.gmtime(idx)) \n",
        "    sent_1= time.strftime(self.formats[random_fs[1]],time.gmtime(idx)) \n",
        "    sent_x= time.strftime(self.formats[random_fs[0]],time.gmtime(other_idx))\n",
        "    y = torch.FloatTensor(np.array([idx==other_idx],np.float32))\n",
        "    return TimeExample(sent_0,sent_0,sent_1,sent_x,y,sent_0)\n",
        "\n",
        "def test():\n",
        "  dataset = TimeStyleDataset(1e3,1)\n",
        "  for i in range(3):\n",
        "    sample = dataset[i] ; print (sample)  \n",
        "  print ('len',len(dataset))\n",
        "  \n",
        "test()\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "from seq2seq.dataset import SourceField,TargetField\n",
        "TEXT = SourceField(batch_first =True,sequential=True,use_vocab=True, lower=False,\n",
        "                            tokenize=lambda x: list(x)) # fix_length=10\n",
        "\"\"\"\" Wrapper class of torchtext.data.Field that forces batch_first to be True \n",
        "and prepend <sos> and append <eos> to sequences in preprocessing step. \"\"\"\n",
        "TEXT_TARGET = TargetField(batch_first =True,sequential=True,use_vocab=True, lower=False,\n",
        "                            tokenize=lambda x: list(x)) # fix_length=10\n",
        "LABEL= data.Field(batch_first=True,sequential=False,use_vocab=False, tensor_type =torch.FloatTensor)\n",
        "fields = [('src',TEXT),('sent_0',TEXT),('sent_1',TEXT),('sent_x',TEXT),('is_x_0',LABEL),('sent_0_target',TEXT_TARGET)] \n",
        "\n",
        "\n",
        "\n",
        "ds = data.Dataset(TimeStyleDataset(1e3,1), fields)\n",
        "ds_eval = data.Dataset(TimeStyleDataset(1e3,2), fields)\n",
        "\n",
        "# usage\n",
        "print (ds[2].sent_0) #not processed\n",
        "print (ds[2].is_x_0) #not processed\n",
        "print (f'building vocab on {len(ds)}')\n",
        "TEXT.build_vocab(ds, max_size=80000)\n",
        "TEXT_TARGET.build_vocab(ds, max_size=80000)\n",
        "print ('vocab TEXT:',len(TEXT.vocab), TEXT.vocab.freqs.most_common()[:10])\n",
        "print ('vocab TEXT_TARGET:',len(TEXT_TARGET.vocab), TEXT_TARGET.vocab.freqs.most_common()[:10])\n",
        "print ('vocab <sos>',TEXT_TARGET.sos_id)\n",
        "print ('vocab <eos>',TEXT_TARGET.eos_id)\n",
        "print ('vocab <eos>',TEXT_TARGET.pad_token)\n",
        "\n",
        "       \n",
        "\n",
        "# READ:  https://github.com/mjc92/TorchTextTutorial/blob/master/01.%20Getting%20started.ipynb\n",
        "train_iter = iter(data.BucketIterator( dataset=ds, batch_size=32, sort_within_batch=False,sort_key=lambda x: len(x.sent_0))) \n",
        "eval_iter =  iter(data.BucketIterator( dataset=ds_eval, batch_size=32, sort_within_batch=False,sort_key=lambda x: len(x.sent_0))) \n",
        "#performance note: the first next, takes 3.5s, the next are fast (10000 is 1s)\n",
        "b= next(train_iter)\n",
        "print ('b.is_x_0.type() MUST BE FLOATTENSOR',b.is_x_0.type())\n",
        "print ('b_sent0',b.sent_0[0].shape,b.sent_0[1].shape)#TEXT.reverse(b.sent_0))\n",
        "print ('b.src is values+len tuple',b.src[0].shape,b.src[1].shape)#TEXT.reverse(b.sent_0))\n",
        "print ('b.sent_0_target',b.sent_0_target.shape)\n"
      ],
      "execution_count": 147,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TimeExample(src='29-Jul-2001 11.09.46.00', sent_0='29-Jul-2001 11.09.46.00', sent_1='Jul 29 2001 11:09:46', sent_x='29-Jul-2001 11.09.46.00', is_x_0=tensor([1.]), sent_0_target='29-Jul-2001 11.09.46.00')\n",
            "TimeExample(src='February 23 11:31:49 1994', sent_0='February 23 11:31:49 1994', sent_1='February 23 94 11:31:49', sent_x='December 20 17:20:40 2091', is_x_0=tensor([0.]), sent_0_target='February 23 11:31:49 1994')\n",
            "TimeExample(src='January 02 13:03:55 2044', sent_0='January 02 13:03:55 2044', sent_1='01/02/2044 13:03:55', sent_x='May 20 09:06:37 2008', is_x_0=tensor([0.]), sent_0_target='January 02 13:03:55 2044')\n",
            "len 1000\n",
            "02/06/2018 01:27:34\n",
            "tensor([1.])\n",
            "building vocab on 1000\n",
            "vocab TEXT: 43 [('0', 11061), ('2', 8226), (' ', 8018), ('1', 7988), (':', 6714), ('3', 3928), ('4', 3873), ('5', 3676), ('9', 3268), ('/', 2700)]\n",
            "vocab TEXT_TARGET: 43 [('0', 2754), ('1', 2047), ('2', 2033), (' ', 2019), (':', 1650), ('3', 962), ('4', 917), ('5', 910), ('9', 889), ('7', 647)]\n",
            "vocab <sos> 0\n",
            "vocab <eos> 0\n",
            "vocab <eos> <pad>\n",
            "b.is_x_0.type() MUST BE FLOATTENSOR torch.FloatTensor\n",
            "b_sent0 torch.Size([32, 25]) torch.Size([32])\n",
            "b.src is values+len tuple torch.Size([32, 25]) torch.Size([32])\n",
            "b.sent_0_target torch.Size([32, 25])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "a66fouEILpSz",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Seq2Seq Sanity"
      ]
    },
    {
      "metadata": {
        "id": "i9Q6pVYxLr7n",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 557
        },
        "outputId": "d1592e35-fb38-4c64-9d5c-2ff366eb40f0"
      },
      "cell_type": "code",
      "source": [
        "import os\n",
        "import argparse\n",
        "import logging\n",
        "\n",
        "import torch\n",
        "from torch.optim.lr_scheduler import StepLR\n",
        "import torchtext\n",
        "\n",
        "import seq2seq\n",
        "from seq2seq.trainer import SupervisedTrainer\n",
        "from seq2seq.models import EncoderRNN, DecoderRNN, Seq2seq\n",
        "from seq2seq.loss import Perplexity\n",
        "from seq2seq.optim import Optimizer\n",
        "from seq2seq.dataset import SourceField, TargetField\n",
        "from seq2seq.evaluator import Predictor\n",
        "\n",
        "\n",
        "\n",
        "# Prepare dataset\n",
        "src = SourceField()\n",
        "tgt = TargetField()\n",
        "max_len = 20\n",
        "src = TEXT\n",
        "tgt = TEXT_TARGET\n",
        "input_vocab = src.vocab\n",
        "output_vocab = tgt.vocab\n",
        "train = ds\n",
        "dev = ds_eval\n",
        "\n",
        "# NOTE: If the source field name and the target field name\n",
        "# are different from 'src' and 'tgt' respectively, they have\n",
        "# to be set explicitly before any training or inference\n",
        "seq2seq.src_field_name = 'sent_0'\n",
        "seq2seq.tgt_field_name = 'sent_0_target'\n",
        "\n",
        "# Prepare loss\n",
        "weight = torch.ones(len(tgt.vocab))\n",
        "pad = tgt.vocab.stoi[tgt.pad_token]\n",
        "loss = Perplexity(weight, pad)\n",
        "if torch.cuda.is_available():\n",
        "    loss.cuda()\n",
        "\n",
        "seq2seq = None\n",
        "optimizer = None\n",
        "# Initialize model\n",
        "hidden_size=128\n",
        "bidirectional = True\n",
        "encoder = EncoderRNN(len(src.vocab), max_len, hidden_size,\n",
        "                     bidirectional=bidirectional, variable_lengths=True)\n",
        "decoder = DecoderRNN(len(tgt.vocab), max_len, hidden_size * 2 if bidirectional else hidden_size,\n",
        "                     dropout_p=0.2, use_attention=True, bidirectional=bidirectional,\n",
        "                     eos_id=tgt.eos_id, sos_id=tgt.sos_id)\n",
        "seq2seq = Seq2seq(encoder, decoder)\n",
        "if torch.cuda.is_available():\n",
        "    seq2seq.cuda()\n",
        "\n",
        "for param in seq2seq.parameters():\n",
        "    param.data.uniform_(-0.08, 0.08)\n",
        "\n",
        "# Optimizer and learning rate scheduler can be customized by\n",
        "# explicitly constructing the objects and pass to the trainer.\n",
        "#\n",
        "# optimizer = Optimizer(torch.optim.Adam(seq2seq.parameters()), max_grad_norm=5)\n",
        "# scheduler = StepLR(optimizer.optimizer, 1)\n",
        "# optimizer.set_scheduler(scheduler)\n",
        "\n",
        "# train\n",
        "import logging\n",
        "logger = logging.getLogger()\n",
        "logger.setLevel(logging.INFO)\n",
        "\n",
        "\n",
        "logging.basicConfig(format='%(asctime)s %(levelname)s:%(message)s', level=logging.DEBUG, datefmt='%I:%M:%S')\n",
        "\n",
        "t = SupervisedTrainer(loss=loss, batch_size=32,\n",
        "                    checkpoint_every=50,\n",
        "                    print_every=10, expt_dir='.')\n",
        "\n",
        "seq2seq = t.train(seq2seq, train,\n",
        "                  num_epochs=2, dev_data=dev,\n",
        "                  optimizer=optimizer,\n",
        "                  teacher_forcing_ratio=0.5,\n",
        "                  resume=False,)\n",
        "\n",
        "predictor = Predictor(seq2seq, input_vocab, output_vocab)\n",
        "seq_str = \"November 21 77 14:07:40\" #raw_input(\"Type in a source sequence:\")\n",
        "seq = seq_str.strip().split()\n",
        "''.join(predictor.predict(\"NoveMBer 21 77 14:07:40\"))"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:52: UserWarning: size_average and reduce args will be deprecated, please use reduction='elementwise_mean' instead.\n",
            "  warnings.warn(warning.format(ret))\n",
            "/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:52: UserWarning: size_average and reduce args will be deprecated, please use reduction='sum' instead.\n",
            "  warnings.warn(warning.format(ret))\n",
            "/usr/local/lib/python3.6/dist-packages/torch/nn/modules/rnn.py:38: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n",
            "  \"num_layers={}\".format(dropout, num_layers))\n",
            "05:18:09 INFO:Optimizer: Adam (\n",
            "Parameter Group 0\n",
            "    amsgrad: False\n",
            "    betas: (0.9, 0.999)\n",
            "    eps: 1e-08\n",
            "    lr: 0.001\n",
            "    weight_decay: 0\n",
            "), Scheduler: None\n",
            "05:18:09 DEBUG:Epoch: 1, Step: 0\n",
            "/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:995: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
            "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n",
            "05:18:13 INFO:Progress: 31%, Train Perplexity: 50.1619\n",
            "05:18:15 INFO:Progress: 46%, Train Perplexity: 20.1048\n",
            "/usr/local/lib/python3.6/dist-packages/torchtext/data/field.py:321: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n",
            "  return Variable(arr, volatile=not train), lengths\n",
            "/usr/local/lib/python3.6/dist-packages/torchtext/data/field.py:322: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n",
            "  return Variable(arr, volatile=not train)\n",
            "05:18:17 INFO:Finished epoch 1: Train Perplexity: 23.0504, Dev Perplexity: 16.5656, Accuracy: 0.1368\n",
            "05:18:17 DEBUG:Epoch: 2, Step: 32\n",
            "05:18:19 INFO:Progress: 62%, Train Perplexity: 16.2117\n",
            "05:18:21 INFO:Progress: 78%, Train Perplexity: 17.4238\n",
            "05:18:23 INFO:Progress: 93%, Train Perplexity: 16.1373\n",
            "05:18:26 INFO:Finished epoch 2: Train Perplexity: 16.3021, Dev Perplexity: 15.5293, Accuracy: 0.1473\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/////2    1 1:::::::'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "metadata": {
        "id": "efa1qLb_QXOo",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "??TargetField\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "PdoVxGFbP-GR",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        ""
      ]
    },
    {
      "metadata": {
        "id": "Mx_wvDraYghh",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# models define"
      ]
    },
    {
      "metadata": {
        "id": "nMc6XeMxWxha",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Documentation"
      ]
    },
    {
      "metadata": {
        "id": "wnsebPEMW0d4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 318
        },
        "outputId": "f63aa780-49b2-4ea9-8394-925e0605a1e7"
      },
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "\n",
        "# semantic_encoder : take sentence return a vector with only semantics\n",
        "# semantic similiary objective: given a pair of sentences with the same semantics,\n",
        "#    expect their results to be close (MeanSquared)    \n",
        "\n",
        "# see idea from https://github.com/edenton/drnet-py/blob/master/models/classifiers.py\n",
        "# in her train method:\n",
        "# FRAMES: VID A: FRAME 1 x_c1 , ?x_p2? (1/2 of times)\n",
        "#                FRAME 2 x_c2 , x_p1\n",
        "#         VID B: FRAME 1      , ?x_p2? (1/2 of times)\n",
        "#  \n",
        "# x_p1,x_p2 chosen randonly from same/not-same video\n",
        "# x_c1,x_c2 are always same-video\n",
        "# c1 and p1 are same content, different pose.\n",
        "\n",
        "# train_scene_discriminator()\n",
        "# h_p1,h_p2 = netEP applied to x[0],x[1]. assumption: SAME VIDEO\n",
        "# important: detach both!\n",
        "# override half of h_p2 by random-permutations of the batch. \n",
        "#   [1,2,3,4,5,6]\n",
        "#   [2,3,1,4,5,6] after 1st half permute\n",
        "#   [1,1,1,0,0,0] set unequal the labels (1=unequal, 0 equal. does it matter? should it be 0.9,0.1?)\n",
        "# apply BCE on inpit: concat of [h_p1,h_p2] \n",
        "# run backward, and optimizer on the netC classifier ONLY! emphasize! not on the encoder\n",
        "\n",
        "\n",
        "# train()\n",
        "# h_c1,h_c2 = netEC(x_c1), netEC(x_c2)  where input is x[0],x[1] sim loss is MSE directly on the hidden content-semantics\n",
        "# h_p1,h_p2 = netEP(x_p1),netEP(x_p2) where input is x[2],x[3]\n",
        "# rec = netD([h_c1, h_p1]) h_c1 is DIFFERENT FRAME , but same content, than h_p1\n",
        "# netC is the semantic-discriminator given h_p1,h_p2, target 0.5 (max-entropy). \n",
        "# emphasize! don't optimize netC is this stage\n",
        "\n",
        "\n",
        "# ANTI-ADVERSERTIAL LOSS FUNCTION, target is 0.5, so min value is 0.6931471805599453\n",
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "x = np.arange(1,100)/100.0\n",
        "plt.title(\"anti adv-loss with target of 0.5. min is 0.693147 \")\n",
        "plt.plot(x, -0.5*(np.log(x)+np.log(1-x)))"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7f095623a550>]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXIAAAEHCAYAAACzy817AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nQmCC\n",
            "text/plain": [
              "<matplotlib.figure.Figure at 0x7f0998d81128>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "2qo5XKYPW25Z",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## PARAMS"
      ]
    },
    {
      "metadata": {
        "id": "ytDrOHZtXMuc",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        ""
      ]
    },
    {
      "metadata": {
        "id": "I9CZBDxzYbt_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "781550b8-c07f-434d-b6a5-5f0ac52a0574"
      },
      "cell_type": "code",
      "source": [
        "import argparse\n",
        "import sys\n",
        "parser = argparse.ArgumentParser()\n",
        "\n",
        "parser.add_argument('--epocs', type=int, default=2, help='number of epochs to train for')\n",
        "parser.add_argument('--epoch_size', type=int, default=600, help='epoch size')\n",
        "parser.add_argument('--batch_size', default=100, type=int, help='batch size')\n",
        "\n",
        "parser.add_argument('--optimizer', default='adam', help='optimizer to train with. only Adam supported')\n",
        "parser.add_argument('--lr', default=0.02, type=float, help='learning rate. source=0.002')\n",
        "parser.add_argument('--adv_disc_lr', default=0.002, type=float, help='learning rate')\n",
        "\n",
        "parser.add_argument('--beta1', default=0.5, type=float, help='momentum term for adam')\n",
        "\n",
        "parser.add_argument('--semantics_dim', type=int, default=20, help='size of the semantics vector')\n",
        "parser.add_argument('--style_dim', type=int, default=5, help='size of the style vector')\n",
        "parser.add_argument('--sd_weight', type=float, default=0.001, help='weight on adversarial loss 0.0001 originally. reducing')\n",
        "\n",
        "parser.add_argument('--max_sent_len', type=int, default=50, help='max size of sentence. sentences typically will be shorter')\n",
        "\n",
        "\n",
        "'''\n",
        "parser.add_argument('--max_step', type=int, default=20, help='maximum distance between frames')\n",
        "parser.add_argument('--seed', default=1, type=int, help='manual seed')\n",
        "parser.add_argument('--log_dir', default='logs', help='base directory to save logs')\n",
        "parser.add_argument('--data_root', default='', help='root directory for data')\n",
        "\n",
        "parser.add_argument('--dataset', default='moving_mnist', help='dataset to train with')\n",
        "\n",
        "parser.add_argument('--sd_nf', type=int, default=100, help='number of layers')\n",
        "parser.add_argument('--content_model', default='dcgan_unet', help='model type (dcgan | dcgan_unet | vgg_unet)')\n",
        "parser.add_argument('--pose_model', default='dcgan', help='model type (dcgan | unet | resnet)')\n",
        "parser.add_argument('--data_threads', type=int, default=5, help='number of parallel data loading threads')\n",
        "parser.add_argument('--data_type', default='drnet', help='speed up data loading for drnet training')\n",
        "'''\n",
        "sys.argv=[\"nothing\"]\n",
        "opt = parser.parse_args()\n",
        "print (opt.lr,opt.beta1)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.02 0.5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "DSLXyMbdX99M",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Define Encoder, Decoder"
      ]
    },
    {
      "metadata": {
        "id": "r5eh7qthtyX5",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "?EncoderRNN\n",
        "#?DecoderRNN"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "G3ghi3B0ymmk",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#   decoders"
      ]
    },
    {
      "metadata": {
        "id": "bXi51149ioGD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        },
        "outputId": "4b7d7094-7421-49cd-a3cd-aa8077d6df21"
      },
      "cell_type": "code",
      "source": [
        "#trn_dl = DataLoader(TimePairsDataset(1e5,1), batch_size=opt.batch_size,)\n",
        "#x,y = next(iter(trn_dl)) \n",
        "#print ('input . x is vertically stacked sentences',x.shape,'y',y.shape)\n",
        "#batch,pair,sentence_len=x.shape\n",
        "\n",
        "from seq2seq.models import EncoderRNN\n",
        "from torch import nn\n",
        "\n",
        "class EncoderWrapper(nn.Module):\n",
        "  \"\"\" wraps encoder, accpet in forward tuple of (data,len). return last hidden\"\"\"\n",
        "  def __init__(self,encoder):\n",
        "    super(EncoderWrapper,self).__init__()\n",
        "    self.encoder = encoder\n",
        "  \n",
        "  def forward(self,inp):\n",
        "\n",
        "      #in_data,in_len = in_tuple\n",
        "      output,hidden = self.encoder(*inp)#in_data,in_len)\n",
        "      # **output** (batch, seq_len, hidden_size): tensor containing the encoded features of the input sequence\n",
        "      # **hidden** (num_layers * num_directions, batch, hidden_size): tensor containing the features in the hidden state `h`\n",
        "      return hidden[0,:,:]\n",
        "\n",
        " \n",
        "adv_disc = nn.Sequential(\n",
        "  # input concat of two style\n",
        "  nn.Linear(2*opt.style_dim,6),\n",
        "  nn.ReLU(inplace=True),\n",
        "  nn.Linear(6,1),\n",
        "  nn.Sigmoid()  #Must be sigmoid, we apply later BCE\n",
        ")\n",
        "\n",
        "\n",
        "variable_lengths = False  # True means batch is ordered. this can't be done as sent0.len!=sent1.len\n",
        "en_sem = EncoderWrapper(EncoderRNN(len(TEXT.vocab),opt.max_sent_len, opt.semantics_dim,variable_lengths =variable_lengths))\n",
        "en_sty = EncoderWrapper(EncoderRNN(len(TEXT.vocab),opt.max_sent_len, opt.style_dim, variable_lengths = variable_lengths))\n",
        "decoder = DecoderRNN(len(TEXT.vocab),opt.max_sent_len, opt.semantics_dim + opt.style_dim,sos_id=TEXT_TARGET.sos_id,eos_id=TEXT_TARGET.eos_id)\n",
        "#adv_disc = Discriminator(EncoderRNN(len(TEXT.vocab),opt.max_sent_len, opt.style_dim, variable_lengths =variable_lengths),\n",
        "#                         opt.style_dim)\n",
        "\n",
        "\n",
        "sample = next(train_iter)\n",
        "print (type(sample.sent_0))\n",
        "in_var,in_len=sample.sent_0\n",
        "#print (in_var[:2],in_len[:2])\n",
        "sem_out = en_sem(sample.sent_0)\n",
        "print ('result of en_sem',sem_out.shape)   #[1, 32, 20]\n",
        "sty_out = en_sty(sample.sent_1)\n",
        "print ('sty_out',sty_out.shape,\n",
        "      'concat',torch.cat([sty_out, sty_out],dim=1).shape)\n",
        "disc_out = adv_disc(torch.cat([sty_out, sty_out],dim=1))\n",
        "print (disc_out.shape)\n",
        "\n",
        "merged = torch.cat([sem_out,sty_out],dim=1)\n",
        "merged.unsqueeze_(0)\n",
        "print ('merged',merged.shape)\n",
        "decoder_outputs, _,_ = decoder(inputs=None,  # pass not None for teacher focring  (batch, seq_len, input_size)\n",
        "                          encoder_hidden=merged, #(num_layers * num_directions, batch_size, hidden_size)\n",
        "                          encoder_outputs = None, # pass not None for attention\n",
        "                          teacher_forcing_ratio=0 #range 0..1 , must pass inputs if >0\n",
        "                         ) \n",
        "#**decoder_outputs** (seq_len, batch, vocab_size): list of tensors with size (batch_size, vocab_size) containing\n",
        "#          the outputs of the decoding function.\n",
        "print ('decoder_outputs',len(decoder_outputs),decoder_outputs[0].shape)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "if opt.optimizer=='adam':\n",
        "  optimizer = torch.optim.Adam\n",
        "\n",
        "optimizer_en_sem = optimizer(en_sem.parameters(), lr=opt.lr) #(, betas=(opt.beta1, 0.999))\n",
        "optimizer_en_sty = optimizer(en_sty.parameters(), lr=opt.lr) #), betas=(opt.beta1, 0.999))\n",
        "optimizer_decoder = optimizer(decoder.parameters(), lr=0.1) #)opt.lr), betas=(opt.beta1, 0.999))\n",
        "optimizer_adv_disc = optimizer(adv_disc.parameters(), lr=opt.adv_disc_lr) ##), betas=(opt.beta1, 0.999))\n",
        " "
      ],
      "execution_count": 153,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'tuple'>\n",
            "result of en_sem torch.Size([32, 20])\n",
            "sty_out torch.Size([32, 5]) concat torch.Size([32, 10])\n",
            "torch.Size([32, 1])\n",
            "merged torch.Size([1, 32, 25])\n",
            "decoder_outputs 50 torch.Size([32, 43])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "ipxPJENEdu8N",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import logging\n",
        "import traceback\n",
        " \n",
        "def handleError(self, record):\n",
        "    traceback.print_stack()\n",
        "logging.Handler.handleError = handleError"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "GaVWTeleYkWk",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Train loop"
      ]
    },
    {
      "metadata": {
        "id": "_jDD-H1faFtq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 3445
        },
        "outputId": "52fdd067-20b7-45fa-e888-b299c036d699"
      },
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "# --------- training funtions ------------------------------------\n",
        "def train(b):\n",
        "\n",
        "    en_sty.zero_grad() \n",
        "    en_sem.zero_grad()\n",
        "    decoder.zero_grad()\n",
        "\n",
        "    # x[0] semantic0   , style0\n",
        "    # x[1] semantic0   , style1   \n",
        "    # x[2] semantic0orX, style0 (1/2 the time 0 , half X)\n",
        "\n",
        "    #sent0 = x[:,0]\n",
        "    #sent1 = x[:,1]\n",
        "    #sentX = x[:,2]\n",
        "\n",
        "    sent0 = b.sent_0\n",
        "    sent1 = b.sent_1\n",
        "    sentX = b.sent_x\n",
        "    recon_target = b.sent_0_target  #one-hot\n",
        "    \n",
        "    logger.debug('sent0',sent0[0].shape,sent0[1].shape)\n",
        "    h_sem0 = en_sem(sent0) \n",
        "    h_sem1 = en_sem(sent1) \n",
        "    print('h_sem0 shape',h_sem0.shape)\n",
        "    # if you want to use torch criterion, you need to copy the label and set it to not requreing gradiant\n",
        "    # so below is different than nn.MSELoss()(h_sem0,h_sem1.detach()). I wonder if only one get grad updates!\n",
        "    sim_loss = torch.mean(torch.pow(  h_sem0- h_sem1,2)) \n",
        "    #sim_loss = mse_criterion(h_c1[0] if opt.content_model[-4:] == 'unet' else h_c1, h_c2)\n",
        "    \n",
        "    \n",
        "    h_sty0 = en_sty(sent0)\n",
        "    merged= torch.cat([h_sem1,h_sty0],dim=1)\n",
        "    merged.unsqueeze_(0) #32x25 -> 1x32x25 . 1 is for one hidden-layer (not-stacked)\n",
        "    print('h_sem1.h_sty0',h_sem1.shape,h_sty0.shape,merged.shape)\n",
        "    recon_sent0, _,_ = decoder(inputs=None,  # pass not None for teacher focring  (batch, seq_len, input_size)\n",
        "                          encoder_hidden=merged, #(num_layers * num_directions, batch_size, hidden_size)\n",
        "                          encoder_outputs = None, # pass not None for attention\n",
        "                          teacher_forcing_ratio=0 #range 0..1 , must pass inputs if >0\n",
        "                         ) \n",
        "    \n",
        "    # calc loss.\n",
        "    print('$'*10,'recon_sent0 length',len(recon_sent0),'each',recon_sent0[0].shape)\n",
        "    #rec_loss = nn.MSELoss()(recon_sent0,sent0)\n",
        "    # see impl https://github.com/IBM/pytorch-seq2seq/blob/master/seq2seq/loss/loss.py\n",
        "    acc_loss, norm_term=0,0\n",
        "    print('recon_target',recon_target.shape,'while decoder outputs',len(decoder_outputs))\n",
        "    #target shape [32, 26]  batch x words , actual len of 50\n",
        "    for step, step_output in enumerate(decoder_outputs):\n",
        "      batch_size = recon_target.size(0)\n",
        "      #print('step_output at step ',step,step_output.shape,type(step_output))\n",
        "      outputs = step_output.contiguous().view(batch_size, -1)\n",
        "      # what to do if output is too-long? decision here is to match only relevant parts\n",
        "      if step+1>=recon_target.size(1):  \n",
        "        break\n",
        "      gold = recon_target[:, step + 1] #tuple [0] is data. [1] is len\n",
        "      #print('output at step ',step,outputs.shape,type(outputs),'gold',gold.shape,type(gold))\n",
        "      \n",
        "      acc_loss += nn.NLLLoss()(outputs, gold) #TODO: why MSE???\n",
        "      norm_term += 1\n",
        "    rec_loss = acc_loss/norm_term\n",
        "    \n",
        "\n",
        "    # TODO : willl it be better to use completely different sentences?\n",
        "    h_styX = en_sty(sentX)\n",
        "    adv_disc_p =  adv_disc(torch.cat([h_sty0,h_styX],dim=1))\n",
        "    \n",
        "    logger.debug (adv_disc_p[0:3].data.numpy().T)\n",
        "    adv_target = torch.FloatTensor(np.full(shape =(sent0.shape[0],1),fill_value=0.5))\n",
        "    # the loss below is a parabula with min at log(0.5)=0.693... see documentation above\n",
        "    adv_disc_loss = nn.BCELoss()(adv_disc_p, adv_target) - np.log(0.5)\n",
        "    #print (adv_disc_loss)\n",
        "    \n",
        "    # full loss\n",
        "    loss = rec_loss #+ sim_loss + opt.sd_weight*adv_disc_loss\n",
        "    loss.backward()\n",
        "\n",
        "    optimizer_en_sem.step()\n",
        "    optimizer_en_sty.step()\n",
        "    optimizer_decoder.step()\n",
        "\n",
        "    return sim_loss.data.cpu().numpy(),rec_loss.data.cpu().numpy(),adv_disc_loss.data.cpu().numpy()*opt.sd_weight\n",
        "\n",
        "def train_scene_discriminator(b):\n",
        "    #print ('train_scene_discriminator',x.shape,y.shape)\n",
        "    \n",
        "    #sent0 = x[:,0]\n",
        "    #sentX = x[:,2]\n",
        "    sent0 = b.sent_0\n",
        "    sentX = b.sent_x\n",
        "    y = b.is_x_0\n",
        "    #logger.debug('y',y.shape,y.type())\n",
        "    \n",
        "    adv_disc.zero_grad()\n",
        "\n",
        "    h_sty0    = en_sty(sent0) #detach?\n",
        "    h_sty0or2 = en_sty(sentX)\n",
        "    \n",
        "  \n",
        "    out = adv_disc(torch.cat([h_sty0, h_sty0or2],dim=1))\n",
        "    logger.debug('adv_disc out',out.shape,'is_x_0',y.shape)\n",
        "    #TODO: #Note BCELossWithLogits is faster and moer stable, to use it remove sigmoid from network end\n",
        "    bce = nn.BCELoss()(out.flatten(), y) #should wrapp in varaible? \n",
        "\n",
        "    bce.backward()\n",
        "    optimizer_adv_disc.step()\n",
        "    #print (out.shape) #torch.Size([16, 1])\n",
        "    acc =  np.round(out.detach().numpy())==y  #CHECK THIS DIMENSTIONS!!! \n",
        "    #print (acc.shape) #1,16\n",
        "    acc = acc.reshape(-1).float()\n",
        "    acc= acc.sum()/len(acc)\n",
        "    return bce.data.cpu().numpy(), acc.numpy()\n",
        "\n",
        "# --------- training loop ------------------------------------\n",
        "#train_ds = TimeStyleDataset(1e9,1)\n",
        "#eval_ds  = TimeStyleDataset(1e9,2)\n",
        "#training_batch_generator = iter(DataLoader(train_ds,batch_size=opt.batch_size))\n",
        "#eval_batch_generator = iter(DataLoader(eval_ds,batch_size=opt.batch_size))\n",
        "training_batch_generator = train_iter  #defined in the notebook start\n",
        "eval_batch_generator = eval_iter \n",
        "b = next(training_batch_generator)\n",
        "\n",
        "  \n",
        "opt.epocs=20 \n",
        "opt.epoch_size=30\n",
        "opt.batch_size= 32 #anti-adv-loss will be noiser\n",
        "\n",
        "logger.setLevel(logging.DEBUG)  \n",
        "for epoch in range(opt.epocs):\n",
        "    #print ('new epoch')\n",
        "    en_sty.train()  # and not eval() mode\n",
        "    en_sem.train()\n",
        "    decoder.train()\n",
        "    adv_disc.train()\n",
        "    epoch_sim_loss, epoch_rec_loss, epoch_anti_disc_loss, epoch_sd_loss, epoch_sd_acc = 0, 0, 0, 0, 0\n",
        "\n",
        "    for i in range(opt.epoch_size):\n",
        "        #if i % 100==0 : print ('batch',i,'of',opt.epoch_size)\n",
        "        b = next(training_batch_generator)\n",
        "\n",
        "        # train scene discriminator\n",
        "        logger.debug ('b_sent_0',b.sent_0[0].shape,b.sent_0[1].shape)#TEXT.reverse(b.sent_0))\n",
        "\n",
        "        sd_loss, sd_acc = train_scene_discriminator(b)\n",
        "        epoch_sd_loss += sd_loss\n",
        "        epoch_sd_acc += sd_acc\n",
        "\n",
        "        # train main model\n",
        "        sim_loss, rec_loss, anti_disc_loss = train(b)\n",
        "        epoch_sim_loss += sim_loss\n",
        "        epoch_rec_loss += rec_loss\n",
        "        epoch_anti_disc_loss += anti_disc_loss\n",
        "    #print (epoch, epoch_rec_loss/opt.epoch_size, epoch_sim_loss/opt.epoch_size)\n",
        "    #print (epoch_sd_acc/opt.epoch_size)\n",
        "    #print (epoch*opt.epoch_size*opt.batch_size)\n",
        "    print('[%02d] rec loss: %.4f | sim loss: %.4f | anti_disc_loss: %.4f || scene disc %.4f %.3f%% ' % (epoch, epoch_rec_loss/opt.epoch_size, \n",
        "                epoch_sim_loss/opt.epoch_size, epoch_anti_disc_loss/opt.epoch_size,\n",
        "                epoch_sd_loss/opt.epoch_size, 100*epoch_sd_acc/opt.epoch_size))\n",
        "    logger.setLevel(logging.INFO)\n",
        "\n",
        "# back to eval mode\n",
        "en_sty.eval()  # and not eval() mode\n",
        "en_sem.eval()\n",
        "decoder.eval()\n",
        "adv_disc.eval()\n",
        "print ('training loop done')\n",
        "# TODO: save the model\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 176,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  File \"/usr/lib/python3.6/runpy.py\", line 193, in _run_module_as_main\n",
            "    \"__main__\", mod_spec)\n",
            "  File \"/usr/lib/python3.6/runpy.py\", line 85, in _run_code\n",
            "    exec(code, run_globals)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py\", line 16, in <module>\n",
            "    app.launch_new_instance()\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/traitlets/config/application.py\", line 658, in launch_instance\n",
            "    app.start()\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/ipykernel/kernelapp.py\", line 477, in start\n",
            "    ioloop.IOLoop.instance().start()\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/zmq/eventloop/ioloop.py\", line 177, in start\n",
            "    super(ZMQIOLoop, self).start()\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tornado/ioloop.py\", line 888, in start\n",
            "    handler_func(fd_obj, events)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tornado/stack_context.py\", line 277, in null_wrapper\n",
            "    return fn(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/zmq/eventloop/zmqstream.py\", line 440, in _handle_events\n",
            "    self._handle_recv()\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/zmq/eventloop/zmqstream.py\", line 472, in _handle_recv\n",
            "    self._run_callback(callback, msg)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/zmq/eventloop/zmqstream.py\", line 414, in _run_callback\n",
            "    callback(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tornado/stack_context.py\", line 277, in null_wrapper\n",
            "    return fn(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/ipykernel/kernelbase.py\", line 283, in dispatcher\n",
            "    return self.dispatch_shell(stream, msg)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/ipykernel/kernelbase.py\", line 235, in dispatch_shell\n",
            "    handler(stream, idents, msg)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/ipykernel/kernelbase.py\", line 399, in execute_request\n",
            "    user_expressions, allow_stdin)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/ipykernel/ipkernel.py\", line 196, in do_execute\n",
            "    res = shell.run_cell(code, store_history=store_history, silent=silent)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/ipykernel/zmqshell.py\", line 533, in run_cell\n",
            "    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py\", line 2718, in run_cell\n",
            "    interactivity=interactivity, compiler=compiler, result=result)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py\", line 2822, in run_ast_nodes\n",
            "    if self.run_code(code, result):\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py\", line 2882, in run_code\n",
            "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
            "  File \"<ipython-input-176-d5c6b785332b>\", line 140, in <module>\n",
            "    logger.debug ('b_sent_0',b.sent_0[0].shape,b.sent_0[1].shape)#TEXT.reverse(b.sent_0))\n",
            "  File \"/usr/lib/python3.6/logging/__init__.py\", line 1294, in debug\n",
            "    self._log(DEBUG, msg, args, **kwargs)\n",
            "  File \"/usr/lib/python3.6/logging/__init__.py\", line 1442, in _log\n",
            "    self.handle(record)\n",
            "  File \"/usr/lib/python3.6/logging/__init__.py\", line 1452, in handle\n",
            "    self.callHandlers(record)\n",
            "  File \"/usr/lib/python3.6/logging/__init__.py\", line 1514, in callHandlers\n",
            "    hdlr.handle(record)\n",
            "  File \"/usr/lib/python3.6/logging/__init__.py\", line 863, in handle\n",
            "    self.emit(record)\n",
            "  File \"/usr/lib/python3.6/logging/__init__.py\", line 998, in emit\n",
            "    self.handleError(record)\n",
            "  File \"<ipython-input-170-8b50c71c9ffe>\", line 5, in handleError\n",
            "    traceback.print_stack()\n",
            "  File \"/usr/lib/python3.6/runpy.py\", line 193, in _run_module_as_main\n",
            "    \"__main__\", mod_spec)\n",
            "  File \"/usr/lib/python3.6/runpy.py\", line 85, in _run_code\n",
            "    exec(code, run_globals)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py\", line 16, in <module>\n",
            "    app.launch_new_instance()\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/traitlets/config/application.py\", line 658, in launch_instance\n",
            "    app.start()\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/ipykernel/kernelapp.py\", line 477, in start\n",
            "    ioloop.IOLoop.instance().start()\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/zmq/eventloop/ioloop.py\", line 177, in start\n",
            "    super(ZMQIOLoop, self).start()\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tornado/ioloop.py\", line 888, in start\n",
            "    handler_func(fd_obj, events)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tornado/stack_context.py\", line 277, in null_wrapper\n",
            "    return fn(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/zmq/eventloop/zmqstream.py\", line 440, in _handle_events\n",
            "    self._handle_recv()\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/zmq/eventloop/zmqstream.py\", line 472, in _handle_recv\n",
            "    self._run_callback(callback, msg)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/zmq/eventloop/zmqstream.py\", line 414, in _run_callback\n",
            "    callback(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tornado/stack_context.py\", line 277, in null_wrapper\n",
            "    return fn(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/ipykernel/kernelbase.py\", line 283, in dispatcher\n",
            "    return self.dispatch_shell(stream, msg)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/ipykernel/kernelbase.py\", line 235, in dispatch_shell\n",
            "    handler(stream, idents, msg)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/ipykernel/kernelbase.py\", line 399, in execute_request\n",
            "    user_expressions, allow_stdin)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/ipykernel/ipkernel.py\", line 196, in do_execute\n",
            "    res = shell.run_cell(code, store_history=store_history, silent=silent)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/ipykernel/zmqshell.py\", line 533, in run_cell\n",
            "    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py\", line 2718, in run_cell\n",
            "    interactivity=interactivity, compiler=compiler, result=result)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py\", line 2822, in run_ast_nodes\n",
            "    if self.run_code(code, result):\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py\", line 2882, in run_code\n",
            "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
            "  File \"<ipython-input-176-d5c6b785332b>\", line 142, in <module>\n",
            "    sd_loss, sd_acc = train_scene_discriminator(b)\n",
            "  File \"<ipython-input-176-d5c6b785332b>\", line 99, in train_scene_discriminator\n",
            "    logger.debug('adv_disc out',out.shape,'is_x_0',y.shape)\n",
            "  File \"/usr/lib/python3.6/logging/__init__.py\", line 1294, in debug\n",
            "    self._log(DEBUG, msg, args, **kwargs)\n",
            "  File \"/usr/lib/python3.6/logging/__init__.py\", line 1442, in _log\n",
            "    self.handle(record)\n",
            "  File \"/usr/lib/python3.6/logging/__init__.py\", line 1452, in handle\n",
            "    self.callHandlers(record)\n",
            "  File \"/usr/lib/python3.6/logging/__init__.py\", line 1514, in callHandlers\n",
            "    hdlr.handle(record)\n",
            "  File \"/usr/lib/python3.6/logging/__init__.py\", line 863, in handle\n",
            "    self.emit(record)\n",
            "  File \"/usr/lib/python3.6/logging/__init__.py\", line 998, in emit\n",
            "    self.handleError(record)\n",
            "  File \"<ipython-input-170-8b50c71c9ffe>\", line 5, in handleError\n",
            "    traceback.print_stack()\n",
            "  File \"/usr/lib/python3.6/runpy.py\", line 193, in _run_module_as_main\n",
            "    \"__main__\", mod_spec)\n",
            "  File \"/usr/lib/python3.6/runpy.py\", line 85, in _run_code\n",
            "    exec(code, run_globals)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py\", line 16, in <module>\n",
            "    app.launch_new_instance()\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/traitlets/config/application.py\", line 658, in launch_instance\n",
            "    app.start()\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/ipykernel/kernelapp.py\", line 477, in start\n",
            "    ioloop.IOLoop.instance().start()\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/zmq/eventloop/ioloop.py\", line 177, in start\n",
            "    super(ZMQIOLoop, self).start()\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tornado/ioloop.py\", line 888, in start\n",
            "    handler_func(fd_obj, events)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tornado/stack_context.py\", line 277, in null_wrapper\n",
            "    return fn(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/zmq/eventloop/zmqstream.py\", line 440, in _handle_events\n",
            "    self._handle_recv()\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/zmq/eventloop/zmqstream.py\", line 472, in _handle_recv\n",
            "    self._run_callback(callback, msg)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/zmq/eventloop/zmqstream.py\", line 414, in _run_callback\n",
            "    callback(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tornado/stack_context.py\", line 277, in null_wrapper\n",
            "    return fn(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/ipykernel/kernelbase.py\", line 283, in dispatcher\n",
            "    return self.dispatch_shell(stream, msg)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/ipykernel/kernelbase.py\", line 235, in dispatch_shell\n",
            "    handler(stream, idents, msg)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/ipykernel/kernelbase.py\", line 399, in execute_request\n",
            "    user_expressions, allow_stdin)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/ipykernel/ipkernel.py\", line 196, in do_execute\n",
            "    res = shell.run_cell(code, store_history=store_history, silent=silent)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/ipykernel/zmqshell.py\", line 533, in run_cell\n",
            "    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py\", line 2718, in run_cell\n",
            "    interactivity=interactivity, compiler=compiler, result=result)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py\", line 2822, in run_ast_nodes\n",
            "    if self.run_code(code, result):\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py\", line 2882, in run_code\n",
            "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
            "  File \"<ipython-input-176-d5c6b785332b>\", line 147, in <module>\n",
            "    sim_loss, rec_loss, anti_disc_loss = train(b)\n",
            "  File \"<ipython-input-176-d5c6b785332b>\", line 20, in train\n",
            "    logger.debug('sent0',sent0[0].shape,sent0[1].shape)\n",
            "  File \"/usr/lib/python3.6/logging/__init__.py\", line 1294, in debug\n",
            "    self._log(DEBUG, msg, args, **kwargs)\n",
            "  File \"/usr/lib/python3.6/logging/__init__.py\", line 1442, in _log\n",
            "    self.handle(record)\n",
            "  File \"/usr/lib/python3.6/logging/__init__.py\", line 1452, in handle\n",
            "    self.callHandlers(record)\n",
            "  File \"/usr/lib/python3.6/logging/__init__.py\", line 1514, in callHandlers\n",
            "    hdlr.handle(record)\n",
            "  File \"/usr/lib/python3.6/logging/__init__.py\", line 863, in handle\n",
            "    self.emit(record)\n",
            "  File \"/usr/lib/python3.6/logging/__init__.py\", line 998, in emit\n",
            "    self.handleError(record)\n",
            "  File \"<ipython-input-170-8b50c71c9ffe>\", line 5, in handleError\n",
            "    traceback.print_stack()\n",
            "08:28:16 DEBUG:[[0.5035684  0.49983537 0.5083363 ]]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "h_sem0 shape torch.Size([32, 20])\n",
            "h_sem1.h_sty0 torch.Size([32, 20]) torch.Size([32, 5]) torch.Size([1, 32, 25])\n",
            "$$$$$$$$$$ recon_sent0 length 50 each torch.Size([32, 43])\n",
            "recon_target torch.Size([32, 25]) while decoder outputs 50\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-176-d5c6b785332b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    145\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    146\u001b[0m         \u001b[0;31m# train main model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 147\u001b[0;31m         \u001b[0msim_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrec_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0manti_disc_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    148\u001b[0m         \u001b[0mepoch_sim_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0msim_loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m         \u001b[0mepoch_rec_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mrec_loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-176-d5c6b785332b>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(b)\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m     \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdebug\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0madv_disc_p\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m     \u001b[0madv_target\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFloatTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfull\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msent0\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfill_value\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m     \u001b[0;31m# the loss below is a parabula with min at log(0.5)=0.693... see documentation above\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m     \u001b[0madv_disc_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBCELoss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0madv_disc_p\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madv_target\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'tuple' object has no attribute 'shape'"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "hp_41_yw0vpK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "d2ebc07e-2ee3-469c-d5f3-f30d7c910fc6"
      },
      "cell_type": "code",
      "source": [
        "''' BCE dynamics\n",
        "bce=lambda a,p: nn.BCELoss()(torch.tensor(a),torch.tensor(p)).numpy()\n",
        "#p= np.array([[0.5001803,  0.50018024, 0.5001803 ]])\n",
        "p = np.array([[1.0,1.0,1.0]]); a = np.array([[0.0,0.0,0.0]]); loss = bce(p,a) ; print (a,p,loss)\n",
        "p = np.array([[1.0,1.0,1.0]]); a = np.array([[1.0,0.0,0.0]]); loss = bce(p,a) ; print (a,p,loss)\n",
        "p = np.array([[1.0,1.0,0.0]]); a = np.array([[0.5,0.5,0.5]]); loss = bce(p,a) ; print (a,p,loss)\n",
        "p = np.array([[0.5,0.5,0.5]]); a = np.array([[0.5,0.5,0.5]]); loss = bce(p,a) ; print (a,p,loss)\n",
        "p = np.array([[0.6,0.4,0.5]]); a = np.array([[0.5,0.5,0.5]]); loss = bce(p,a) ; print (a,p,loss)\n",
        "\n",
        "#       -1*( y* log(p) + (1-y) log(1-p) )\n",
        "#p=0.5  -1   y* 0.693  + (1-y)* 0.693  == -0.693 (y+1-y) = -0.693\n",
        "\n",
        "#a=0.5  -1* (0.5*log(p)+ 0.5*log(1-p)) = -0.5(log(p)+log(1-p))\n",
        "'''\n",
        "1"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "metadata": {
        "id": "ARPHhHtNit6k",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "??DecoderRNN"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Sg7Ny6D4QlXE",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# EVAL"
      ]
    },
    {
      "metadata": {
        "id": "8df9zoymohYU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 298
        },
        "outputId": "f48a1a9f-4995-4ca5-95e0-9fda5fb1acb6"
      },
      "cell_type": "code",
      "source": [
        "eval_ds=  TimePairsDataset(1e7,2)\n",
        "eval_batch_generator=iter(DataLoader(eval_ds,batch_size=3))\n",
        "x,y = next(eval_batch_generator)\n",
        "print (x.shape,y.shape)\n",
        "\n",
        "sent0 = None    # x[0] semantic0   , style0\n",
        "sent1 = x[:,1]  # x[1] semantic0   , style1 \n",
        "sent2 = x[:,2]  # x[2] semantic0orX, style0 (1/2 the time 0 , half X)\n",
        "\n",
        "h_sem = en_sem(sent1)\n",
        "h_sty = en_sty(sent2)\n",
        "p = decoder(torch.cat([h_sem,h_sty],dim=1))\n",
        "  \n",
        "for i in range(len(x)) :\n",
        "  print ('source sent. take semantics: ',eval_ds.untokenize_tokens(sent1[i]))\n",
        "  print ('target sent. take style    : ',eval_ds.untokenize_tokens(sent2[i]))\n",
        "  print ('target sent                : ',eval_ds.untokenize_tokens(p[i]))\n",
        "  print ('\\n')\n",
        "  \n",
        "  \n",
        "  \n",
        "  "
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([3, 3, 20]) torch.Size([3, 1])\n",
            "source sent. take semantics:  Jan 01 1970 00:00:02\n",
            "target sent. take style    :  04/Apr/1970 22:51:53\n",
            "target sent                :  ;MS3EJ&1970 06:00:35\n",
            "\n",
            "\n",
            "source sent. take semantics:  Jan 01 1970 00:00:02\n",
            "target sent. take style    :  01/Jan/1970 00:00:02\n",
            "target sent                :  ;MS3EJ&1970 06:00:35\n",
            "\n",
            "\n",
            "source sent. take semantics:  Jan 01 1970 00:00:02\n",
            "target sent. take style    :  02/Feb/1970 11:32:26\n",
            "target sent                :  ;MS3EJ&1970 06:00:35\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "GSPSoEXTgVV_",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#from here: http://anie.me/On-Torchtext/\n",
        "from torchtext.data import Field\n",
        "import torch\n",
        "import torch.nn\n",
        "\n",
        "class SplitReversibleField(Field):\n",
        "\n",
        "    def __init__(self, untokenize_char='', **kwargs):\n",
        "        super(SplitReversibleField, self).__init__(**kwargs)\n",
        "        self.untokenize_char = untokenize_char\n",
        "        \n",
        "\n",
        "    def reverse(self, batch):\n",
        "\n",
        "        if not self.batch_first:\n",
        "            batch = batch.t()\n",
        "        with torch.cuda.device_of(batch):\n",
        "            batch = batch.tolist()\n",
        "        batch = [[self.vocab.itos[ind] for ind in ex] for ex in batch]  # denumericalize\n",
        "\n",
        "        def trim(s, t):\n",
        "            sentence = []\n",
        "            for w in s:\n",
        "                if w == t:\n",
        "                    break\n",
        "                sentence.append(w)\n",
        "            return sentence\n",
        "\n",
        "        batch = [trim(ex, self.eos_token) for ex in batch]  # trim past frst eos\n",
        "\n",
        "        def filter_special(tok):\n",
        "            return tok not in (self.init_token, self.pad_token)\n",
        "\n",
        "        batch = [filter(filter_special, ex) for ex in batch]\n",
        "        return [self.untokenize_char.join(ex) for ex in batch]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "sQLllWeCXlrK",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Fx9wR-zaDxTc",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# MY EncoderRNN self made buggy start of result"
      ]
    },
    {
      "metadata": {
        "id": "lRy7otShNctN",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        ""
      ]
    },
    {
      "metadata": {
        "id": "vAVE29Z8hgHf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "139999cb-22e4-48ec-c033-df4d34f4cc82"
      },
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "%matplotlib inline\n",
        "\n",
        "sample = next(train_iter)\n",
        "device='cpu'\n",
        "'''\n",
        "class MyEncoderRNN(nn.Module):  #see https://pytorch.org/tutorials/intermediate/seq2seq_translation_tutorial.html\n",
        "    def __init__(self, vocab_size, hidden_size):\n",
        "        super(EncoderRNN, self).__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "        self.embedding = nn.Embedding(vocab_size, hidden_size)\n",
        "        self.gru = nn.GRU(hidden_size, hidden_size)\n",
        "\n",
        "    def forward(self, input, hidden):\n",
        "        \"\"\" input:  1xbs :  example: 1   x 32\n",
        "            hidden: hxbs :  example: 100 x 32\n",
        "        \"\"\"\n",
        "        print ('EncoderRNN input',input.shape, 'hidden',hidden.shape)\n",
        "        assert input.shape[1]==hidden.shape[1] # batch\n",
        "        assert input.shape[0]==1\n",
        "        assert hidden.shape[0]==self.hidden_size\n",
        "        \n",
        "        \n",
        "        embedded = self.embedding(input).view(1, input.shape[1], -1)\n",
        "        print (embedded.shape)\n",
        "        output, hidden = self.gru(embedded, hidden) #input must be 3 dimension\n",
        "        return output, hidden\n",
        "\n",
        "    def init_hidden(self,batch_size):\n",
        "        return torch.zeros( 1, self.hidden_size,batch_size, device=device)  \n",
        "\n",
        "class Encoder(nn.Module):\n",
        "    def __init__(self, encoder_rnn):\n",
        "        \"\"\" wrapper around EncoderRNN running on a full sequence in one fwd pass \"\"\"\n",
        "        super(Encoder, self).__init__()\n",
        "        self.encoder_rnn = encoder_rnn\n",
        "    \n",
        "    def forward(self, input):\n",
        "        print (input.shape)\n",
        "        sen_len, batch_size = input.shape\n",
        "        h= self.encoder_rnn.init_hidden(batch_size)\n",
        "        for i in range(sen_len):\n",
        "          o,h = self.encoder_rnn(input[i:i+1], h)\n",
        "        return h\n",
        "\n",
        "\n",
        "class MyDecoderRNN(nn.Module):\n",
        "    def __init__(self, input_hidden_size, output_vocab_size):\n",
        "        super(DecoderRNN, self).__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "\n",
        "        self.embedding = nn.Embedding(output_size, hidden_size)\n",
        "        self.gru = nn.GRU(hidden_size, hidden_size)\n",
        "        self.out = nn.Linear(hidden_size, output_vocab_size)\n",
        "        self.softmax = nn.LogSoftmax(dim=1)\n",
        "\n",
        "    def forward(self, input, hidden):\n",
        "        output = self.embedding(input).view(1, 1, -1)\n",
        "        output = F.relu(output)\n",
        "        output, hidden = self.gru(output, hidden)\n",
        "        output = self.softmax(self.out(output[0]))\n",
        "        return output, hidden\n",
        "\n",
        "    def initHidden(self):\n",
        "        return torch.zeros(1, 1, self.hidden_size, device=device)\n",
        "      \n",
        "      \n",
        "#decoder= MyDecoderRNN(opt.semantics_dim+opt.style_dim)   \n",
        "\n",
        "\n",
        "en_sem = Encoder(EncoderRNN(len(TEXT.vocab), opt.semantics_dim))\n",
        "en_sty = Encoder(EncoderRNN(len(TEXT.vocab), opt.style_dim))\n",
        "\n",
        "en_sem(sample.sent_0)\n",
        "'''\n",
        "1"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 64
        }
      ]
    },
    {
      "metadata": {
        "id": "PLIjIkZpNdxR",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# where this code came from?"
      ]
    },
    {
      "metadata": {
        "id": "IKcrmDmgLnJS",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "\n",
        "'''\n",
        "      \n",
        "en_sem = nn.Sequential(\n",
        "  # expect sentence_len,so from outside, cut a pair into x[0],x[1] and pass seperatly each\n",
        "  nn.Linear(sentence_len,19),\n",
        "  nn.ReLU(inplace=True), \n",
        "  nn.Linear(19,opt.semantics_dim),\n",
        "  #nn.Tanh()\n",
        ")\n",
        "\n",
        "en_sty= nn.Sequential(\n",
        "  nn.Linear(sentence_len,19),\n",
        "  nn.ReLU(inplace=True),\n",
        "  nn.Linear(19,opt.style_dim),\n",
        "  #nn.Tanh()\n",
        ")\n",
        "decoder = nn.Sequential(\n",
        "  # input concat of semantic and style\n",
        "  # output sentence_len , each word/char has currently value in range 0..1\n",
        "  nn.Linear(opt.semantics_dim+opt.style_dim,19),\n",
        "  nn.ReLU(inplace=True),\n",
        "  nn.Linear(19,60),\n",
        "  nn.ReLU(inplace=True),\n",
        "  nn.Linear(60,sentence_len),\n",
        "  # we apply MSE on this\n",
        ")\n",
        "adv_disc = nn.Sequential(\n",
        "  # input concat of two style\n",
        "  nn.Linear(2*opt.style_dim,6),\n",
        "  nn.ReLU(inplace=True),\n",
        "  nn.Linear(6,1),\n",
        "  nn.Sigmoid()  #Must be sigmoid, we apply later BCE\n",
        ")\n",
        "'''"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "jKl-9BxXNgvU",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "teacher_forcing_ratio = 0.5\n",
        "\n",
        "\n",
        "def train(input_tensor, target_tensor, encoder, decoder, encoder_optimizer, decoder_optimizer, criterion, max_length=MAX_LENGTH):\n",
        "    encoder_hidden = encoder.initHidden()\n",
        "\n",
        "    encoder_optimizer.zero_grad()\n",
        "    decoder_optimizer.zero_grad()\n",
        "\n",
        "    input_length = input_tensor.size(0)\n",
        "    target_length = target_tensor.size(0)\n",
        "\n",
        "    encoder_outputs = torch.zeros(max_length, encoder.hidden_size, device=device)\n",
        "\n",
        "    loss = 0\n",
        "\n",
        "    for ei in range(input_length):\n",
        "        encoder_output, encoder_hidden = encoder(\n",
        "            input_tensor[ei], encoder_hidden)\n",
        "        encoder_outputs[ei] = encoder_output[0, 0]\n",
        "\n",
        "    decoder_input = torch.tensor([[SOS_token]], device=device)\n",
        "\n",
        "    decoder_hidden = encoder_hidden\n",
        "\n",
        "    use_teacher_forcing = True if random.random() < teacher_forcing_ratio else False\n",
        "\n",
        "    if use_teacher_forcing:\n",
        "        # Teacher forcing: Feed the target as the next input\n",
        "        for di in range(target_length):\n",
        "            decoder_output, decoder_hidden, decoder_attention = decoder(\n",
        "                decoder_input, decoder_hidden, encoder_outputs)\n",
        "            loss += criterion(decoder_output, target_tensor[di])\n",
        "            decoder_input = target_tensor[di]  # Teacher forcing\n",
        "\n",
        "    else:\n",
        "        # Without teacher forcing: use its own predictions as the next input\n",
        "        for di in range(target_length):\n",
        "            decoder_output, decoder_hidden, decoder_attention = decoder(\n",
        "                decoder_input, decoder_hidden, encoder_outputs)\n",
        "            topv, topi = decoder_output.topk(1)\n",
        "            decoder_input = topi.squeeze().detach()  # detach from history as input\n",
        "\n",
        "            loss += criterion(decoder_output, target_tensor[di])\n",
        "            if decoder_input.item() == EOS_token:\n",
        "                break\n",
        "\n",
        "    loss.backward()\n",
        "\n",
        "    encoder_optimizer.step()\n",
        "    decoder_optimizer.step()\n",
        "\n",
        "    return loss.item() / target_length"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "crjmKimmLijT",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "'''from torch.utils.data import Dataset#, DataLoader\n",
        "import numpy as np\n",
        "import time\n",
        "\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import numpy as np\n",
        "%matplotlib inline\n",
        "\n",
        "class TimePairsDataset(Dataset):\n",
        "  \n",
        "  def __init__(self,length,time_mod_3_result): #1e9 means 1970-2001\n",
        "    \"\"\"\n",
        "    time_mod_3_result - to make sure time is train/test/valid is different, pass\n",
        "    a different result here.\n",
        "    \"\"\"\n",
        "    #super().__init__()\n",
        "    self.length = length\n",
        "    self.formats = [\"%b %d %Y %H:%M:%S\", \"%m/%b/%Y %H:%M:%S\"] # STAY WITH 2 STYLES, DISCRIMINATOR SIMPLER #\"%d %b %Y %H:%M:%S\",\n",
        "    self.time_mod_3_result=time_mod_3_result\n",
        "  \n",
        "  \n",
        "  def __len__(self):\n",
        "    return int(self.length)\n",
        "  \n",
        "  def _choose(self,idx,style):\n",
        "    st = time.strftime(self.formats[style],time.gmtime(idx))\n",
        "    return np.array([ord(c) for c in list(st)][:24],np.float32)/120 #chars are up to that\n",
        "  \n",
        "  def untokenize_sample(self,sample):\n",
        "    \"\"\" sample x and y, x contains multiple sentences\"\"\"\n",
        "    x,y = sample\n",
        "    out=[] \n",
        "    for tokens in x:    \n",
        "      out.append(self.untokenize_tokens(tokens) )\n",
        "    return out,y\n",
        "\n",
        "  def untokenize_tokens(self,tokens):\n",
        "    \"\"\" one sentence\"\"\"\n",
        "    if type(tokens)==torch.Tensor:\n",
        "      tokens = tokens.detach().numpy()\n",
        "    return ''.join([chr(int(round(token*120))) for token in tokens])\n",
        "  \n",
        "  \n",
        "  def _tvt(self,idx):\n",
        "    # for 10, if train, return 9, valid 10, test 11\n",
        "    return (idx//3) * 3 + self.time_mod_3_result #10//3 * 3 + x = 9+x\n",
        "  \n",
        "  def __getitem__(self,idx):\n",
        "    \"\"\" x -  x[0] semantic0   , style0\n",
        "             x[1] semantic0   , style1   \n",
        "             x[2] semantic0orX, style0 (1/2 the time 0 , half X)\n",
        "    \"\"\"\n",
        "    \n",
        "    #other_idx is 50% same, 50% other\n",
        "    other_idx = (idx + np.random.randint(0,2)*(np.random.randint(10,self.length))) %self.length\n",
        "    #print (idx,other_idx)\n",
        "    idx = self._tvt(idx)\n",
        "    other_idx = self._tvt(other_idx)\n",
        "    #print (idx,other_idx)\n",
        "    \n",
        "    # two random formats\n",
        "    random_fs= np.random.choice(len(self.formats),size=2,replace=False)\n",
        "    #print (random_fs)\n",
        "    x_list = []\n",
        "    x_list.append(self._choose(idx,random_fs[0]))\n",
        "    x_list.append(self._choose(idx,random_fs[1]))\n",
        "    x_list.append(self._choose(other_idx,random_fs[0]))\n",
        "    \n",
        "    y = np.array([idx==other_idx],np.float32)\n",
        "    \n",
        "   \n",
        "    return  (np.vstack(x_list), y)\n",
        "\n",
        "def test():\n",
        "  dataset = TimePairsDataset(1e9,1)\n",
        "  sample = dataset[9] ;#print (sample)\n",
        "  print (dataset.untokenize_sample(sample))\n",
        "  print ('shapes x,y',sample[0].shape,sample[1].shape)\n",
        "  \n",
        "test()\n",
        "'''"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}
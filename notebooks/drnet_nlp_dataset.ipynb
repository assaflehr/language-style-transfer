{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "drnet_nlp_dataset.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [
        "VlCwK-JQbNoY",
        "RurR2Mjb4Ls6"
      ],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "[View in Colaboratory](https://colab.research.google.com/github/assaflehr/language-style-transfer/blob/master/notebooks/drnet_nlp_dataset.ipynb)"
      ]
    },
    {
      "metadata": {
        "id": "9DZmHoW4hbsO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 2466
        },
        "outputId": "ee4bc8ad-e46d-4345-c857-dd82e0291e5c"
      },
      "cell_type": "code",
      "source": [
        "#!pip install spacy   #can take few minutes\n",
        "#!python -m spacy download en\n",
        "!pip install git+https://github.com/fastai/fastai.git\n",
        "!pip install torch -U # 0.4 at-least"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting git+https://github.com/fastai/fastai.git\r\n",
            "  Cloning https://github.com/fastai/fastai.git to /tmp/pip-req-build-bojptk6m\n",
            "Collecting bcolz (from fastai==0.7.0)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/5c/4e/23942de9d5c0fb16f10335fa83e52b431bcb8c0d4a8419c9ac206268c279/bcolz-1.2.1.tar.gz (1.5MB)\n",
            "\u001b[K    100% |████████████████████████████████| 1.5MB 7.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: bleach in /usr/local/lib/python3.6/dist-packages (from fastai==0.7.0) (2.1.3)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.6/dist-packages (from fastai==0.7.0) (2018.4.16)\n",
            "Requirement already satisfied: cycler in /usr/local/lib/python3.6/dist-packages (from fastai==0.7.0) (0.10.0)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.6/dist-packages (from fastai==0.7.0) (4.3.0)\n",
            "Requirement already satisfied: entrypoints in /usr/local/lib/python3.6/dist-packages (from fastai==0.7.0) (0.2.3)\n",
            "Collecting feather-format (from fastai==0.7.0)\n",
            "  Downloading https://files.pythonhosted.org/packages/08/55/940b97cc6f19a19f5dab9efef2f68a0ce43a7632f858b272391f0b851a7e/feather-format-0.4.0.tar.gz\n",
            "Collecting graphviz (from fastai==0.7.0)\n",
            "  Downloading https://files.pythonhosted.org/packages/53/39/4ab213673844e0c004bed8a0781a0721a3f6bb23eb8854ee75c236428892/graphviz-0.8.4-py2.py3-none-any.whl\n",
            "Requirement already satisfied: html5lib in /usr/local/lib/python3.6/dist-packages (from fastai==0.7.0) (1.0.1)\n",
            "Requirement already satisfied: ipykernel in /usr/local/lib/python3.6/dist-packages (from fastai==0.7.0) (4.6.1)\n",
            "Requirement already satisfied: ipython in /usr/local/lib/python3.6/dist-packages (from fastai==0.7.0) (5.5.0)\n",
            "Requirement already satisfied: ipython-genutils in /usr/local/lib/python3.6/dist-packages (from fastai==0.7.0) (0.2.0)\n",
            "Collecting ipywidgets (from fastai==0.7.0)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f0/5d/868df21e3b004a5a61294cab70e1f6f44986933eb3aa9c396dfd5112acb2/ipywidgets-7.3.0-py2.py3-none-any.whl (109kB)\n",
            "\u001b[K    100% |████████████████████████████████| 112kB 10.7MB/s \n",
            "\u001b[?25hCollecting isoweek (from fastai==0.7.0)\n",
            "  Downloading https://files.pythonhosted.org/packages/c2/d4/fe7e2637975c476734fcbf53776e650a29680194eb0dd21dbdc020ca92de/isoweek-1.3.3-py2.py3-none-any.whl\n",
            "Collecting jedi (from fastai==0.7.0)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/3d/68/8bbf0ef969095a13ba0d4c77c1945bd86e9811960d052510551d29a2f23b/jedi-0.12.1-py2.py3-none-any.whl (174kB)\n",
            "\u001b[K    100% |████████████████████████████████| 184kB 10.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: Jinja2 in /usr/local/lib/python3.6/dist-packages (from fastai==0.7.0) (2.10)\n",
            "Requirement already satisfied: jsonschema in /usr/local/lib/python3.6/dist-packages (from fastai==0.7.0) (2.6.0)\n",
            "Collecting jupyter (from fastai==0.7.0)\n",
            "  Downloading https://files.pythonhosted.org/packages/83/df/0f5dd132200728a86190397e1ea87cd76244e42d39ec5e88efd25b2abd7e/jupyter-1.0.0-py2.py3-none-any.whl\n",
            "Requirement already satisfied: MarkupSafe in /usr/local/lib/python3.6/dist-packages (from fastai==0.7.0) (1.0)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.6/dist-packages (from fastai==0.7.0) (2.1.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from fastai==0.7.0) (1.14.5)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.6/dist-packages (from fastai==0.7.0) (3.4.2.17)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.6/dist-packages (from fastai==0.7.0) (0.22.0)\n",
            "Collecting pandas_summary (from fastai==0.7.0)\n",
            "  Downloading https://files.pythonhosted.org/packages/3d/a7/0364272be0c6561c45d67edec8a7bf0532d56b830438168f9078f7720f63/pandas-summary-0.0.41.tar.gz\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.6/dist-packages (from fastai==0.7.0) (0.7.4)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.6/dist-packages (from fastai==0.7.0) (4.0.0)\n",
            "Collecting plotnine (from fastai==0.7.0)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/3a/68/cf39dfde4e9fd886703621e3393cd8103cb48d5ecc95b8f048ec148e53a6/plotnine-0.3.0-py2.py3-none-any.whl (3.4MB)\n",
            "\u001b[K    100% |████████████████████████████████| 3.4MB 8.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: ptyprocess in /usr/local/lib/python3.6/dist-packages (from fastai==0.7.0) (0.6.0)\n",
            "Requirement already satisfied: Pygments in /usr/local/lib/python3.6/dist-packages (from fastai==0.7.0) (2.1.3)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.6/dist-packages (from fastai==0.7.0) (2.2.0)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.6/dist-packages (from fastai==0.7.0) (2.5.3)\n",
            "Requirement already satisfied: pytz in /usr/local/lib/python3.6/dist-packages (from fastai==0.7.0) (2018.5)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.6/dist-packages (from fastai==0.7.0) (3.13)\n",
            "Requirement already satisfied: pyzmq in /usr/local/lib/python3.6/dist-packages (from fastai==0.7.0) (16.0.4)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from fastai==0.7.0) (0.19.1)\n",
            "Requirement already satisfied: seaborn in /usr/local/lib/python3.6/dist-packages (from fastai==0.7.0) (0.7.1)\n",
            "Requirement already satisfied: simplegeneric in /usr/local/lib/python3.6/dist-packages (from fastai==0.7.0) (0.8.1)\n",
            "Collecting sklearn_pandas (from fastai==0.7.0)\n",
            "  Downloading https://files.pythonhosted.org/packages/c5/9e/42d7bcddb09a3ff52d0c60c810ba5d0fded28abbe320c85bbf7368192956/sklearn_pandas-1.6.0-py2.py3-none-any.whl\n",
            "Requirement already satisfied: testpath in /usr/local/lib/python3.6/dist-packages (from fastai==0.7.0) (0.3.1)\n",
            "Collecting torch<0.4 (from fastai==0.7.0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/5b/a5/e8b50b55b1abac9f1e3346c4242f1e42a82d368a8442cbd50c532922f6c4/torch-0.3.1-cp36-cp36m-manylinux1_x86_64.whl (496.4MB)\n",
            "\u001b[K    100% |████████████████████████████████| 496.4MB 29kB/s \n",
            "\u001b[?25hCollecting torchtext (from fastai==0.7.0)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/78/90/474d5944d43001a6e72b9aaed5c3e4f77516fbef2317002da2096fd8b5ea/torchtext-0.2.3.tar.gz (42kB)\n",
            "\u001b[K    100% |████████████████████████████████| 51kB 12.9MB/s \n",
            "\u001b[?25hCollecting torchvision (from fastai==0.7.0)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ca/0d/f00b2885711e08bd71242ebe7b96561e6f6d01fdb4b9dcf4d37e2e13c5e1/torchvision-0.2.1-py2.py3-none-any.whl (54kB)\n",
            "\u001b[K    100% |████████████████████████████████| 61kB 13.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: tornado in /usr/local/lib/python3.6/dist-packages (from fastai==0.7.0) (4.5.3)\n",
            "Collecting tqdm (from fastai==0.7.0)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/93/24/6ab1df969db228aed36a648a8959d1027099ce45fad67532b9673d533318/tqdm-4.23.4-py2.py3-none-any.whl (42kB)\n",
            "\u001b[K    100% |████████████████████████████████| 51kB 22.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: traitlets in /usr/local/lib/python3.6/dist-packages (from fastai==0.7.0) (4.3.2)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.6/dist-packages (from fastai==0.7.0) (0.1.7)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.6/dist-packages (from fastai==0.7.0) (0.5.1)\n",
            "Collecting widgetsnbextension (from fastai==0.7.0)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/b9/43/f6ff09448f7b961e102fd75b7e46a5d44b68b9746bb1ab5c4be64c3e236d/widgetsnbextension-3.3.0-py2.py3-none-any.whl (2.2MB)\n",
            "\u001b[K    100% |████████████████████████████████| 2.2MB 6.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from bleach->fastai==0.7.0) (1.11.0)\n",
            "Collecting pyarrow>=0.4.0 (from feather-format->fastai==0.7.0)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/fe/27/576e6c979bfa5f63070f809c930aa85d6198b91d17a64866234597ba861f/pyarrow-0.9.0-cp36-cp36m-manylinux1_x86_64.whl (13.7MB)\n",
            "\u001b[K    100% |████████████████████████████████| 13.7MB 2.0MB/s \n",
            "\u001b[?25hRequirement already satisfied: jupyter-client in /usr/local/lib/python3.6/dist-packages (from ipykernel->fastai==0.7.0) (5.2.3)\n",
            "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.6/dist-packages (from ipython->fastai==0.7.0) (39.1.0)\n",
            "Requirement already satisfied: pexpect; sys_platform != \"win32\" in /usr/local/lib/python3.6/dist-packages (from ipython->fastai==0.7.0) (4.6.0)\n",
            "Requirement already satisfied: prompt-toolkit<2.0.0,>=1.0.4 in /usr/local/lib/python3.6/dist-packages (from ipython->fastai==0.7.0) (1.0.15)\n",
            "Requirement already satisfied: nbformat>=4.2.0 in /usr/local/lib/python3.6/dist-packages (from ipywidgets->fastai==0.7.0) (4.4.0)\n",
            "Collecting parso>=0.3.0 (from jedi->fastai==0.7.0)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/09/51/9c48a46334be50c13d25a3afe55fa05c445699304c5ad32619de953a2305/parso-0.3.1-py2.py3-none-any.whl (88kB)\n",
            "\u001b[K    100% |████████████████████████████████| 92kB 26.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: nbconvert in /usr/local/lib/python3.6/dist-packages (from jupyter->fastai==0.7.0) (5.3.1)\n",
            "Requirement already satisfied: notebook in /usr/local/lib/python3.6/dist-packages (from jupyter->fastai==0.7.0) (5.2.2)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Collecting jupyter-console (from jupyter->fastai==0.7.0)\n",
            "  Downloading https://files.pythonhosted.org/packages/77/82/6469cd7fccf7958cbe5dce2e623f1e3c5e27f1bb1ad36d90519bc2d5d370/jupyter_console-5.2.0-py2.py3-none-any.whl\n",
            "Collecting qtconsole (from jupyter->fastai==0.7.0)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/90/ff/047e0dca2627b162866920e7aa93f04523c0ae81e5c67060eec85701992d/qtconsole-4.3.1-py2.py3-none-any.whl (108kB)\n",
            "\u001b[K    100% |████████████████████████████████| 112kB 25.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: olefile in /usr/local/lib/python3.6/dist-packages (from Pillow->fastai==0.7.0) (0.45.1)\n",
            "Requirement already satisfied: statsmodels>=0.8.0 in /usr/local/lib/python3.6/dist-packages (from plotnine->fastai==0.7.0) (0.8.0)\n",
            "Collecting mizani>=0.4.1 (from plotnine->fastai==0.7.0)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/52/01/8a3b4c6e45749674a1e5241174b4b63cd6435125e124bec275f3e02c96ac/mizani-0.4.6-py2.py3-none-any.whl (65kB)\n",
            "\u001b[K    100% |████████████████████████████████| 71kB 27.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: patsy>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from plotnine->fastai==0.7.0) (0.5.0)\n",
            "Requirement already satisfied: scikit-learn>=0.15.0 in /usr/local/lib/python3.6/dist-packages (from sklearn_pandas->fastai==0.7.0) (0.19.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from torchtext->fastai==0.7.0) (2.18.4)\n",
            "Requirement already satisfied: jupyter-core in /usr/local/lib/python3.6/dist-packages (from jupyter-client->ipykernel->fastai==0.7.0) (4.4.0)\n",
            "Requirement already satisfied: pandocfilters>=1.4.1 in /usr/local/lib/python3.6/dist-packages (from nbconvert->jupyter->fastai==0.7.0) (1.4.2)\n",
            "Requirement already satisfied: mistune>=0.7.4 in /usr/local/lib/python3.6/dist-packages (from nbconvert->jupyter->fastai==0.7.0) (0.8.3)\n",
            "Requirement already satisfied: terminado>=0.3.3; sys_platform != \"win32\" in /usr/local/lib/python3.6/dist-packages (from notebook->jupyter->fastai==0.7.0) (0.8.1)\n",
            "Collecting palettable (from mizani>=0.4.1->plotnine->fastai==0.7.0)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/56/8a/84537c0354f0d1f03bf644b71bf8e0a50db9c1294181905721a5f3efbf66/palettable-3.1.1-py2.py3-none-any.whl (77kB)\n",
            "\u001b[K    100% |████████████████████████████████| 81kB 25.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->torchtext->fastai==0.7.0) (3.0.4)\n",
            "Requirement already satisfied: urllib3<1.23,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->torchtext->fastai==0.7.0) (1.22)\n",
            "Requirement already satisfied: idna<2.7,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->torchtext->fastai==0.7.0) (2.6)\n",
            "Building wheels for collected packages: fastai, bcolz, feather-format, pandas-summary, torchtext\n",
            "  Running setup.py bdist_wheel for fastai ... \u001b[?25l-\b \b\\\b \bdone\n",
            "\u001b[?25h  Stored in directory: /tmp/pip-ephem-wheel-cache-sqgcnxmq/wheels/cf/46/39/b2d08762125ed2376861976ab2c4ac30c029b86e375735d9b8\n",
            "  Running setup.py bdist_wheel for bcolz ... \u001b[?25l-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \bdone\n",
            "\u001b[?25h  Stored in directory: /content/.cache/pip/wheels/9f/78/26/fb8c0acb91a100dc8914bf236c4eaa4b207cb876893c40b745\n",
            "  Running setup.py bdist_wheel for feather-format ... \u001b[?25l-\b \bdone\n",
            "\u001b[?25h  Stored in directory: /content/.cache/pip/wheels/85/7d/12/2dfa5c0195f921ac935f5e8f27deada74972edc0ae9988a9c1\n",
            "  Running setup.py bdist_wheel for pandas-summary ... \u001b[?25l-\b \bdone\n",
            "\u001b[?25h  Stored in directory: /content/.cache/pip/wheels/86/a9/6b/36b727a9ec687dac08bd3d0501cddd7b1a223943513eb04a03\n",
            "  Running setup.py bdist_wheel for torchtext ... \u001b[?25l-\b \b\\\b \bdone\n",
            "\u001b[?25h  Stored in directory: /content/.cache/pip/wheels/42/a6/f4/b267328bde6bb680094a0c173e8e5627ccc99543abded97204\n",
            "Successfully built fastai bcolz feather-format pandas-summary torchtext\n",
            "\u001b[31mplotnine 0.3.0 has requirement scipy>=1.0.0, but you'll have scipy 0.19.1 which is incompatible.\u001b[0m\n",
            "\u001b[31mtorchvision 0.2.1 has requirement pillow>=4.1.1, but you'll have pillow 4.0.0 which is incompatible.\u001b[0m\n",
            "Installing collected packages: bcolz, pyarrow, feather-format, graphviz, widgetsnbextension, ipywidgets, isoweek, parso, jedi, jupyter-console, qtconsole, jupyter, pandas-summary, palettable, mizani, plotnine, sklearn-pandas, torch, tqdm, torchtext, torchvision, fastai\n",
            "Successfully installed bcolz-1.2.1 fastai-0.7.0 feather-format-0.4.0 graphviz-0.8.4 ipywidgets-7.3.0 isoweek-1.3.3 jedi-0.12.1 jupyter-1.0.0 jupyter-console-5.2.0 mizani-0.4.6 palettable-3.1.1 pandas-summary-0.0.41 parso-0.3.1 plotnine-0.3.0 pyarrow-0.9.0 qtconsole-4.3.1 sklearn-pandas-1.6.0 torch-0.3.1 torchtext-0.2.3 torchvision-0.2.1 tqdm-4.23.4 widgetsnbextension-3.3.0\n",
            "Collecting torch\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/69/43/380514bd9663f1bf708abeb359b8b48d3fabb1c8e95bb3427a980a064c57/torch-0.4.0-cp36-cp36m-manylinux1_x86_64.whl (484.0MB)\n",
            "\u001b[K    18% |█████▉                          | 88.9MB 47.8MB/s eta 0:00:09"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[K    100% |████████████████████████████████| 484.0MB 13kB/s \n",
            "tcmalloc: large alloc 1073750016 bytes == 0x5bf1a000 @  0x7f5ad433b1c4 0x46d6a4 0x5fcbcc 0x4c494d 0x54f3c4 0x553aaf 0x54e4c8 0x54f4f6 0x553aaf 0x54efc1 0x54f24d 0x553aaf 0x54efc1 0x54f24d 0x553aaf 0x54efc1 0x54f24d 0x551ee0 0x54e4c8 0x54f4f6 0x553aaf 0x54efc1 0x54f24d 0x551ee0 0x54efc1 0x54f24d 0x551ee0 0x54e4c8 0x54f4f6 0x553aaf 0x54e4c8\n",
            "\u001b[31mtorchvision 0.2.1 has requirement pillow>=4.1.1, but you'll have pillow 4.0.0 which is incompatible.\u001b[0m\n",
            "\u001b[31mfastai 0.7.0 has requirement torch<0.4, but you'll have torch 0.4.0 which is incompatible.\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: torch\n",
            "  Found existing installation: torch 0.3.1\n",
            "    Uninstalling torch-0.3.1:\n",
            "      Successfully uninstalled torch-0.3.1\n",
            "Successfully installed torch-0.4.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "wbPufJ8sycZ2",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "UFVkIdJeI3PZ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "m1hlOS_vs_0U",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 723
        },
        "outputId": "afc35159-6675-43eb-a1bf-c96698453ec1"
      },
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "from fastai.metrics import *\n",
        "from fastai.model import *\n",
        "from fastai.dataset import *\n",
        "from fastai.core import *\n",
        "import fastai\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import numpy as np\n",
        "import time\n",
        "from fastai.imports import *\n",
        "from fastai.torch_imports import *\n",
        "from fastai.io import *\n",
        "%matplotlib inline\n",
        "\n",
        "class TimeDataset(BaseDataset):\n",
        "  \n",
        "  def __init__(self,length=1e3): #1e9 means 1970-2001\n",
        "    #super().__init__()\n",
        "    self.length = length\n",
        "    self.formats = [\"%b %d %Y %H:%M:%S\",\"%d %b %Y %H:%M:%S\", \"%m/%b/%Y %H:%M:%S\"]\n",
        "    self.x_dim = (10,)\n",
        "    self.y_dim = (len(self.formats),)\n",
        "    \n",
        "  def __len__(self):\n",
        "    return int(self.length)\n",
        "  \n",
        "  def transform(self,x):\n",
        "    return np.array([ord(c) for c in list(x)][:self.x_dim[0]],np.float32)/100 #chars are up to that\n",
        "\n",
        "  def __getitem__(self,idx):\n",
        "    \"\"\" choose one random format and format time idx with it\"\"\"\n",
        "    \n",
        "    # random seed is initialized before each batch, we use idx to be different\n",
        "    fs = len(self.formats)\n",
        "    \n",
        "    #idx = 666\n",
        "    #formats = np.remainder(idx + np.random.randint(0,fs,size=2),fs)\n",
        "    f=np.random.randint(0,fs)\n",
        "    \n",
        "    x = time.strftime(self.formats[f],time.gmtime(idx))\n",
        "    #print (x)\n",
        "    x= self.transform(x)\n",
        "    \n",
        "    y =  np.array(f ,np.int64 ) #0,1,2 must be Long to enalbe using NNLLoss\n",
        "    #y = np.eye(fs, dtype='int64')[f]          #y as one-hot (wastefull a bit)\n",
        "    \n",
        "    \n",
        "    return  (x, y)\n",
        "\n",
        "dataset = TimeDataset(1e3)          \n",
        "torch_dataloader = DataLoader(TimeDataset(1e3), batch_size=3, shuffle=False, num_workers=2) \n",
        "for _ in range (2):\n",
        "  x,y = next(iter(torch_dataloader))\n",
        "  print (x.shape,y.shape)\n",
        "  print (x,y)\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([3, 10]) torch.Size([3])\n",
            "tensor([[ 0.4800,  0.4900,  0.3200,  0.7400,  0.9700,  1.1000,  0.3200,\n",
            "          0.4900,  0.5700,  0.5500],\n",
            "        [ 0.7400,  0.9700,  1.1000,  0.3200,  0.4800,  0.4900,  0.3200,\n",
            "          0.4900,  0.5700,  0.5500],\n",
            "        [ 0.4800,  0.4900,  0.4700,  0.7400,  0.9700,  1.1000,  0.4700,\n",
            "          0.4900,  0.5700,  0.5500]]) tensor([ 1,  0,  2])\n",
            "torch.Size([3, 10]) torch.Size([3])\n",
            "tensor([[ 0.4800,  0.4900,  0.3200,  0.7400,  0.9700,  1.1000,  0.3200,\n",
            "          0.4900,  0.5700,  0.5500],\n",
            "        [ 0.7400,  0.9700,  1.1000,  0.3200,  0.4800,  0.4900,  0.3200,\n",
            "          0.4900,  0.5700,  0.5500],\n",
            "        [ 0.4800,  0.4900,  0.4700,  0.7400,  0.9700,  1.1000,  0.4700,\n",
            "          0.4900,  0.5700,  0.5500]]) tensor([ 1,  0,  2])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Exception ignored in: <bound method _DataLoaderIter.__del__ of <torch.utils.data.dataloader._DataLoaderIter object at 0x7f1ae21704e0>>\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/torch/utils/data/dataloader.py\", line 349, in __del__\n",
            "    self._shutdown_workers()\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/torch/utils/data/dataloader.py\", line 328, in _shutdown_workers\n",
            "    self.worker_result_queue.get()\n",
            "  File \"/usr/lib/python3.6/multiprocessing/queues.py\", line 337, in get\n",
            "    return _ForkingPickler.loads(res)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/torch/multiprocessing/reductions.py\", line 70, in rebuild_storage_fd\n",
            "    fd = df.detach()\n",
            "  File \"/usr/lib/python3.6/multiprocessing/resource_sharer.py\", line 57, in detach\n",
            "    with _resource_sharer.get_connection(self._id) as conn:\n",
            "  File \"/usr/lib/python3.6/multiprocessing/resource_sharer.py\", line 87, in get_connection\n",
            "    c = Client(address, authkey=process.current_process().authkey)\n",
            "  File \"/usr/lib/python3.6/multiprocessing/connection.py\", line 493, in Client\n",
            "    answer_challenge(c, authkey)\n",
            "  File \"/usr/lib/python3.6/multiprocessing/connection.py\", line 732, in answer_challenge\n",
            "    message = connection.recv_bytes(256)         # reject large message\n",
            "  File \"/usr/lib/python3.6/multiprocessing/connection.py\", line 216, in recv_bytes\n",
            "    buf = self._recv_bytes(maxlength)\n",
            "  File \"/usr/lib/python3.6/multiprocessing/connection.py\", line 407, in _recv_bytes\n",
            "    buf = self._recv(4)\n",
            "  File \"/usr/lib/python3.6/multiprocessing/connection.py\", line 379, in _recv\n",
            "    chunk = read(handle, remaining)\n",
            "ConnectionResetError: [Errno 104] Connection reset by peer\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "VlCwK-JQbNoY",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## In Torch"
      ]
    },
    {
      "metadata": {
        "id": "a_y-pgh-bP-P",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        },
        "outputId": "8bffecdf-cb13-41b9-f98e-e44031e52a17"
      },
      "cell_type": "code",
      "source": [
        "net = nn.Sequential(\n",
        "    nn.Linear(dataset.x_dim[0], 50),\n",
        "    nn.ReLU(),\n",
        "    nn.Linear(50, dataset.y_dim[0]),\n",
        "    nn.LogSoftmax()\n",
        ")\n",
        "############ NOT WORKING\n",
        "print (net)\n",
        "opt=optim.Adam(net.parameters())\n",
        "print('torch.__version__',torch.__version__)\n",
        "for epoch in range(2):\n",
        "    print (epoch)\n",
        "    for xb,yb in torch_dataloader:\n",
        "        #print (type(xb),type(yb))\n",
        "        if torch.__version__=='0.3.1': #starting in 0.4.0, it is done automagically\n",
        "          xb = V(xb)\n",
        "          yb = V(yb)\n",
        "          \n",
        "        pred = net(xb)\n",
        "        #print ('pred',pred.shape,'yb',yb.shape)\n",
        "        loss = nn.NLLLoss()(pred,yb)\n",
        "\n",
        "        loss.backward()\n",
        "        opt.step()\n",
        "        opt.zero_grad()\n"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Sequential(\n",
            "  (0): Linear(in_features=10, out_features=50, bias=True)\n",
            "  (1): ReLU()\n",
            "  (2): Linear(in_features=50, out_features=3, bias=True)\n",
            "  (3): LogSoftmax()\n",
            ")\n",
            "torch.__version__ 0.4.0\n",
            "0\n",
            "1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "FNcv14gGbUCH",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## In FastAI (shorter)"
      ]
    },
    {
      "metadata": {
        "id": "fVGLvClwhmex",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 228
        },
        "outputId": "f06725d7-f60e-4731-9ad3-f19da939361b"
      },
      "cell_type": "code",
      "source": [
        "net = nn.Sequential(\n",
        "    nn.Linear(dataset.x_dim[0], 50),\n",
        "    #nn.ReLU(),\n",
        "    nn.ELU(), #ELU is 2018 LeakyRelu is 2017 Relu is 2014\n",
        "    nn.Linear(50, dataset.y_dim[0]),\n",
        "    nn.LogSoftmax()\n",
        ")\n",
        "\n",
        "\n",
        "loss= nn.NLLLoss()\n",
        "metrics=[accuracy]\n",
        "opt=optim.Adam(net.parameters())\n",
        "\n",
        "fastai_dataloader = fastai.dataloader.DataLoader(TimeDataset(1e3),batch_size=5)\n",
        "md = ModelData('.', fastai_dataloader,fastai_dataloader)\n",
        "\n",
        "\n",
        "fit(net, md, n_epochs=5, crit=loss, opt=opt, metrics=metrics)\n",
        "\n",
        "# how to predict/eval on one-batch the result\n",
        "x,y=next(iter(md.trn_dl))\n",
        "print ('batch x',x.shape,'y',y.shape)\n",
        "p = net(x) \n",
        "print ('p',p.max(dim=1)[1]) #max is pyTorch max,argmax together max is [0]\n",
        "# we can do it in numpy toom but you an't call numpy() on Variable that requires grad.\n",
        "print('p',np.argmax(p.detach().numpy(),axis=1))  \n",
        "\n",
        "print ('y',y.numpy())  #here you can print y directly\n",
        "\n"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "7307575b3e5d410abe886b48e2337b6e",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(IntProgress(value=0, description='Epoch', max=5), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "epoch      trn_loss   val_loss   accuracy   \n",
            "    0      0.642369   0.538236   1.0       \n",
            "    1      0.452212   0.430325   1.0       \n",
            "    2      0.3695     0.376724   1.0       \n",
            "    3      0.300625   0.276684   1.0       \n",
            "    4      0.205823   0.185157   1.0       \n",
            "\n",
            "batch x torch.Size([5, 10]) y torch.Size([5])\n",
            "p tensor([ 0,  0,  1,  2,  0])\n",
            "p [0 0 1 2 0]\n",
            "y [0 0 1 2 0]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "oX4qPrM7bjUn",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Let's implement another Time\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "QnDXClYdBhZ0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "af5cf3d6-a97d-441c-a904-7b708154b34b"
      },
      "cell_type": "code",
      "source": [
        "from torch.utils.data import Dataset#, DataLoader\n",
        "import numpy as np\n",
        "import time\n",
        "\n",
        "class TimePairsDataset(BaseDataset):\n",
        "  \n",
        "  def __init__(self,length,time_mod_3_result): #1e9 means 1970-2001\n",
        "    \"\"\"\n",
        "    time_mod_3_result - to make sure time is train/test/valid is different, pass\n",
        "    a different result here.\n",
        "    \"\"\"\n",
        "    #super().__init__()\n",
        "    self.length = length\n",
        "    self.formats = [\"%b %d %Y %H:%M:%S\",\"%d %b %Y %H:%M:%S\", \"%m/%b/%Y %H:%M:%S\"]\n",
        "    self.time_mod_3_result=time_mod_3_result\n",
        "  \n",
        "  \n",
        "  def __len__(self):\n",
        "    return int(self.length)\n",
        "  \n",
        "  def _choose(self,idx,style):\n",
        "    st = time.strftime(self.formats[style],time.gmtime(idx))\n",
        "    return np.array([ord(c) for c in list(st)][:24],np.float32)/120 #chars are up to that\n",
        "  \n",
        "  def untokenize(self,sample):\n",
        "    x,y = sample\n",
        "    out=[] \n",
        "    for tokens in x:    \n",
        "      out.append(''.join([chr(int(round(token*120))) for token in tokens]))\n",
        "    return out,y\n",
        "\n",
        "    \n",
        "  \n",
        "  \n",
        "  def _tvt(self,idx):\n",
        "    # for 10, if train, return 9, valid 10, test 11\n",
        "    return (idx//3) * 3 + self.time_mod_3_result #10//3 * 3 + x = 9+x\n",
        "  \n",
        "  def __getitem__(self,idx):\n",
        "    \"\"\" x -  x[0] semantic0   , style0\n",
        "             x[1] semantic0   , style1   \n",
        "             x[2] semantic0orX, style0 (1/2 the time 0 , half X)\n",
        "    \"\"\"\n",
        "    \n",
        "    #other_idx is 50% same, 50% other\n",
        "    other_idx = (idx + np.random.randint(0,2)*(np.random.randint(10,self.length))) %self.length\n",
        "    #print (idx,other_idx)\n",
        "    idx = self._tvt(idx)\n",
        "    other_idx = self._tvt(other_idx)\n",
        "    #print (idx,other_idx)\n",
        "    \n",
        "    # two random formats\n",
        "    random_fs= np.random.choice(len(self.formats),size=2,replace=False)\n",
        "    #print (random_fs)\n",
        "    x_list = []\n",
        "    x_list.append(self._choose(idx,random_fs[0]))\n",
        "    x_list.append(self._choose(idx,random_fs[1]))\n",
        "    x_list.append(self._choose(other_idx,random_fs[0]))\n",
        "    \n",
        "    y = np.array(idx==other_idx,np.int64)\n",
        "   \n",
        "    return  (np.vstack(x_list), y)\n",
        "\n",
        "def test():\n",
        "  dataset = TimePairsDataset(1e7,1)\n",
        "  sample = dataset[9] ;#print (sample)\n",
        "  print (dataset.untokenize(sample))\n",
        "  \n",
        "  \n",
        "test()  "
      ],
      "execution_count": 107,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(['Jan 01 1970 00:00:10', '01/Jan/1970 00:00:10', 'Jan 01 1970 00:00:10'], array(1))\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "bXi51149ioGD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 786
        },
        "outputId": "4a3ce3ac-d532-4714-a5d3-4a26c56ccab1"
      },
      "cell_type": "code",
      "source": [
        "\n",
        "import torch.nn as nn\n",
        "import fastai\n",
        "from fastai.metrics import *\n",
        "from fastai.model import *\n",
        "from fastai.dataset import *\n",
        "from fastai.core import *\n",
        "from fastai.imports import *\n",
        "from fastai.torch_imports import *\n",
        "from fastai.io import *\n",
        "%matplotlib inline\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# semantic_encoder : take sentence return a vector with only semantics\n",
        "# semantic similiary objective: given a pair of sentences with the same semantics,\n",
        "#    expect their results to be close (MeanSquared)    \n",
        "\n",
        "# see idea from https://github.com/edenton/drnet-py/blob/master/models/classifiers.py\n",
        "# in her train method:\n",
        "# FRAMES: VID A: FRAME 1 x_c1 , ?x_p2? (1/2 of times)\n",
        "#                FRAME 2 x_c2 , x_p1\n",
        "#         VID B: FRAME 1      , ?x_p2? (1/2 of times)\n",
        "#  \n",
        "# x_p1,x_p2 chosen randonly from same/not-same video\n",
        "# x_c1,x_c2 are always same-video\n",
        "# c1 and p1 are same content, different pose.\n",
        "\n",
        "# train_scene_discriminator()\n",
        "# h_p1,h_p2 = netEP applied to x[0],x[1]. assumption: SAME VIDEO\n",
        "# important: detach both!\n",
        "# override half of h_p2 by random-permutations of the batch. \n",
        "#   [1,2,3,4,5,6]\n",
        "#   [2,3,1,4,5,6] after 1st half permute\n",
        "#   [1,1,1,0,0,0] set unequal the labels (1=unequal, 0 equal. does it matter? should it be 0.9,0.1?)\n",
        "# apply BCE on inpit: concat of [h_p1,h_p2] \n",
        "# run backward, and optimizer on the netC classifier ONLY! emphasize! not on the encoder\n",
        "\n",
        "\n",
        "# train()\n",
        "# h_c1,h_c2 = netEC(x_c1), netEC(x_c2)  where input is x[0],x[1] sim loss is MSE directly on the hidden content-semantics\n",
        "# h_p1,h_p2 = netEP(x_p1),netEP(x_p2) where input is x[2],x[3]\n",
        "# rec = netD([h_c1, h_p1]) h_c1 is DIFFERENT FRAME , but same content, than h_p1\n",
        "# netC is the semantic-discriminator given h_p1,h_p2, target 0.5 (max-entropy). \n",
        "# emphasize! don't optimize netC is this stage\n",
        "\n",
        " \n",
        "md = ModelData('.',fastai.dataloader.DataLoader(TimePairsDataset(1e5,1), batch_size=16,),\n",
        "                   fastai.dataloader.DataLoader(TimePairsDataset(1e4,2), batch_size=16,))\n",
        "x,y = next(iter(md.trn_dl)) \n",
        "print ('input . x is vertically stacked sentences',x.shape,'y',y.shape)\n",
        "\n",
        "batch,pair,sentence_len=x.shape\n",
        "\n",
        "semantics_units = 20\n",
        "style_units = 10\n",
        "\n",
        "\n",
        "      \n",
        "en_sem = nn.Sequential(\n",
        "  # expect sentence_len,so from outside, cut a pair into x[0],x[1] and pass seperatly each\n",
        "  nn.Linear(sentence_len,19),\n",
        "  nn.ReLU(inplace=True),\n",
        "  nn.Linear(19,semantics_units),\n",
        "  nn.Tanh()\n",
        ")\n",
        "\n",
        "en_sty= nn.Sequential(\n",
        "  nn.Linear(sentence_len,19),\n",
        "  nn.ReLU(inplace=True),\n",
        "  nn.Linear(19,style_units),\n",
        "  nn.Tanh()\n",
        ")\n",
        "decoder = nn.Sequential(\n",
        "  # input concat of semantic and style\n",
        "  # output sentence_len , each word/char has currently value in range 0..1\n",
        "  nn.Linear(semantics_units+style_units,19),\n",
        "  nn.ReLU(inplace=True),\n",
        "  nn.Linear(19,sentence_len),\n",
        "  # we apply MSE on this\n",
        ")\n",
        "adv_dis = nn.Sequential(\n",
        "  # input concat of two style\n",
        "  nn.Linear(2*style_units,19),\n",
        "  nn.ReLU(inplace=True),\n",
        "  nn.Linear(19,1),\n",
        "  nn.Sigmoid()  #Must be sigmoid, we apply later BCE\n",
        ")\n",
        "\n",
        "\n",
        "# trick: fastai requires model and loss function, but we have many small models together\n",
        "# so we just wrap it up with big network, combine losses, and pass to fastai a lamba x:x loss\n",
        "class MainNet(nn.Module):\n",
        "  def __init__(self,en_sem,en_sty,decoder,adv_discriminator,verbose=False):\n",
        "    super().__init__()\n",
        "    self.en_sem = en_sem\n",
        "    self.en_sty = en_sty\n",
        "    self.decoder = decoder\n",
        "    self.adv_discriminator = adv_discriminator\n",
        "    self.verbose = verbose\n",
        "    \n",
        "  def forward(self,x): \n",
        "    if self.verbose: print ('\\nMainNet x',x.numpy().shape,x[:,0].numpy().shape)\n",
        "    \n",
        "    # x[0] semantic0   , style0\n",
        "    # x[1] semantic0   , style1   \n",
        "    # x[2] semantic0orX, style0 (1/2 the time 0 , half X)\n",
        "    \n",
        "    sent0 = x[:,0]\n",
        "    sent1 = x[:,1]\n",
        "    sentX = x[:,2]\n",
        "    h_sem0 = self.en_sem(sent0) \n",
        "    h_sem1 = self.en_sem(sent1) \n",
        "    # if you want to use torch criterion, you need to copy the label and set it to not requreing gradiant\n",
        "    # so below is different than nn.MSELoss()(h_sem0,h_sem1.detach()). I wonder if only one get grad updates!\n",
        "    loss_s = torch.mean(torch.pow(  h_sem0- h_sem1,2)) \n",
        "    h_sty0 = self.en_sty(sent0)\n",
        "    recon_sent0 = self.decoder(torch.cat([h_sem1,h_sty0],dim=1)) #assume h_sem0==h_sem1\n",
        "    recon_loss = nn.MSELoss()(recon_sent0,sent0)\n",
        "    # TODO : willl it be better to use completely different sentences?\n",
        "    h_styX = self.en_sty(sentX)\n",
        "    adv_disc_p =  self.adv_discriminator(torch.cat([h_sty0,h_styX],dim=1))\n",
        "    adv_target = np.full(shape =(sent0.shape[0],1),fill_value=0.5)\n",
        "    adv_disc_loss = nn.BCELoss()(adv_disc_p, T(adv_target))\n",
        "               \n",
        "    self.verbose = False\n",
        "    return loss_s + recon_loss + adv_disc_loss\n",
        " \n",
        "\n",
        " \n",
        "\n",
        "#main_net = MainNet(en_sem, en_sty,decoder, adv_discriminator, verbose=True) \n",
        "#opt = optim.Adam(main_net.parameters())\n",
        "#fit(main_net, md, n_epochs=10, crit=lambda loss,label:loss, opt=opt, metrics=[])\n",
        "\n"
      ],
      "execution_count": 115,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "input . x is vertically stacked sentences torch.Size([16, 3, 20]) y torch.Size([16])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "439e36f4d7d6404384ea059a26a0cd8f",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(IntProgress(value=0, description='Epoch', max=10), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "  0%|          | 0/6250 [00:00<?, ?it/s]\n",
            "MainNet x (16, 3, 20) (16, 20)\n",
            "(16, 20)\n",
            "epoch      trn_loss   val_loss   \n",
            "    0      0.693245   0.693267  \n",
            " 82%|████████▏ | 5101/6250 [00:28<00:06, 176.04it/s, loss=0.693]"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "    1      0.693207   0.693232  \n",
            "    2      0.6932     0.693232  \n",
            " 49%|████▊     | 3041/6250 [00:17<00:18, 175.23it/s, loss=0.693]"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-115-e4b15a9743bf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[0mmain_net\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMainNet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0men_sem\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0men_sty\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdecoder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madv_discriminator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m \u001b[0mopt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAdam\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmain_net\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 131\u001b[0;31m \u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmain_net\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_epochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcrit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopt\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mopt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/fastai/model.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(model, data, n_epochs, opt, crit, metrics, callbacks, stepper, swa_model, swa_start, swa_eval_freq, visualize, **kwargs)\u001b[0m\n\u001b[1;32m    139\u001b[0m             \u001b[0mbatch_num\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mcb\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mcb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 141\u001b[0;31m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_stepper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mV\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mV\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    142\u001b[0m             \u001b[0mavg_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mavg_loss\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mavg_mom\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mloss\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mavg_mom\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m             \u001b[0mdebias_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mavg_loss\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mavg_mom\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mbatch_num\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/fastai/model.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, xs, y, epoch)\u001b[0m\n\u001b[1;32m     68\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mp\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mgroup\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'params'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mwd\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfp16\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m             \u001b[0mcopy_fp32_to_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfp32_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/optim/adam.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m    104\u001b[0m                 \u001b[0mstep_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgroup\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'lr'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbias_correction2\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mbias_correction1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 106\u001b[0;31m                 \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maddcdiv_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mstep_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexp_avg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdenom\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    107\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "JYY2o5c6W0LE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "07a1f63d-5935-4cb8-b273-e027f310ec5b"
      },
      "cell_type": "code",
      "source": [
        "import argparse\n",
        "import sys\n",
        "parser = argparse.ArgumentParser()\n",
        "parser.add_argument('--lr', default=0.002, type=float, help='learning rate')\n",
        "parser.add_argument('--beta1', default=0.5, type=float, help='momentum term for adam')\n",
        "parser.add_argument('--batch_size', default=100, type=int, help='batch size')\n",
        "parser.add_argument('--log_dir', default='logs', help='base directory to save logs')\n",
        "parser.add_argument('--data_root', default='', help='root directory for data')\n",
        "parser.add_argument('--optimizer', default='adam', help='optimizer to train with')\n",
        "parser.add_argument('--epocs', type=int, default=2, help='number of epochs to train for')\n",
        "parser.add_argument('--seed', default=1, type=int, help='manual seed')\n",
        "parser.add_argument('--epoch_size', type=int, default=600, help='epoch size')\n",
        "parser.add_argument('--content_dim', type=int, default=128, help='size of the content vector')\n",
        "parser.add_argument('--pose_dim', type=int, default=10, help='size of the pose vector')\n",
        "parser.add_argument('--image_width', type=int, default=64, help='the height / width of the input image to network')\n",
        "parser.add_argument('--channels', default=3, type=int)\n",
        "parser.add_argument('--dataset', default='moving_mnist', help='dataset to train with')\n",
        "parser.add_argument('--max_step', type=int, default=20, help='maximum distance between frames')\n",
        "parser.add_argument('--sd_weight', type=float, default=0.0001, help='weight on adversarial loss')\n",
        "parser.add_argument('--sd_nf', type=int, default=100, help='number of layers')\n",
        "parser.add_argument('--content_model', default='dcgan_unet', help='model type (dcgan | dcgan_unet | vgg_unet)')\n",
        "parser.add_argument('--pose_model', default='dcgan', help='model type (dcgan | unet | resnet)')\n",
        "parser.add_argument('--data_threads', type=int, default=5, help='number of parallel data loading threads')\n",
        "parser.add_argument('--data_type', default='drnet', help='speed up data loading for drnet training')\n",
        "\n",
        "sys.argv=[\"nothing\"]\n",
        "opt = parser.parse_args()\n"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "20\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "_jDD-H1faFtq",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "\n",
        "optimizer_en_sem = opt.optimizer(en_sem.parameters(), lr=opt.lr, betas=(opt.beta1, 0.999))\n",
        "optimizer_en_sty = opt.optimizer(en_sty.parameters(), lr=opt.lr, betas=(opt.beta1, 0.999))\n",
        "optimizer_decoder = opt.optimizer(decoder.parameters(), lr=opt.lr, betas=(opt.beta1, 0.999))\n",
        "optimizer_adv_dis = opt.optimizer(adv_dis.parameters(), lr=opt.lr, betas=(opt.beta1, 0.999))\n",
        "\n",
        "\n",
        "# --------- training funtions ------------------------------------\n",
        "def train(x,nets,optimizers,nets):\n",
        "    \n",
        "    en_sty.zero_grad() \n",
        "    en_sem.zero_grad()\n",
        "    decoder.zero_grad()\n",
        "\n",
        "    \n",
        "    # x[0] semantic0   , style0\n",
        "    # x[1] semantic0   , style1   \n",
        "    # x[2] semantic0orX, style0 (1/2 the time 0 , half X)\n",
        "    sent0 = x[:,0]\n",
        "    sent1 = x[:,1]\n",
        "    sentX = x[:,2]\n",
        "    h_sem0 = self.en_sem(sent0) \n",
        "    h_sem1 = self.en_sem(sent1) \n",
        "    # if you want to use torch criterion, you need to copy the label and set it to not requreing gradiant\n",
        "    # so below is different than nn.MSELoss()(h_sem0,h_sem1.detach()). I wonder if only one get grad updates!\n",
        "    sim_loss = torch.mean(torch.pow(  h_sem0- h_sem1,2)) \n",
        "    #sim_loss = mse_criterion(h_c1[0] if opt.content_model[-4:] == 'unet' else h_c1, h_c2)\n",
        "    \n",
        "    \n",
        "    h_sty0 = self.en_sty(sent0)\n",
        "    recon_sent0 = self.decoder(torch.cat([h_sem1,h_sty0],dim=1)) #assume h_sem0==h_sem1\n",
        "    rec_loss = nn.MSELoss()(recon_sent0,sent0)\n",
        "\n",
        "    # TODO : willl it be better to use completely different sentences?\n",
        "    h_styX = self.en_sty(sentX)\n",
        "    adv_disc_p =  self.adv_discriminator(torch.cat([h_sty0,h_styX],dim=1))\n",
        "    adv_target = np.full(shape =(sent0.shape[0],1),fill_value=0.5)\n",
        "    adv_disc_loss = nn.BCELoss()(adv_disc_p, T(adv_target))\n",
        "    \n",
        "    \n",
        "    # full loss\n",
        "    loss = sim_loss + rec_loss + opt.sd_weight*adv_disc_loss\n",
        "    loss.backward()\n",
        "\n",
        "    optimizer_en_sem.step()\n",
        "    optimizer_en_sty.step()\n",
        "    optimizer_decoder.step()\n",
        "\n",
        "    return sim_loss.data.cpu().numpy(),rec_loss.data.cpu().numpy() \n",
        "\n",
        "def train_scene_discriminator(x,y):\n",
        "    adv_disc.zero_grad()\n",
        "\n",
        "    target = torch.cuda.FloatTensor(opt.batch_size, 1)\n",
        "\n",
        "    h_sty0    = self.en_sty(x[0]) #detach?\n",
        "    h_sty0or2 = self.en_sty(x[2])\n",
        "    \n",
        "  \n",
        "    out = adv_discriminator([h_sty0, h_sty0or2])\n",
        "    bce = bce_criterion(out, y) #should wrapp in varaible?\n",
        "\n",
        "    bce.backward()\n",
        "    optimizer_adv_dis.step()\n",
        "\n",
        "    acc =  np.argmax(out.detach().numpy(),axis=1)==y  #CHECK THIS DIMENSTIONS!!! \n",
        "    return bce.data.cpu().numpy(), acc.data.cpu().numpy()/len(y)\n",
        "\n",
        "# --------- training loop ------------------------------------\n",
        "for epoch in rangeepocs):\n",
        "    en_sty.train()\n",
        "    en_sem.train()\n",
        "    decoder.train()\n",
        "    adv_discriminator.train()\n",
        "    epoch_sim_loss, epoch_rec_loss, epoch_sd_loss, epoch_sd_acc = 0, 0, 0, 0\n",
        "\n",
        "    for i in range(opt.epoch_size):\n",
        "        print (i)\n",
        "        x = next(training_batch_generator)\n",
        "\n",
        "        # train scene discriminator\n",
        "        sd_loss, sd_acc = train_scene_discriminator(x)\n",
        "        epoch_sd_loss += sd_loss\n",
        "        epoch_sd_acc += sd_acc\n",
        "\n",
        "        # train main model\n",
        "        sim_loss, rec_loss = train(x)\n",
        "        epoch_sim_loss += sim_loss\n",
        "        epoch_rec_loss += rec_loss\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "RurR2Mjb4Ls6",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Same for MNIST"
      ]
    },
    {
      "metadata": {
        "id": "8df9zoymohYU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 140
        },
        "outputId": "0ef4d744-fdb5-40cd-cfa1-ad5e2bc7fcdc"
      },
      "cell_type": "code",
      "source": [
        "from fastai.imports import *\n",
        "from fastai.torch_imports import *\n",
        "from fastai.io import *\n",
        "from fastai.metrics import *\n",
        "from fastai.model import *\n",
        "from fastai.dataset import *\n",
        "\n",
        "import torch.nn as nn\n",
        "\n",
        "\n",
        "path = 'data/mnist/'\n",
        "import os\n",
        "os.makedirs(path, exist_ok=True)\n",
        "URL='http://deeplearning.net/data/mnist/'\n",
        "FILENAME='mnist.pkl.gz'\n",
        "\n",
        "def load_mnist(filename):\n",
        "    return pickle.load(gzip.open(filename, 'rb'), encoding='latin-1')\n",
        "get_data(URL+FILENAME, path+FILENAME)\n",
        "((x, y), (x_valid, y_valid), _) = load_mnist(path+FILENAME)\n",
        "\n",
        "type(x), x.shape, type(y), y.shape\n",
        "mean = x.mean()\n",
        "std = x.std()\n",
        "\n",
        "x=(x-mean)/std\n",
        "mean, std, x.mean(), x.std()\n",
        "x_valid = (x_valid-mean)/std\n",
        "x_valid.mean(), x_valid.std()\n",
        "print (x.shape,y.shape,x_valid.shape,y_valid.shape)\n",
        "net = nn.Sequential(\n",
        "    nn.Linear(28*28, 100),\n",
        "    nn.ReLU(),\n",
        "    nn.LogSoftmax()\n",
        ")\n",
        "\n",
        "md = ImageClassifierData.from_arrays(path, (x,y), (x_valid, y_valid))\n",
        "loss=nn.NLLLoss()\n",
        "metrics=[accuracy]\n",
        "# opt=optim.SGD(net.parameters(), 1e-1, momentum=0.9)\n",
        "opt=optim.SGD(net.parameters(), 1e-1, momentum=0.9, weight_decay=1e-3)\n",
        "fit(net, md, n_epochs=1, crit=loss, opt=opt, metrics=metrics)"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "mnist.pkl.gz: 16.2MB [00:03, 4.75MB/s]                            \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "(50000, 784) (50000,) (10000, 784) (10000,)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "6e2eb81351dd4eb6b58cf7b009d3012a",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(IntProgress(value=0, description='Epoch', max=1), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "epoch      trn_loss   val_loss   accuracy   \n",
            "    0      0.96713    0.883354   0.8699    \n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.8833535579681396, 0.8699]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    }
  ]
}
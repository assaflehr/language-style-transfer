{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "keras_nlp.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "[View in Colaboratory](https://colab.research.google.com/github/assaflehr/language-style-transfer/blob/master/notebooks/keras_nlp.ipynb)"
      ]
    },
    {
      "metadata": {
        "id": "vR_wGTR6szDb",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        ""
      ]
    },
    {
      "metadata": {
        "id": "wp4BcB4250bT",
        "colab_type": "toc"
      },
      "cell_type": "markdown",
      "source": [
        ">>[Keras accuracy/performace limitations](#scrollTo=vR_wGTR6szDb)\n",
        "\n",
        ">>[Pretraining autoencoder or LM will surely help.](#scrollTo=vR_wGTR6szDb)\n",
        "\n",
        ">>>[CuDNNLSTM vs LSTM](#scrollTo=vR_wGTR6szDb)\n",
        "\n",
        ">>>[Tip to self:](#scrollTo=vR_wGTR6szDb)\n",
        "\n",
        ">>>[For David: example of how to clone, then use from github](#scrollTo=OrKzdh71sBKm)\n",
        "\n",
        ">[Dataset](#scrollTo=wwc6_EHFD_Ir)\n",
        "\n",
        ">[Model defintion](#scrollTo=BWVEcaeF6DBR)\n",
        "\n",
        ">>[classifier](#scrollTo=VTobPYftYvQC)\n",
        "\n",
        ">>[adverserial model](#scrollTo=9TBO_5dXv40K)\n",
        "\n",
        ">[TRAINING](#scrollTo=9s0-8EJi6AG1)\n",
        "\n",
        ">[Error analysis](#scrollTo=XvIkFOWy55ov)\n",
        "\n",
        ">>[Error of style disc.](#scrollTo=8QaOXXjUAwVH)\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "Og2XNK-_53VP",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Keras accuracy/performace limitations\n",
        "\n",
        "## Pretraining autoencoder or LM will surely help.\n",
        "\n",
        "see late review here: https://thegradient.pub/author/sebastian\n",
        "and autoencoder (which is less recommended than LM here: \"Semi-supervised Sequence Learning\" 2015. They use one RNN for both encoder and decoder)\n",
        "\n",
        "\n",
        "### CuDNNLSTM vs LSTM \n",
        "The former trains very fast on GPU, but does not support the attributes: dropout,recurrent_dropout,which are the STOA regulaizers. This is cuda problem, and even native TF does not support it\n",
        "\n",
        "### Tip to self:\n",
        "* manually check loss value on one sample (predict vs gt). From doing this, I saw <s> was not given one-hot-value"
      ]
    },
    {
      "metadata": {
        "id": "OrKzdh71sBKm",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### For David: example of how to clone, then use from github\n",
        "```python\n",
        "#!rm -r language-style-transfer  #remove previous github copy if needed\n",
        "!git clone https://github.com/assaflehr/language-style-transfer.git\n",
        "#we rename to as lang_transfer will be the package name\n",
        "!mv language-style-transfer/code language-style-transfer/lang_transfer\n",
        "\n",
        "# Add the local_modules directory to the set of paths Python uses to look for imports.\n",
        "import sys\n",
        "sys.path.append('language-style-transfer')\n",
        "\n",
        "import lang_transfer   #your code here!!!\n",
        "```"
      ]
    },
    {
      "metadata": {
        "id": "UbJwZjyhsDvP",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# adaptation of: https://blog.keras.io/a-ten-minute-introduction-to-sequence-to-sequence-learning-in-keras.html\n",
        "# first Dataset class to load bible-data\n",
        "# then copy of the model, but working with words instead of chars\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "wwc6_EHFD_Ir",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Dataset"
      ]
    },
    {
      "metadata": {
        "id": "PcPSCDUrx3B8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 600
        },
        "outputId": "1ea963f6-ea34-4084-aa0f-e68b5802206c"
      },
      "cell_type": "code",
      "source": [
        "## NLP preprocessing for text\n",
        "# has few parts:\n",
        "# 1. load zip files and then use glob to filter part of them (data/*/*.txt)\n",
        "# 2. parse each row into (x,y) by passing a parser method. it can be simple as lambda line:line:x, or if you use tab delimited lambda line: line.split(',')[4]\n",
        "# 3. tokenize - split by spaces, but also by ., and be smart about it.  ('...' should be one token , \"ai'nt\" one token. then; should be two 'token' and ';')\n",
        "#    you should also build vocabulary, keep X words and throw away rare ones, they will be replaced by <oov> flag.\n",
        "# 4. transform text to sequences for the result. for words there are usually two different types: ['s>','hello', 'world'] -> [0,5,6] but there is also \n",
        "#     a one-hot-econding version where 5 is actaully a vector of size voc-length full of zeros, with 5th index==1.\n",
        "#    The one-hot ecoding is used as output for text-generation and has a HUGE MEMORY requirement.  100K sentences of size 20 words need 2M floats = 8MB\n",
        "#    But for the one-hot-encoding multiply this by vocab-size. for char-encoding it's ~30 , for good vocab of 10K words, we need 80GB(!)\n",
        "#    The simple, and only , way to solve this , is to never keep one-hot-encoding in memory, just use a generator to make it one-hot in runtime\n",
        "\n",
        "\n",
        "\n",
        "from __future__ import print_function\n",
        "\n",
        "import numpy as np\n",
        "import os\n",
        "import glob\n",
        "import csv, json\n",
        "from collections import namedtuple\n",
        "from zipfile import ZipFile\n",
        "from os.path import expanduser, exists\n",
        "from keras.utils.data_utils import get_file\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.utils.data_utils import get_file\n",
        "from keras.utils import to_categorical\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "\n",
        "TVT = namedtuple('TVT',['train','val','test'])\n",
        "\n",
        "class Dataset:\n",
        "  #Dataset for COPY encoder-decoder\n",
        "  # to David: generator x,y where x1 is encoder_input is batch_size,max-words of type integer. (hello word <e> )   [x] (64,10)\n",
        "  #                               x2 is decoder_input is batch,max-words of type integer  ( <s>  hello word)  [x]      (64,10)\n",
        "  #                               y1             batch,max-words,one-hot-encoding (offset one: hello world <end>) (64,10,10000)\n",
        "  #                               y_style:           batch,one-hot-of-style                                       (64,2)\n",
        "  #                                          shape: (64,10)  batch_size=64 ,max_words=10 , vocab_size= 10000  style_vocab=2/5\n",
        "  # tokenizer is currently very bad. replace it\n",
        "  # vocabulary (training-only) , don't use 666 , use large number (10K?)\n",
        "  # Generator : iteration result ([x1,x2],[y1,y_style])\n",
        "  \n",
        "  # for auto-encoder pre-training without style  ([x1,x2],y1)  with no y_style\n",
        "  \n",
        "  \n",
        "  def __init__(self,unique_name,url,extract,cache_dir,pattern,skip_first,row_parser,validation_pattern=0.1,test_pattern=0.1):\n",
        "    '''\n",
        "    unique_name will be used for the dataset source(or zip) file. \n",
        "    pattern need to include path inside zip (including zip root)\n",
        "    extract - is it zipped/tarred or not\n",
        "    cache_dir - under which the files be downloaded <cache_dir>/datasets/<unique_name>\n",
        "    pattern - glob will be done to choose only those files ,for example data*.txt. This should incldude both train and test\n",
        "    validation - subset glob pattern to use. If it's a float like 0.1, use it as split of one file\n",
        "    test - see above\n",
        "    '''\n",
        "    if not extract and pattern:\n",
        "      raise ValueError('pattern must be empty if extract=False chooses a subset of the files (data/*.txt). but you downloaded only one file')\n",
        "\n",
        "    if not os.path.exists(cache_dir):\n",
        "       os.makedirs(cache_dir)\n",
        "\n",
        "    fpath=get_file(unique_name, url,extract=True, cache_dir=cache_dir)\n",
        "    print ('fpath',fpath)\n",
        "    files = [fpath] if not pattern else glob.glob(f'{cache_dir}/datasets/{pattern}')\n",
        "\n",
        "    train,val,test=[],[],[]\n",
        "    for f in files:\n",
        "      lines = [row_parser(f,line.rstrip()) for line in open(f,encoding=\"latin-1\").readlines()] \n",
        "      lines = lines[1 if skip_first else 0:][:10000]\n",
        "      print ('HARDCODED MAX LINES = 10000')\n",
        "      \n",
        "      print (files,'#lines',len(lines),'first 3 lines')\n",
        "      print (lines[0],'\\n',lines[1],'\\n',lines[2])\n",
        "      \n",
        "      if isinstance(validation_pattern,float) and isinstance(test_pattern,float):\n",
        "        test_count = int(len(lines)*(1-validation_pattern))\n",
        "        val_count =  int(len(lines)*(1-test_pattern-validation_pattern))\n",
        "        print ('(val_count,test_count)',val_count,test_count)\n",
        "        train+= lines[:val_count]\n",
        "        val+=   lines[val_count:test_count]\n",
        "        test+=  lines[test_count:]\n",
        "        \n",
        "    self.tvt_lines = TVT(train, val, test)\n",
        "    print ('train:',len(self.tvt_lines.train),'val',len(self.tvt_lines.val),'test',len(self.tvt_lines.test))\n",
        "    self.parsed= self.tvt_lines\n",
        "  \n",
        "  \n",
        "  def fit(self):\n",
        "    \"\"\" the current implementation is quite bad, hello world! will be 2 tokens world! is the second. \n",
        "    \"\"\"\n",
        "    print ('limiting num_words in Tokenizer due to MEMORY BOUNDS')  #num_words =100*1000\n",
        "\n",
        "    \n",
        "    # I use here tokenizer only to count freq. of words, then manually choose most freq. and manually split\n",
        "    # this is bad. There are better ways to do it (probably library/code which do it in one line)\n",
        "    print ('\\nREPLACE ME . BAD TOKENIZER!!!')\n",
        "    self.tokenizer = Tokenizer(num_words=100000, filters='', lower=False, split=' ', char_level=False, oov_token='<oov>')\n",
        "    \n",
        "    # self.parsed.train is a list , each value is tuple text_string,file_name\n",
        "    self.tokenizer.fit_on_texts([x for x,style in self.parsed.train])\n",
        "    self.styles = set([style for x,style in self.parsed.train])\n",
        "    print ('styles',self.styles)\n",
        "    self.style2index = {style:i for i,style in enumerate(self.styles)}\n",
        "    self.index2style = {index:style for style,index in self.style2index.items() }\n",
        "    print (self.style2index,self.index2style)\n",
        "    \n",
        "    #print ('\\n word_index',len(self.tokenizer.word_index),'<oov>',self.tokenizer.word_index['<oov>'])\n",
        "    print ('common',list(self.tokenizer.word_index.items())[:15])\n",
        "    print ('uncommon',list(self.tokenizer.word_index.items())[-15:])\n",
        "  \n",
        "    \n",
        "    num_words= 10000\n",
        "    print ('CAPPING. keeping ',num_words,'of',len(self.tokenizer.word_index))\n",
        "    \n",
        "    num_words= min(num_words,len(self.styles)+1+len(self.tokenizer.word_index))\n",
        "    print (num_words,num_words,num_words)    \n",
        "    word2index = dict(list(self.tokenizer.word_index.items())[:num_words-len(self.styles)-2])\n",
        "    word2index['<s>']=0  #keras tokenizer keeps 0 unused\n",
        "    for i,style in enumerate(self.styles):\n",
        "      word2index[style]=num_words-1-len(self.styles)+i  #if num_words=100 . [96,97,98] \n",
        "    word2index['<oov>']=num_words-1                     #<oov> is [99]\n",
        "    print ('word2index',len(word2index))\n",
        "    \n",
        "    #FOR NOW the start and end are both ZERO. maybe not good???\n",
        "    \n",
        "    num_encoder_tokens = num_decoder_tokens= num_words # len(self.tokenizer.word_index)\n",
        "    self.word2index = word2index\n",
        "    self.index2word = {index:word for (word,index) in self.word2index.items()}\n",
        "    self.MAX_SEQUENCE_LENGTH=20  #100\n",
        "    \n",
        "    verbose=5\n",
        "    result = []\n",
        "    for rows in self.parsed:\n",
        "\n",
        "      encoder_input_data  = np.zeros( (len(rows), self.MAX_SEQUENCE_LENGTH),    dtype='float32')\n",
        "      decoder_input_data  = np.zeros( (len(rows), self.MAX_SEQUENCE_LENGTH),    dtype='float32') # shifted by 1\n",
        "      decoder_target_data = None #np.zeros((len(rows),  self.MAX_SEQUENCE_LENGTH, num_decoder_tokens),    dtype='float32')\n",
        "      style_data          = np.zeros((len(rows),  len(self.styles)),    dtype='float32') #one-hot\n",
        "      \n",
        "      #input to decoder   <s> hello world\n",
        "      #target of decoder: hello world <s>\n",
        "      \n",
        "      for i, (input_text,style) in enumerate(rows):\n",
        "        input_text = input_text.split(' ') #BUG: we need to use tokenizer here!!!!\n",
        "        #pad with end token  hello world <end> <end> <end>\n",
        "        end_token='<s>'\n",
        "        input_text += [end_token for _ in range(self.MAX_SEQUENCE_LENGTH - len(input_text)+1)]\n",
        "        if verbose:\n",
        "          print ('input_text',input_text)\n",
        "          verbose-=1\n",
        "        # out : hello  world  <end>  (MAX_SEQUENCE_LENGTH=2)  <-encoder_input+ decoder_output(but one-hot)\n",
        "        #\n",
        "        # in: : <s>   hello   world  <- decoder-input\n",
        "         \n",
        "        for t, word in enumerate(([style]+input_text)[:self.MAX_SEQUENCE_LENGTH]):\n",
        "            one_hot = word2index['<oov>'] if word not in word2index else word2index[word]\n",
        "            decoder_input_data[i, t ] = one_hot\n",
        "            \n",
        "        for t,word in enumerate(input_text[:self.MAX_SEQUENCE_LENGTH]):  #last must be <end>=<s> token\n",
        "            one_hot = word2index['<oov>'] if word not in word2index else word2index[word]\n",
        "            encoder_input_data[i,t]=one_hot\n",
        "            #decoder_target_data[i, t, one_hot] = 1. \n",
        "            \n",
        "        style_data[i,self.style2index[style]]= 1\n",
        "        \n",
        "      #print (decoder_target_data.sum(),len(rows)*self.MAX_SEQUENCE_LENGTH)\n",
        "      #assert int(decoder_target_data.sum())==len(rows)*self.MAX_SEQUENCE_LENGTH #one-hot-encoding must always include one\n",
        "      \n",
        "      result.append( (encoder_input_data,decoder_input_data,decoder_target_data,style_data))\n",
        "\n",
        "    self.result= TVT(*result)\n",
        "\n",
        "  def one_x_as_text(self,x):\n",
        "    \"\"\" 1x20 or 20 input\"\"\"\n",
        "    if len(x.shape)==2: \n",
        "      assert x.shape[0] ==1  #can only work on batch of 1\n",
        "      x= x[0]\n",
        "    return ' '.join([self.index2word[index] for index in x])\n",
        "\n",
        "  def one_y_as_text(self,y):\n",
        "    \"\"\" 1x20x2000 or 20x2000 input, in case of first will work on y[0]\"\"\"\n",
        "    if len(y.shape)==3: \n",
        "      assert y.shape[0] ==1  #can only work on batch of 1\n",
        "      y=y[0]\n",
        "      \n",
        "    best_token = np.argmax(y,1)\n",
        "    return ' '.join([self.index2word[index] for index in best_token])\n",
        "\n",
        "  \n",
        "cache_dir='cache' \n",
        "#dataset('quora_dups','http://qim.ec.quoracdn.net/quora_duplicate_questions.tsv',False,cache_dir) \n",
        "#dataset('bible4','https://codeload.github.com/keithecarlson/Zero-Shot-Style-Transfer/zip/master',extract=True,cache_dir=cache_dir\n",
        "#       pattern=('Zero-Shot-Style-Transfer-master/Data/Bibles/ASV/*/*.txt','Zero-Shot-Style-Transfer-master/Data/Bibles/BBE/*/*.txt')\n",
        "\n",
        "row_parser= lambda file_name,line: (line.split(',')[4],file_name.split('/')[-1]) #map x to x,style_file\n",
        "dataset = Dataset('bible_csv','https://codeload.github.com/ashual/style-transfer/zip/master',extract=True,cache_dir=cache_dir,\n",
        "                  \n",
        "                  pattern='style-transfer-master/datasets/bible-corpus/t_[yb]*.csv',skip_first=True,row_parser=row_parser)    #kbd\n",
        "dataset.fit()        \n",
        "x_train, x_train_d, y_train,style_train = dataset.result.train\n",
        "x_val, x_val_d,y_val ,style_val= dataset.result.val\n",
        "x_test,x_test_d,y_test ,style_test= dataset.result.test\n",
        "\n",
        "print ('train',x_train.shape,x_train_d.shape,y_train,style_train.shape)\n",
        "print('val',x_val.shape)\n",
        "print ('train in MB x,y',x_train.nbytes/1e6)\n",
        "\n",
        "\n",
        "#,t_bbe,BBE,english,Bible in Basic English,,http://en.wikipedia.org/wiki/Bible_in_Basic_English,,Public Domain,\n",
        "                  #,t_dby,DARBY,english,Darby English Bible,,http://en.wikipedia.org/wiki/Darby_Bible,,Public Domain,\n",
        "                  #,t_kjv,KJV,english,King James Version,,http://en.wikipedia.org/wiki/King_James_Version,,Public Domain,\n"
      ],
      "execution_count": 237,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "fpath cache/datasets/bible_csv\n",
            "HARDCODED MAX LINES = 10000\n",
            "['cache/datasets/style-transfer-master/datasets/bible-corpus/t_bbe.csv', 'cache/datasets/style-transfer-master/datasets/bible-corpus/t_ylt.csv'] #lines 10000 first 3 lines\n",
            "('At the first God made the heaven and the earth.', 't_bbe.csv') \n",
            " ('And the earth was waste and without form; and it was dark on the face of the deep: and the Spirit of God was moving on the face of the waters.', 't_bbe.csv') \n",
            " ('\"And God said', 't_bbe.csv')\n",
            "(val_count,test_count) 8000 9000\n",
            "HARDCODED MAX LINES = 10000\n",
            "['cache/datasets/style-transfer-master/datasets/bible-corpus/t_bbe.csv', 'cache/datasets/style-transfer-master/datasets/bible-corpus/t_ylt.csv'] #lines 10000 first 3 lines\n",
            "(\"In the beginning of God's preparing the heavens and the earth --\", 't_ylt.csv') \n",
            " ('\"the earth hath existed waste and void', 't_ylt.csv') \n",
            " ('\"and God saith', 't_ylt.csv')\n",
            "(val_count,test_count) 8000 9000\n",
            "train: 16000 val 2000 test 2000\n",
            "limiting num_words in Tokenizer due to MEMORY BOUNDS\n",
            "\n",
            "REPLACE ME . BAD TOKENIZER!!!\n",
            "styles {'t_bbe.csv', 't_ylt.csv'}\n",
            "{'t_bbe.csv': 0, 't_ylt.csv': 1} {0: 't_bbe.csv', 1: 't_ylt.csv'}\n",
            "common [('the', 1), ('of', 2), ('\"And', 3), ('to', 4), ('and', 5), ('\"and', 6), ('in', 7), ('a', 8), ('his', 9), ('he', 10), ('is', 11), ('on', 12), ('for', 13), ('said', 14), ('you', 15)]\n",
            "uncommon [('spies', 7333), ('\"far', 7334), ('faithfulness', 7335), ('months;', 7336), ('\"Neither', 7337), ('believeth', 7338), ('disguiseth', 7339), ('stature', 7340), ('stall', 7341), ('Cherethite', 7342), ('twilight', 7343), ('delivereth', 7344), ('delivered.', 7345), ('faint', 7346), ('<oov>', 7347)]\n",
            "CAPPING. keeping  10000 of 7347\n",
            "7350 7350 7350\n",
            "word2index 7350\n",
            "input_text ['At', 'the', 'first', 'God', 'made', 'the', 'heaven', 'and', 'the', 'earth.', '<s>', '<s>', '<s>', '<s>', '<s>', '<s>', '<s>', '<s>', '<s>', '<s>', '<s>']\n",
            "input_text ['And', 'the', 'earth', 'was', 'waste', 'and', 'without', 'form;', 'and', 'it', 'was', 'dark', 'on', 'the', 'face', 'of', 'the', 'deep:', 'and', 'the', 'Spirit', 'of', 'God', 'was', 'moving', 'on', 'the', 'face', 'of', 'the', 'waters.']\n",
            "input_text ['\"And', 'God', 'said', '<s>', '<s>', '<s>', '<s>', '<s>', '<s>', '<s>', '<s>', '<s>', '<s>', '<s>', '<s>', '<s>', '<s>', '<s>', '<s>', '<s>', '<s>']\n",
            "input_text ['\"And', 'God', '<s>', '<s>', '<s>', '<s>', '<s>', '<s>', '<s>', '<s>', '<s>', '<s>', '<s>', '<s>', '<s>', '<s>', '<s>', '<s>', '<s>', '<s>', '<s>']\n",
            "input_text ['\"Naming', 'the', 'light', '<s>', '<s>', '<s>', '<s>', '<s>', '<s>', '<s>', '<s>', '<s>', '<s>', '<s>', '<s>', '<s>', '<s>', '<s>', '<s>', '<s>', '<s>']\n",
            "train (16000, 20) (16000, 20) None (16000, 2)\n",
            "val (2000, 20)\n",
            "train in MB x,y 1.28\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "9GT06VNk7vSN",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#!head -50 cache/datasets/style-transfer-master/datasets/bible-corpus/bible_version_key.csv\n",
        "#!ls -lh cache/datasets/style-transfer-master/datasets/bible-corpus\n",
        "\n",
        "#for i in [5000, 2002,3001]:\n",
        "#  print ('\\n',i)\n",
        "#  for j in ['ylt','kjv','wbt','asv','web','bbe','dby']:\n",
        "#    !sed -n -e {i}p cache/datasets/style-transfer-master/datasets/bible-corpus/t_{j}.csv\n",
        "\n",
        "# differences: \n",
        "# very old: ylt\n",
        "# very dynamic: bbe\n",
        "# middle ground (5 similiar wbt)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "S_v9vKqIcTn6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 228
        },
        "outputId": "2f704d22-65be-4bd9-f2b5-72c3ec80c044"
      },
      "cell_type": "code",
      "source": [
        "#show a sample of x_train\n",
        "for i in range(1150,1152):\n",
        "  print ('\\ntokens  :' , x_train_d[i])\n",
        "  print ('as words:',[dataset.index2word[index] for index in x_train_d[i] ])\n",
        "  print ('original:',dataset.parsed.train[i][0].split(' '))\n",
        "  print (dataset.one_x_as_text(x_train_d[i]))\n",
        "  #print (dataset.one_y_as_text(y_train[i]))"
      ],
      "execution_count": 215,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "tokens  : [9.997e+03 1.160e+02 1.190e+02 4.100e+01 1.380e+02 1.280e+02 4.000e+00\n",
            " 8.600e+02 5.000e+00 3.101e+03]\n",
            "as words: ['t_bbe.csv', '\"Now', 'Joseph', 'was', 'taken', 'down', 'to', 'Egypt;', 'and', 'Potiphar']\n",
            "original: ['\"Now', 'Joseph', 'was', 'taken', 'down', 'to', 'Egypt;', 'and', 'Potiphar', 'the', 'Egyptian']\n",
            "t_bbe.csv \"Now Joseph was taken down to Egypt; and Potiphar\n",
            "\n",
            "tokens  : [9.997e+03 3.000e+00 1.000e+00 2.000e+01 4.100e+01 2.800e+01 1.190e+02\n",
            " 0.000e+00 0.000e+00 0.000e+00]\n",
            "as words: ['t_bbe.csv', '\"And', 'the', 'Lord', 'was', 'with', 'Joseph', '<s>', '<s>', '<s>']\n",
            "original: ['\"And', 'the', 'Lord', 'was', 'with', 'Joseph']\n",
            "t_bbe.csv \"And the Lord was with Joseph <s> <s> <s>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "BWVEcaeF6DBR",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Model defintion\n"
      ]
    },
    {
      "metadata": {
        "id": "kqkLdFGl0FMB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 439
        },
        "outputId": "f5af0a33-aac3-49fb-bc31-3ceef5e45c14"
      },
      "cell_type": "code",
      "source": [
        "from keras.models import Model\n",
        "from keras.layers import Input, LSTM, Dense, Embedding,CuDNNLSTM,Bidirectional,Concatenate,Dropout\n",
        "\n",
        "# size of tokenizer indexes\n",
        "\n",
        "num_decoder_tokens = num_encoder_tokens = len(dataset.word2index) \n",
        "print (num_decoder_tokens)\n",
        "\n",
        "embedding_dim=300 #100-300 good numbers\n",
        "latent_dim = 256\n",
        "batch_size=64\n",
        "epochs=30\n",
        "\n",
        "bidi_encoder=False\n",
        "cuddlstm=True  #on bidi , diff in time is 20s vs 32 se\n",
        "\n",
        "# Define an input sequence and process it.  \n",
        "# input: batch,num-of-words of integers (not-one-hot)\n",
        "# each batch should be of the size and padded, but between batches size can be different\n",
        "# batch 1:   len 7,8,9,10(max)  inside the same batch, size is similiar (less waste on GPU)\n",
        "# batch 2 :    len 97-100(max)  between batches size is different.\n",
        "# order is random... sometime small batch sometime large \n",
        "\n",
        "encoder_inputs = Input(shape=(None,),name='encoder_inputs')\n",
        "\n",
        "shared_embedding = Embedding(num_encoder_tokens, \n",
        "                     embedding_dim, \n",
        "                     #weights=[word_embedding_matrix], if there is one (word2vec)\n",
        "                     #trainable=False,                            \n",
        "                     #input_length=MAX_SEQUENCE_LENGTH, if there is one\n",
        "                     )\n",
        "#see dropout disucssion: https://github.com/keras-team/keras/issues/7290. iliaschalkidis \n",
        "#Dropout(noise_shape=(batch_size, 1, features))\n",
        "x = shared_embedding(encoder_inputs) \n",
        "if (cuddlstm):\n",
        "  encoder_lstm=CuDNNLSTM(latent_dim, return_state=True)\n",
        "else:\n",
        "  print ('using LSTM with dropout!')\n",
        "  #need to tune the dropout values (maybe fast.ai tips) , just invented those value\n",
        "  encoder_lstm=LSTM(latent_dim, return_state=True,dropout=0.3,recurrent_dropout=0.3)\n",
        "if (bidi_encoder):\n",
        "  encoder_lstm=Bidirectional(encoder_lstm,merge_mode='concat')\n",
        "  x, forward_h, forward_c, backward_h, backward_c = encoder_lstm(x) #output,h1,c1,h2,c2\n",
        "  state_h = Concatenate()([forward_h, backward_h])\n",
        "  state_c = Concatenate()([forward_c, backward_c])\n",
        "else:  \n",
        "  x, state_h, state_c = encoder_lstm(x)\n",
        "\n",
        "  \n",
        "  \n",
        "#sentence embedding LSTM: h,c  \n",
        "encoder_states = [state_h, state_c]\n",
        "\n",
        "# Set up the decoder, using `encoder_states` as initial state.\n",
        "#looks similiar to  \n",
        "#gold decoder_ouputs: [1,0,0] [0,1,0] one-hot of the below\n",
        "#encoder_inputs:      hello   world <end> <end>\n",
        "#decoder_input      : <style> hello world <end>   | style = bible1,bible2,(maybe-generic for pertraining)\n",
        " \n",
        "decoder_inputs = Input(shape=(None,),name='decoder_inputs')  \n",
        "\n",
        "decoder_latent_dim = latent_dim*2 if bidi_encoder else latent_dim #bi-di pass merge of h1+h2, c1+c2\n",
        "if (cuddlstm):\n",
        "  decoder_lstm = CuDNNLSTM(decoder_latent_dim, return_sequences=True,return_state=True) #returned state used in inference\n",
        "else:\n",
        "  decoder_lstm = LSTM(decoder_latent_dim, return_sequences=True,return_state=True)\n",
        "decoder_outputs, _, _  = decoder_lstm(shared_embedding(decoder_inputs), initial_state=encoder_states)\n",
        "decoder_dense  = Dense(num_decoder_tokens, activation='softmax',name='decoder_softmax')\n",
        "decoder_outputs = decoder_dense(decoder_outputs)\n",
        "\n",
        "# Define the model that will turn\n",
        "# `encoder_input_data` & `decoder_input_data` into `decoder_target_data`\n",
        "model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
        "\n",
        "# Compile & run training\n",
        "print (model.summary())\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# now for the INFER models (re-arrangement of the prev one)\n",
        "# Remember that the training model varaibles were:\n",
        "#                                        decoder_outputs\n",
        "#encoder   --->    encoder_states  -->   decoder_lstm  \n",
        "#shared_embedding                        shared_embeddings  \n",
        "#encoder_inputs                          decdoer_inputs                  \n",
        "encoder_model = Model(encoder_inputs, encoder_states)\n",
        "\n",
        "decoder_states_inputs = [Input(shape=(decoder_latent_dim,)), Input(shape=(decoder_latent_dim,))]\n",
        "\n",
        "decoder_outputs2, state_h, state_c = decoder_lstm(shared_embedding(decoder_inputs), initial_state=decoder_states_inputs)\n",
        "\n",
        "decoder_states = [state_h, state_c]\n",
        "decoder_outputs2 = decoder_dense(decoder_outputs2)\n",
        "\n",
        "decoder_model = Model(\n",
        "    [decoder_inputs] + decoder_states_inputs,\n",
        "    [decoder_outputs2] + decoder_states)\n",
        "\n",
        "\n",
        "\n",
        "    \n"
      ],
      "execution_count": 216,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "7350\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "decoder_inputs (InputLayer)     (None, None)         0                                            \n",
            "__________________________________________________________________________________________________\n",
            "encoder_inputs (InputLayer)     (None, None)         0                                            \n",
            "__________________________________________________________________________________________________\n",
            "embedding_6 (Embedding)         (None, None, 300)    2205000     encoder_inputs[0][0]             \n",
            "                                                                 decoder_inputs[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "cu_dnnlstm_11 (CuDNNLSTM)       [(None, 256), (None, 571392      embedding_6[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "cu_dnnlstm_12 (CuDNNLSTM)       [(None, None, 256),  571392      embedding_6[1][0]                \n",
            "                                                                 cu_dnnlstm_11[0][1]              \n",
            "                                                                 cu_dnnlstm_11[0][2]              \n",
            "__________________________________________________________________________________________________\n",
            "decoder_softmax (Dense)         (None, None, 7350)   1888950     cu_dnnlstm_12[0][0]              \n",
            "==================================================================================================\n",
            "Total params: 5,236,734\n",
            "Trainable params: 5,236,734\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "S983Fs2WYshb",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "VTobPYftYvQC",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "##  classifier\n",
        "\n",
        "**Intro**\n",
        "\n",
        "(1) We start with regukar seq2seq is encoder->embedding->decoder and trained with reconstruction-loss\n",
        "\n",
        "(2)We can build style-discriminator where the target is to classify author-style from the sentence-embedding.\n",
        "When training it you need to freeze the encoder and decoder parts of the model, then:\n",
        "input1: sentence --freezed encoder--> embedding    (no need to run decoder)\n",
        "input2: style (one-hot)\n",
        "output: style (one-hot)  \n",
        "The discriminator can be a simple classifier (dense-based) with simple minimize cross-entropy target.\n",
        "\n",
        "(3) The smart-part: We want to train the encoder to create an embedding which will fool the discriminator.\n",
        "We will freeze the discriminator weights, and train the encoder-decoder similiarly to (1) with extra objective.\n",
        "That the loss from the discriminator will be Maximized. \n"
      ]
    },
    {
      "metadata": {
        "id": "2BIl7v9DnM5j",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "\n",
        "#### Classifier model #############################\n",
        "# works on the embedding itself\n",
        "style_concat= Concatenate()(encoder_states)\n",
        "\n",
        "a = Dropout(0.1)(style_concat)                          \n",
        "# if your inputs have shape  (batch_size, timesteps, features) and you want the dropout mask to be the same for all timesteps, you can use noise_shape=(batch_size, 1, features).\n",
        "a = Dense(100,activation='relu',name='d_dense1')(a) \n",
        "#a = keras.layers.LeakyReLU()(a) #LeakyReLU  #why leaky? see: how to train your GAN - BUT IT FAILED TO LEARN (accuracy always 0.5)\n",
        "a = Dropout(0.1)(a)\n",
        "style_outputs = Dense(len(dataset.style2index),activation='softmax',name='d_dense_softmax')(a)\n",
        "\n",
        "d = Model(encoder_inputs,style_outputs)  #style_outputs : batch , one-hot-encoding-of-style\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "9TBO_5dXv40K",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## adverserial model"
      ]
    },
    {
      "metadata": {
        "id": "owHJkiERHsG1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 615
        },
        "outputId": "a86aa477-8e16-40ef-e013-b6e6185437f2"
      },
      "cell_type": "code",
      "source": [
        "############################# Adv model\n",
        "# Note that it does not have new layers, just combining all of them with new loss\n",
        "def inverse_categorical_crossentropy(y_true, y_pred):\n",
        "  #need to implement it better , sum(1/categorical_crossentropy_per_sample)\n",
        "  # if discriminator is random, on 2 styles, if expect 50% which should mean logloss of 1. so 1/1= 1\n",
        "  # if discriminator is great, 99%, log-loss close to 0 , so 1/0 is big.\n",
        "  # so expeceted range is GREAT=1 , BAD=BIGGG\n",
        "  \n",
        "  return 1/(K.categorical_crossentropy(y_true, y_pred)+0.0001)\n",
        "#style_outputs\n",
        "adv_model = Model([encoder_inputs, decoder_inputs],[decoder_outputs,style_outputs])\n",
        "\n",
        "print (adv_model.summary())\n"
      ],
      "execution_count": 269,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "decoder_inputs (InputLayer)     (None, None)         0                                            \n",
            "__________________________________________________________________________________________________\n",
            "encoder_inputs (InputLayer)     (None, None)         0                                            \n",
            "__________________________________________________________________________________________________\n",
            "embedding_6 (Embedding)         (None, None, 300)    2205000     encoder_inputs[0][0]             \n",
            "                                                                 decoder_inputs[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "cu_dnnlstm_11 (CuDNNLSTM)       [(None, 256), (None, 571392      embedding_6[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_13 (Concatenate)    (None, 512)          0           cu_dnnlstm_11[0][1]              \n",
            "                                                                 cu_dnnlstm_11[0][2]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_23 (Dropout)            (None, 512)          0           concatenate_13[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "d_dense1 (Dense)                (None, 100)          51300       dropout_23[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "cu_dnnlstm_12 (CuDNNLSTM)       [(None, None, 256),  571392      embedding_6[1][0]                \n",
            "                                                                 cu_dnnlstm_11[0][1]              \n",
            "                                                                 cu_dnnlstm_11[0][2]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_24 (Dropout)            (None, 100)          0           d_dense1[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "decoder_softmax (Dense)         (None, None, 7350)   1888950     cu_dnnlstm_12[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "d_dense_softmax (Dense)         (None, 2)            202         dropout_24[0][0]                 \n",
            "==================================================================================================\n",
            "Total params: 5,288,236\n",
            "Trainable params: 5,288,236\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "9fOJf8SLX_Xd",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# compile"
      ]
    },
    {
      "metadata": {
        "id": "YjI-3lfJv62T",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 562
        },
        "outputId": "1dd3937d-c8fd-43e9-861c-53f18d73590a"
      },
      "cell_type": "code",
      "source": [
        "# compile it all\n",
        "def print_trainable(model):\n",
        "  for layer in model.layers:\n",
        "    print (layer.name,layer,layer.trainable)\n",
        "    \n",
        "\n",
        "def set_trainable(model,trainable) :\n",
        "  \"\"\" set all layers of the model (ignores Input) to trainable True/False\"\"\"\n",
        "  for layer in model.layers:\n",
        "    if type(layer)==keras.engine.topology.InputLayer:\n",
        "      pass\n",
        "    else:\n",
        "      layer.trainable = trainable \n",
        "\n",
        "optimizer =  keras.optimizers.Adam()#clipvalue=0.5,clipnorm=1.0) #TODO: values!!!!!    \n",
        "######################################3\n",
        "#compile all, set trainable parts (as keras hold it before compilation)\n",
        "set_trainable(d,model)    \n",
        "model.compile(optimizer=optimizer, loss='categorical_crossentropy')  #30peocs loss: 0.2836 - val_loss: 0.4428\n",
        "print ('\\nmodel compiled with:')\n",
        "print_trainable(model)\n",
        "\n",
        "\n",
        "# when training d, the encoder should not change.\n",
        "# impl. detail: instead of choose layers one by one, we first set all d True then override part with False\n",
        "set_trainable(d,True)    \n",
        "set_trainable(encoder_model,False) #setting it back(it's parts of d)\n",
        "d.compile(optimizer=optimizer, loss='categorical_crossentropy',metrics=['accuracy'])\n",
        "print ('\\nd compiled with:')\n",
        "print_trainable(d)\n",
        "\n",
        "# when training adv_model, the decoder should not change\n",
        "set_trainable(d,False)\n",
        "set_trainable(model,True)\n",
        "adv_model.compile(optimizer=optimizer, \n",
        "                  loss=['categorical_crossentropy',inverse_categorical_crossentropy],\n",
        "                  loss_weights=[1, 1])\n",
        "print ('\\nadv compiled with:')\n",
        "print_trainable(adv_model)\n"
      ],
      "execution_count": 270,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "model compiled with:\n",
            "decoder_inputs <keras.engine.topology.InputLayer object at 0x7fd86d022c18> False\n",
            "encoder_inputs <keras.engine.topology.InputLayer object at 0x7fd86cfe8898> False\n",
            "embedding_6 <keras.layers.embeddings.Embedding object at 0x7fd86cfe8940> <keras.engine.training.Model object at 0x7fd989008320>\n",
            "cu_dnnlstm_11 <keras.layers.cudnn_recurrent.CuDNNLSTM object at 0x7fd86cfe88d0> <keras.engine.training.Model object at 0x7fd989008320>\n",
            "cu_dnnlstm_12 <keras.layers.cudnn_recurrent.CuDNNLSTM object at 0x7fd98870ee48> True\n",
            "decoder_softmax <keras.layers.core.Dense object at 0x7fd86d1c9eb8> True\n",
            "\n",
            "d compiled with:\n",
            "encoder_inputs <keras.engine.topology.InputLayer object at 0x7fd86cfe8898> False\n",
            "embedding_6 <keras.layers.embeddings.Embedding object at 0x7fd86cfe8940> False\n",
            "cu_dnnlstm_11 <keras.layers.cudnn_recurrent.CuDNNLSTM object at 0x7fd86cfe88d0> False\n",
            "concatenate_13 <keras.layers.merge.Concatenate object at 0x7fd86b09bcc0> True\n",
            "dropout_23 <keras.layers.core.Dropout object at 0x7fd86b09b550> True\n",
            "d_dense1 <keras.layers.core.Dense object at 0x7fd86b09bbe0> True\n",
            "dropout_24 <keras.layers.core.Dropout object at 0x7fd86a7edef0> True\n",
            "d_dense_softmax <keras.layers.core.Dense object at 0x7fd86a7ede10> True\n",
            "\n",
            "adv compiled with:\n",
            "decoder_inputs <keras.engine.topology.InputLayer object at 0x7fd86d022c18> False\n",
            "encoder_inputs <keras.engine.topology.InputLayer object at 0x7fd86cfe8898> False\n",
            "embedding_6 <keras.layers.embeddings.Embedding object at 0x7fd86cfe8940> True\n",
            "cu_dnnlstm_11 <keras.layers.cudnn_recurrent.CuDNNLSTM object at 0x7fd86cfe88d0> True\n",
            "concatenate_13 <keras.layers.merge.Concatenate object at 0x7fd86b09bcc0> False\n",
            "dropout_23 <keras.layers.core.Dropout object at 0x7fd86b09b550> False\n",
            "d_dense1 <keras.layers.core.Dense object at 0x7fd86b09bbe0> False\n",
            "cu_dnnlstm_12 <keras.layers.cudnn_recurrent.CuDNNLSTM object at 0x7fd98870ee48> True\n",
            "dropout_24 <keras.layers.core.Dropout object at 0x7fd86a7edef0> False\n",
            "decoder_softmax <keras.layers.core.Dense object at 0x7fd86d1c9eb8> True\n",
            "d_dense_softmax <keras.layers.core.Dense object at 0x7fd86a7ede10> False\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "_ZC94QpK1bcw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 246
        },
        "outputId": "a5442e04-4515-43f5-b895-68f376061561"
      },
      "cell_type": "code",
      "source": [
        "max_decoder_seq_length=dataset.MAX_SEQUENCE_LENGTH\n",
        "print (max_decoder_seq_length)\n",
        "# TODO: now it's greedy and use argmax\n",
        "# maybe to choose randomly by distribution\n",
        "# and maybe to implement BEAM SEARCH\n",
        "def decode_sequence(input_seq,style,verbose=False):\n",
        "    assert input_seq.shape == (1, max_decoder_seq_length )\n",
        "    if verbose: print ('input_seq',input_seq.shape)\n",
        "    # Encode the input as state vectors.\n",
        "    states_value = encoder_model.predict(input_seq)\n",
        "    if verbose: print ('encoder result states_value','h',states_value[0].shape,states_value[0].mean(),'c',states_value[1].shape,states_value[1].mean())\n",
        "    \n",
        "    # Generate empty target sequence of length 1.\n",
        "    #                      batch,word-number value is token (0 /122)\n",
        "    target_seq = np.zeros((1, 1))\n",
        "    # Populate the first character of target sequence with the start character.\n",
        "    target_seq[0, 0] = dataset.word2index[style]\n",
        "\n",
        "    # Sampling loop for a batch of sequences\n",
        "    # (to simplify, here we assume a batch of size 1).\n",
        "    stop_condition = False\n",
        "    decoded_sentence = []\n",
        "    while not stop_condition:\n",
        "        #start with encoder-state then change to self state\n",
        "        output_tokens, h, c = decoder_model.predict( [target_seq] + states_value) \n",
        "        if verbose: print ('output_tokens',output_tokens.shape,output_tokens.mean(),'h',h.shape,'c',c.shape)\n",
        "\n",
        "        # Sample a token\n",
        "        sampled_token_index = np.argmax(output_tokens)# [0, -1, :])\n",
        "        if verbose: print ('sampled_token_index',sampled_token_index.shape,output_tokens.max(),sampled_token_index)\n",
        "        decoded_sentence.append(sampled_token_index)\n",
        "\n",
        "        # Exit condition: either hit max length\n",
        "        # or find stop character.\n",
        "        if (sampled_token_index == dataset.word2index['<s>'] or\n",
        "           len(decoded_sentence) > max_decoder_seq_length):\n",
        "          stop_condition = True\n",
        "\n",
        "        # Update the target sequence (of length 1).\n",
        "        target_seq = np.zeros((1, 1))\n",
        "        target_seq[0, 0] = sampled_token_index\n",
        "\n",
        "        # Update states\n",
        "        states_value = [h, c]\n",
        "\n",
        "    res= np.array(decoded_sentence) #[dataset.index2word[index] for index in decoded_sentence]\n",
        "    return res\n",
        "\n",
        "  \n",
        "\n",
        "def show_sample(data_type='val',teacher_forcing=False,sample_ids=[1000],replace_style=None):\n",
        "  \"\"\" \n",
        "    teacher_forcing : should we simulate training and feed the input. default False, as for test\n",
        "  \"\"\"\n",
        "  for i in sample_ids:\n",
        "      data={'train': dataset.result.train,'val':dataset.result.val , 'test':dataset.result.test}\n",
        "      \n",
        "      print ('\\n')\n",
        "      one_x= data[data_type][0][i:i+1]\n",
        "\n",
        "      one_x_d= data[data_type][1][i:i+1]\n",
        "      if replace_style:\n",
        "        if dataset.index2word[one_x_d[0,0]]==replace_style:\n",
        "           print ('No need to replace style, already in',replace_style)\n",
        "        style_as_text = replace_style\n",
        "        one_x_d= np.copy(one_x_d)\n",
        "        one_x_d[0,0]=dataset.word2index[replace_style]\n",
        "      else:\n",
        "        style_as_text = dataset.index2word[one_x_d[0][0]]\n",
        "        \n",
        "      #one_y= data[data_type][2][i:i+1]\n",
        "      if one_x.shape[0]==0:\n",
        "        print ('sample out of range',data[data_type][0].shape)\n",
        "      print ('gold  x: ',dataset.one_x_as_text(one_x))\n",
        "      #internal debug print ('gold_styl:',dataset.one_x_as_text(one_x_d))\n",
        "      #internal debug print ('gold y: ',dataset.one_y_as_text(one_y))\n",
        "      \n",
        "      \n",
        "      if teacher_forcing:\n",
        "        p = model.predict([one_x,one_x_d])\n",
        "        print ('actual y:',dataset.one_y_as_text(p))  \n",
        "        print ('used teacher-forcing:',one_x_d[0][0])\n",
        "      else:\n",
        "        p = decode_sequence(one_x,style_as_text)\n",
        "        print ('actual y:',dataset.one_x_as_text(p))   \n",
        "        print ('used sample:',style_as_text)\n",
        "\n",
        "\n",
        "#show_sample(data_type='train',sample_ids=[0,8000,16000])#,replace_style='t_bbe.csv')    \n",
        "#show_sample(data_type='train',sample_ids=[1,8001,16001])#,replace_style='t_bbe.csv')  \n",
        "\n",
        "\n",
        "for i in [0]:#,1,1000,1001]:\n",
        "  print ('#'*30,'verb',i,'#'*30)\n",
        "  show_sample('train',sample_ids=[i,8000+i],teacher_forcing=True,replace_style='t_bbe.csv')   \n",
        "    "
      ],
      "execution_count": 271,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "20\n",
            "############################## verb 0 ##############################\n",
            "\n",
            "\n",
            "No need to replace style, already in t_bbe.csv\n",
            "gold  x:  At the first God made the heaven and the earth. <s> <s> <s> <s> <s> <s> <s> <s> <s> <s>\n",
            "actual y: At the first God made the heaven and the earth. <s> <s> <s> <s> <s> <s> <s> <s> <s> <s>\n",
            "used teacher-forcing: 7347.0\n",
            "\n",
            "\n",
            "gold  x:  In the beginning of God's preparing the heavens and the earth -- <s> <s> <s> <s> <s> <s> <s> <s>\n",
            "actual y: \"In the end of heaven preparing the earth and the earth and <s> <s> <s> <s> <s> <s> <s> <s>\n",
            "used teacher-forcing: 7347.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "9s0-8EJi6AG1",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# TRAINING"
      ]
    },
    {
      "metadata": {
        "id": "0_0G8_Dr2bMM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "outputId": "e0ec524d-e617-473c-cf55-667a40541452"
      },
      "cell_type": "code",
      "source": [
        "import keras\n",
        "from keras.callbacks import ReduceLROnPlateau\n",
        "class LossHistory(keras.callbacks.Callback):\n",
        "    def __init__(self):\n",
        "      self.losses = {'loss':[],'val_loss':[]}\n",
        "      \n",
        "    #def on_train_begin(self, logs={}):\n",
        "    #  pass  \n",
        "    \n",
        "    def on_epoch_end(self, batch, logs={}):\n",
        "      for loss in ['loss','val_loss']:\n",
        "        self.losses[loss].append(logs.get(loss))\n",
        "        \n",
        "np.random.seed(42)\n",
        "\n",
        "\n",
        "def gen(t,batch_size,gen_type):\n",
        "    \"\"\"grn_type = g/d/adv\"\"\"\n",
        "    x_encoder,x_decoder,y_one_hot_decoder,y_style = t\n",
        "    WORDS=x_encoder.shape[1]\n",
        "    while 1:\n",
        "      ind=np.array(np.random.randint(len(x_encoder),size=(batch_size) ))\n",
        "      \n",
        "      #build decoder target data on the fly\n",
        "      one_hot = np.zeros((batch_size,WORDS,len(dataset.index2word)))\n",
        "      for row in range(batch_size):\n",
        "         for t in range(WORDS):\n",
        "            one_hot[row,t,int(x_encoder[ind][row,t])] = 1\n",
        "      \n",
        "      if gen_type=='g':\n",
        "        yield ([x_encoder[ind],x_decoder[ind]],one_hot)\n",
        "      elif gen_type=='d':\n",
        "        yield (x_encoder[ind],y_style[ind])\n",
        "      elif gen_type=='adv':\n",
        "        yield ([x_encoder[ind],x_decoder[ind]],[one_hot,y_style[ind]]) #y_one_hot_decoder[ind]\n",
        "      else:\n",
        "        raise ValueError('gen_type unkown',gen_type)\n",
        "\n",
        "gener=gen(dataset.result.val,5,'d')\n",
        "x1,y=next(gener)\n",
        "print ('test gen batch 2',x1.shape,y.shape,y)\n",
        "\n",
        "\n",
        "     \n",
        "\n",
        "loss_history = LossHistory()\n",
        "loss_history_d = LossHistory()\n",
        "loss_history_adv = LossHistory()\n",
        "\n"
      ],
      "execution_count": 272,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "test gen batch 2 (5, 20) (5, 2) [[0. 1.]\n",
            " [0. 1.]\n",
            " [1. 0.]\n",
            " [0. 1.]\n",
            " [0. 1.]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Sm05AY862pem",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "outputId": "23880600-1d7f-495e-e380-dae51d5ef776"
      },
      "cell_type": "code",
      "source": [
        "from keras import backend as K\n",
        "\n",
        "batch_size=64\n",
        "\n",
        "          \n",
        "\n",
        "\n",
        "def train_g(steps,validation_steps=1):\n",
        "                                                                \n",
        "    model.fit_generator(gen(dataset.result.train,batch_size,'g'),\n",
        "                        steps,\n",
        "                        validation_steps=validation_steps,\n",
        "                        validation_data=gen(dataset.result.val,batch_size,'g'),\n",
        "                        callbacks=[loss_history],\n",
        "                        verbose=0 if steps<50 else 1,\n",
        "                        max_queue_size=10,\n",
        "                        workers=2\n",
        "                       )\n",
        "    #model.fit([x_train, x_train_d], y_train,\n",
        "    \n",
        "def train_d(steps,validation_steps=1):\n",
        "  # check wieghts\n",
        "  d.trainable = True  #only for warning\n",
        "  \n",
        "  d.fit_generator(gen(dataset.result.train,batch_size,'d'),\n",
        "                        steps,\n",
        "                        validation_steps=validation_steps,\n",
        "                        validation_data=gen(dataset.result.val,batch_size,'d'),\n",
        "                        verbose=0 if steps<50 else 1,\n",
        "                        callbacks=[loss_history_d])\n",
        "  # d.fit(x_train, style_train,\n",
        "  d.trainable = False  #only for warning\n",
        "  \n",
        "              \n",
        " \n",
        "\n",
        "  \n",
        "def train_adv(steps,validation_steps=1):\n",
        "  #adv_model.fit([x_train, x_train_d], [y_train,style_train],\n",
        "  adv_model.fit_generator(gen(dataset.result.train,batch_size,'adv'),\n",
        "                        steps,\n",
        "                        validation_steps=validation_steps,\n",
        "                        validation_data=gen(dataset.result.val,batch_size,'adv'),\n",
        "                        verbose=0 if steps<50 else 1,\n",
        "                        callbacks=[loss_history_adv])\n",
        "  \n",
        "  \n",
        "\n",
        "\n",
        "\n",
        "  \n",
        "\n",
        "#def print_d_mean():\n",
        "#  print(d.get_layer('d_dense_softmax').get_weights()[0].mean(),'b',d.get_layer('d_dense_softmax').get_weights()[1].mean())\n",
        "\n",
        "#next(generate_from_result(dataset.result.val,32))\n",
        "epoc = int(len(dataset.result.train[0])/batch_size)\n",
        "#init: \n",
        "#train_g(epoc*1)  #pretrain\n",
        "\n",
        "\n",
        "show_sample('train',sample_ids=[0],teacher_forcing=True)   #,8000+0\n",
        "\n",
        "small_steps=5\n",
        "for e in range(0):\n",
        "  print ('epocs',e)\n",
        "  for _ in range(int(epoc/small_steps)):\n",
        "    train_d(small_steps)\n",
        "    train_adv(small_steps)\n",
        "  show_sample('train',sample_ids=[0],teacher_forcing=True)   #,8000+0\n",
        "  plt_all()\n",
        "  \n",
        "print ('done')\n",
        "\n",
        "\n"
      ],
      "execution_count": 278,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "gold  x:  At the first God made the heaven and the earth. <s> <s> <s> <s> <s> <s> <s> <s> <s> <s>\n",
            "actual y: At the first day made the heaven and the earth. <s> <s> <s> <s> <s> <s> <s> <s> <s> <s>\n",
            "used teacher-forcing: 7347.0\n",
            "done\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "R_OBmX182djj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 294
        },
        "outputId": "247f79b9-c392-437e-b785-6f44d21e3f96"
      },
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt \n",
        "\n",
        "# summarize history for loss\n",
        "def plt_losses(loss_history,title,with_val=False):\n",
        "  plt.plot(loss_history.losses['loss'][:])\n",
        "  if with_val:\n",
        "    plt.plot(loss_history.losses['val_loss'][:])\n",
        "  plt.title(title)\n",
        "  med=0.1 if len(loss_history.losses['loss'])<1 else np.median(loss_history.losses['loss'])\n",
        "  plt.ylim(ymax=med+0.5)\n",
        "  plt.ylabel('loss')\n",
        "  plt.xlabel('epoch')\n",
        "  plt.legend(['train', 'val'], loc='upper right')\n",
        "  \n",
        "\n",
        "def plt_all():  \n",
        "  plt.figure(figsize=(14,4))\n",
        "  plt.subplot(131) #numrows, numcols, fignum\n",
        "  plt_losses(loss_history,'g loss')  \n",
        "  plt.subplot(132)\n",
        "  plt_losses(loss_history_d,'d loss')  \n",
        "  plt.subplot(133)\n",
        "  plt_losses(loss_history_adv,'adv loss') \n",
        "  plt.show()\n",
        "\n",
        "plt_all()"
      ],
      "execution_count": 161,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAz4AAAEVCAYAAAAhPzAEAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n+BLTBat9hx4AAAAASUVORK5CYII=\n",
            "text/plain": [
              "<matplotlib.figure.Figure at 0x7fd86deefba8>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "HWiYXoTTX02f",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "I2NGxSQb2dxD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 378
        },
        "outputId": "c9fcbba8-8e48-459e-d563-934d3e977955"
      },
      "cell_type": "code",
      "source": [
        "#print ('eval on train:',model.evaluate([x_train, x_train_d], y_train))\n",
        "#print ('eval on val:',model.evaluate([x_val, x_val_d], y_val))\n",
        "\n",
        "s=20\n",
        "e=s+1\n",
        "print ('score',model.evaluate([x_train[s:e], x_train_d[s:e]], y_train[s:e],batch_size=batch_size,verbose=0))\n",
        "\n",
        "show_sample('train',False,s) \n",
        "\n",
        "\n",
        "print ('\\n COMPARE TO VAL:\\n')\n",
        "print('score',model.evaluate([x_val[s:e], x_val_d[s:e]], y_val[s:e],batch_size=batch_size,verbose=0))\n",
        "show_sample('val',False,s) \n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "score 0.006540380418300629\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-23-67451f46e0d1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'score'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_train_d\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mshow_sample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'train'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-19-7470d20ad84d>\u001b[0m in \u001b[0;36mshow_sample\u001b[0;34m(data_type, teacher_forcing, sample_ids, replace_style)\u001b[0m\n\u001b[1;32m     50\u001b[0m     \u001b[0mteacher_forcing\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mshould\u001b[0m \u001b[0mwe\u001b[0m \u001b[0msimulate\u001b[0m \u001b[0mtraining\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed\u001b[0m \u001b[0mthe\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mdefault\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m   \"\"\"\n\u001b[0;32m---> 52\u001b[0;31m   \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msample_ids\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     53\u001b[0m       \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'train'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'val'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mval\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0;34m'test'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: 'int' object is not iterable"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "XvIkFOWy55ov",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Error analysis"
      ]
    },
    {
      "metadata": {
        "id": "Ob6kDbRUBJki",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 396
        },
        "outputId": "ac970bea-cbb0-4556-ea6d-24c4816104d2"
      },
      "cell_type": "code",
      "source": [
        "\n",
        "def show_sample(data_type='val',teacher_forcing=False,sample_ids=[1000],replace_style=None):\n",
        "  \"\"\" \n",
        "    teacher_forcing : should we simulate training and feed the input. default False, as for test\n",
        "  \"\"\"\n",
        "  for i in sample_ids:\n",
        "      data={'train': dataset.result.train,'val':dataset.result.val , 'test':dataset.result.test}\n",
        "      \n",
        "      print ('\\n')\n",
        "      one_x= data[data_type][0][i:i+1]\n",
        "\n",
        "      one_x_d= data[data_type][1][i:i+1]\n",
        "      if replace_style:\n",
        "        if dataset.index2word[one_x_d[0,0]]==replace_style:\n",
        "           print ('No need to replace style, already in',replace_style)\n",
        "        style_as_text = replace_style\n",
        "        one_x_d= np.copy(one_x_d)\n",
        "        one_x_d[0,0]=dataset.word2index[replace_style]\n",
        "      else:\n",
        "        style_as_text = dataset.index2word[one_x_d[0][0]]\n",
        "        \n",
        "      one_y= data[data_type][2][i:i+1]\n",
        "      if one_x.shape[0]==0:\n",
        "        print ('sample out of range',data[data_type][0].shape)\n",
        "      print ('gold  x: ',dataset.one_x_as_text(one_x))\n",
        "      #internal debug print ('gold_styl:',dataset.one_x_as_text(one_x_d))\n",
        "      #internal debug print ('gold y: ',dataset.one_y_as_text(one_y))\n",
        "      \n",
        "      \n",
        "      if teacher_forcing:\n",
        "        p = model.predict([one_x,one_x_d])\n",
        "        print ('actual y:',dataset.one_y_as_text(p))  \n",
        "        print ('used teacher-forcing:',one_x_d[0][0])\n",
        "      else:\n",
        "        p = decode_sequence(one_x,style_as_text)\n",
        "        print ('actual y:',dataset.one_x_as_text(p))   \n",
        "        print ('used sample:',style_as_text)\n",
        "\n",
        "\n",
        "#show_sample(data_type='train',sample_ids=[0,8000,16000])#,replace_style='t_bbe.csv')    \n",
        "#show_sample(data_type='train',sample_ids=[1,8001,16001])#,replace_style='t_bbe.csv')  \n",
        "\n",
        "\n",
        "for i in [0,1,1000,1001]:\n",
        "  print ('#'*30,'verb',i,'#'*30)\n",
        "  show_sample('train',sample_ids=[i,8000+i],teacher_forcing=True,replace_style='t_bbe.csv') "
      ],
      "execution_count": 233,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "############################## verb 0 ##############################\n",
            "\n",
            "\n",
            "No need to replace style, already in t_bbe.csv\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-233-a67080209b8a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1001\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m   \u001b[0mprint\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'#'\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m30\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'verb'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'#'\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m30\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 46\u001b[0;31m   \u001b[0mshow_sample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'train'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msample_ids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m8000\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mteacher_forcing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mreplace_style\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m't_bbe.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-233-a67080209b8a>\u001b[0m in \u001b[0;36mshow_sample\u001b[0;34m(data_type, teacher_forcing, sample_ids, replace_style)\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0mstyle_as_text\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex2word\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mone_x_d\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m       \u001b[0mone_y\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdata_type\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mone_x\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0mprint\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'sample out of range'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdata_type\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: 'NoneType' object is not subscriptable"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "TkFXxinr0fNo",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 343
        },
        "outputId": "1750af53-9416-4f6a-cfd6-efe4ac984f08"
      },
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "\n",
        "#a= model.predict([x_train[s:e], x_train_d[s:e]])\n",
        "#for i in range(dataset.MAX_SEQUENCE_LENGTH):\n",
        "#  best=np.argmax(a[0,i])\n",
        "#  print (i,best,dataset.index2word[best],a[0,i,best],a[0,i,0])\n",
        "\n",
        "from keras.losses import categorical_crossentropy\n",
        "p=model.predict([x_val,x_val_d])\n",
        "scores=K.eval(K.sum(categorical_crossentropy(K.constant(p), K.constant(y_val) ),axis=1))\n",
        "worse_10 = scores.argsort()[::-1][:10]\n",
        "\n",
        "for i in range(len(worse_10)):\n",
        "  bad=worse_10[i]\n",
        "  print (i,'arg',bad,'score',scores[bad],show_sample('val',False,bad))\n",
        "  \n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-98-1e4d70dec522>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mworse_10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m   \u001b[0mbad\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworse_10\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m   \u001b[0mprint\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'arg'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbad\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'score'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mscores\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbad\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mshow_sample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'val'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbad\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-74-7470d20ad84d>\u001b[0m in \u001b[0;36mshow_sample\u001b[0;34m(data_type, teacher_forcing, sample_ids, replace_style)\u001b[0m\n\u001b[1;32m     50\u001b[0m     \u001b[0mteacher_forcing\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mshould\u001b[0m \u001b[0mwe\u001b[0m \u001b[0msimulate\u001b[0m \u001b[0mtraining\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed\u001b[0m \u001b[0mthe\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mdefault\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m   \"\"\"\n\u001b[0;32m---> 52\u001b[0;31m   \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msample_ids\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     53\u001b[0m       \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'train'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'val'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mval\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0;34m'test'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: 'numpy.int64' object is not iterable"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "8QaOXXjUAwVH",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Error of style disc."
      ]
    },
    {
      "metadata": {
        "id": "t_YnBS4fAr1M",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 439
        },
        "outputId": "66f96bc5-cef6-40b6-e629-a0ebd0e1badf"
      },
      "cell_type": "code",
      "source": [
        "### Error of style discriminator\n",
        "\n",
        "print (style_val[:10])\n",
        "print(d.predict(x_val[:10]))#, style_train,\n",
        "print('train',d.evaluate(x_train[:10],style_train[:10]))\n",
        "print('val',d.evaluate(x_val[:10],style_val[:10]))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[1. 0.]\n",
            " [1. 0.]\n",
            " [1. 0.]\n",
            " [1. 0.]\n",
            " [1. 0.]\n",
            " [1. 0.]\n",
            " [1. 0.]\n",
            " [1. 0.]\n",
            " [1. 0.]\n",
            " [1. 0.]]\n",
            "[[1.0000000e+00 8.6882187e-23]\n",
            " [5.0392920e-01 4.9607080e-01]\n",
            " [1.0000000e+00 4.3903558e-11]\n",
            " [1.0000000e+00 7.5971468e-19]\n",
            " [4.6258405e-01 5.3741598e-01]\n",
            " [1.0000000e+00 6.1337112e-13]\n",
            " [1.8087876e-01 8.1912118e-01]\n",
            " [5.6046247e-01 4.3953755e-01]\n",
            " [5.4291797e-01 4.5708200e-01]\n",
            " [1.3678908e-01 8.6321092e-01]]\n",
            "10/10 [==============================] - 0s 607us/step\n",
            "train [0.7125540971755981, 0.5]\n",
            "10/10 [==============================] - 0s 362us/step\n",
            "val [0.6345280408859253, 0.699999988079071]\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}
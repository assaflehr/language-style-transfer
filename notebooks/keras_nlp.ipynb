{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "keras_nlp.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "[View in Colaboratory](https://colab.research.google.com/github/assaflehr/language-style-transfer/blob/master/notebooks/keras_nlp.ipynb)"
      ]
    },
    {
      "metadata": {
        "id": "vR_wGTR6szDb",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        ""
      ]
    },
    {
      "metadata": {
        "id": "wp4BcB4250bT",
        "colab_type": "toc"
      },
      "cell_type": "markdown",
      "source": [
        ">>[Keras accuracy/performace limitations](#scrollTo=vR_wGTR6szDb)\n",
        "\n",
        ">>[Pretraining autoencoder or LM will surely help.](#scrollTo=vR_wGTR6szDb)\n",
        "\n",
        ">>>[CuDNNLSTM vs LSTM](#scrollTo=vR_wGTR6szDb)\n",
        "\n",
        ">>>[Tip to self:](#scrollTo=vR_wGTR6szDb)\n",
        "\n",
        ">>>[For David: example of how to clone, then use from github](#scrollTo=OrKzdh71sBKm)\n",
        "\n",
        ">[Dataset](#scrollTo=wwc6_EHFD_Ir)\n",
        "\n",
        ">[Model defintion](#scrollTo=BWVEcaeF6DBR)\n",
        "\n",
        ">>[classifier](#scrollTo=VTobPYftYvQC)\n",
        "\n",
        ">>[adverserial model](#scrollTo=9TBO_5dXv40K)\n",
        "\n",
        ">[TRAINING](#scrollTo=9s0-8EJi6AG1)\n",
        "\n",
        ">[Error analysis](#scrollTo=XvIkFOWy55ov)\n",
        "\n",
        ">>[Error of style disc.](#scrollTo=8QaOXXjUAwVH)\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "Og2XNK-_53VP",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Keras accuracy/performace limitations\n",
        " \n",
        "# Performace caution :\n",
        "G training epoc (250x64 rows) \n",
        "\n",
        "type|RNN|bidi?|time\n",
        "--|--\n",
        "CPU|LSTM|Y| 15 min|\n",
        "GPU|LSTM|Y| 75s| (slower but more-accurate)\n",
        "GPU|CuDNNLSTM|Y| 42s\n",
        "GPU|CuDNNLSTM|N| 35s\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "## Pretraining autoencoder or LM will surely help.\n",
        "\n",
        "see late review here: https://thegradient.pub/author/sebastian\n",
        "and autoencoder (which is less recommended than LM here: \"Semi-supervised Sequence Learning\" 2015. They use one RNN for both encoder and decoder)\n",
        "\n",
        "\n",
        "###   LSTM \n",
        "* CuDNNLSTM trains on GPU , but does not support the attributes: dropout,recurrent_dropout,which are the STOA regulaizers. This is cuda problem, and even native TF does not support it\n",
        "Hard to compare only that. all G (with dense and more...) takes 35s on GPU. on CPU ???\n",
        "* Make LSTM deep instead of bigger for linear instead of quadratic growth in compuation. when doing so, add skip connection to 2nd/3rd/... layers\n",
        "* large vocab size means huge softmax, means slow runtime. to optimize training NCE loss replaces softmax on train-time (TF only)\n",
        "\n",
        "### Tip to self:\n",
        "* manually check loss value on one sample (predict vs gt). From doing this, I saw <s> was not given one-hot-value"
      ]
    },
    {
      "metadata": {
        "id": "OrKzdh71sBKm",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### For David: example of how to clone, then use from github\n",
        "```python\n",
        "#!rm -r language-style-transfer  #remove previous github copy if needed\n",
        "!git clone https://github.com/assaflehr/language-style-transfer.git\n",
        "#we rename to as lang_transfer will be the package name\n",
        "!mv language-style-transfer/code language-style-transfer/lang_transfer\n",
        "\n",
        "# Add the local_modules directory to the set of paths Python uses to look for imports.\n",
        "import sys\n",
        "sys.path.append('language-style-transfer')\n",
        "\n",
        "import lang_transfer   #your code here!!!\n",
        "```"
      ]
    },
    {
      "metadata": {
        "id": "UbJwZjyhsDvP",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# adaptation of: https://blog.keras.io/a-ten-minute-introduction-to-sequence-to-sequence-learning-in-keras.html\n",
        "# first Dataset class to load bible-data\n",
        "# then copy of the model, but working with words instead of chars\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "MBAgWVvXycpF",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Some params"
      ]
    },
    {
      "metadata": {
        "id": "tyGmM8WFrH4n",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "embedding_dim=300 #100-300 good numbers\n",
        "latent_dim = 256  #for hidden unit of LSTM\n",
        "bidi_encoder=True\n",
        "cuddlstm=True  #on bidi , diff in time is 20s vs 32 se\n",
        "\n",
        "batch_size=64\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "wwc6_EHFD_Ir",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Dataset"
      ]
    },
    {
      "metadata": {
        "id": "PcPSCDUrx3B8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 600
        },
        "outputId": "aed55ec2-ad05-4a61-ebc1-f376542045ec"
      },
      "cell_type": "code",
      "source": [
        "## NLP preprocessing for text\n",
        "# has few parts:\n",
        "# 1. load zip files and then use glob to filter part of them (data/*/*.txt)\n",
        "# 2. parse each row into (x,y) by passing a parser method. it can be simple as lambda line:line:x, or if you use tab delimited lambda line: line.split(',')[4]\n",
        "# 3. tokenize - split by spaces, but also by ., and be smart about it.  ('...' should be one token , \"ai'nt\" one token. then; should be two 'token' and ';')\n",
        "#    you should also build vocabulary, keep X words and throw away rare ones, they will be replaced by <oov> flag.\n",
        "# 4. transform text to sequences for the result. for words there are usually two different types: ['s>','hello', 'world'] -> [0,5,6] but there is also \n",
        "#     a one-hot-econding version where 5 is actaully a vector of size voc-length full of zeros, with 5th index==1.\n",
        "#    The one-hot ecoding is used as output for text-generation and has a HUGE MEMORY requirement.  100K sentences of size 20 words need 2M floats = 8MB\n",
        "#    But for the one-hot-encoding multiply this by vocab-size. for char-encoding it's ~30 , for good vocab of 10K words, we need 80GB(!)\n",
        "#    The simple, and only , way to solve this , is to never keep one-hot-encoding in memory, just use a generator to make it one-hot in runtime\n",
        "\n",
        "\n",
        "\n",
        "from __future__ import print_function\n",
        "\n",
        "import numpy as np\n",
        "import os\n",
        "import glob\n",
        "import csv, json\n",
        "from collections import namedtuple\n",
        "from zipfile import ZipFile\n",
        "from os.path import expanduser, exists\n",
        "import keras\n",
        "from keras import backend as K\n",
        "from keras.utils.data_utils import get_file\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.utils.data_utils import get_file\n",
        "from keras.utils import to_categorical\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "\n",
        "\n",
        "\n",
        "TVT = namedtuple('TVT',['train','val','test'])\n",
        "\n",
        "class Dataset:\n",
        "  #Dataset for COPY encoder-decoder\n",
        "  # to David: generator x,y where x1 is encoder_input is batch_size,max-words of type integer. (hello word <e> )   [x] (64,10)\n",
        "  #                               x2 is decoder_input is batch,max-words of type integer  ( <s>  hello word)  [x]      (64,10)\n",
        "  #                               y1             batch,max-words,one-hot-encoding (offset one: hello world <end>) (64,10,10000)\n",
        "  #                               y_style:           batch,one-hot-of-style                                       (64,2)\n",
        "  #                                          shape: (64,10)  batch_size=64 ,max_words=10 , vocab_size= 10000  style_vocab=2/5\n",
        "  # tokenizer is currently very bad. replace it\n",
        "  # vocabulary (training-only) , don't use 666 , use large number (10K?)\n",
        "  # Generator : iteration result ([x1,x2],[y1,y_style])\n",
        "  \n",
        "  # for auto-encoder pre-training without style  ([x1,x2],y1)  with no y_style\n",
        "  \n",
        "  \n",
        "  def __init__(self,unique_name,url,extract,cache_dir,pattern,skip_first,row_parser,validation_pattern=0.1,test_pattern=0.1):\n",
        "    '''\n",
        "    unique_name will be used for the dataset source(or zip) file. \n",
        "    pattern need to include path inside zip (including zip root)\n",
        "    extract - is it zipped/tarred or not\n",
        "    cache_dir - under which the files be downloaded <cache_dir>/datasets/<unique_name>\n",
        "    pattern - glob will be done to choose only those files ,for example data*.txt. This should incldude both train and test\n",
        "    validation - subset glob pattern to use. If it's a float like 0.1, use it as split of one file\n",
        "    test - see above\n",
        "    '''\n",
        "    if not extract and pattern:\n",
        "      raise ValueError('pattern must be empty if extract=False chooses a subset of the files (data/*.txt). but you downloaded only one file')\n",
        "\n",
        "    if not os.path.exists(cache_dir):\n",
        "       os.makedirs(cache_dir)\n",
        "\n",
        "    fpath=get_file(unique_name, url,extract=True, cache_dir=cache_dir)\n",
        "    print ('fpath',fpath)\n",
        "    files = [fpath] if not pattern else glob.glob(f'{cache_dir}/datasets/{pattern}')\n",
        "\n",
        "    train,val,test=[],[],[]\n",
        "    for f in files:\n",
        "      lines = [row_parser(f,line.rstrip()) for line in open(f,encoding=\"latin-1\").readlines()] \n",
        "      lines = lines[1 if skip_first else 0:][:10000]\n",
        "      print ('HARDCODED MAX LINES = 10000')\n",
        "      \n",
        "      print (files,'#lines',len(lines),'first 3 lines')\n",
        "      print (lines[0],'\\n',lines[1],'\\n',lines[2])\n",
        "      \n",
        "      if isinstance(validation_pattern,float) and isinstance(test_pattern,float):\n",
        "        test_count = int(len(lines)*(1-validation_pattern))\n",
        "        val_count =  int(len(lines)*(1-test_pattern-validation_pattern))\n",
        "        print ('(val_count,test_count)',val_count,test_count)\n",
        "        train+= lines[:val_count]\n",
        "        val+=   lines[val_count:test_count]\n",
        "        test+=  lines[test_count:]\n",
        "        \n",
        "    self.tvt_lines = TVT(train, val, test)\n",
        "    print ('train:',len(self.tvt_lines.train),'val',len(self.tvt_lines.val),'test',len(self.tvt_lines.test))\n",
        "    self.parsed= self.tvt_lines\n",
        "  \n",
        "  \n",
        "  def fit(self):\n",
        "    \"\"\" the current implementation is quite bad, hello world! will be 2 tokens world! is the second. \n",
        "    \"\"\"\n",
        "    print ('limiting num_words in Tokenizer due to MEMORY BOUNDS')  #num_words =100*1000\n",
        "\n",
        "    \n",
        "    # I use here tokenizer only to count freq. of words, then manually choose most freq. and manually split\n",
        "    # this is bad. There are better ways to do it (probably library/code which do it in one line)\n",
        "    print ('\\nREPLACE ME . BAD TOKENIZER!!!')\n",
        "    self.tokenizer = Tokenizer(num_words=100000, filters='', lower=False, split=' ', char_level=False, oov_token='<oov>')\n",
        "    \n",
        "    # self.parsed.train is a list , each value is tuple text_string,file_name\n",
        "    self.tokenizer.fit_on_texts([x for x,style in self.parsed.train])\n",
        "    self.styles = set([style for x,style in self.parsed.train])\n",
        "    print ('styles',self.styles)\n",
        "    self.style2index = {style:i for i,style in enumerate(self.styles)}\n",
        "    self.index2style = {index:style for style,index in self.style2index.items() }\n",
        "    print (self.style2index,self.index2style)\n",
        "    \n",
        "    #print ('\\n word_index',len(self.tokenizer.word_index),'<oov>',self.tokenizer.word_index['<oov>'])\n",
        "    print ('common',list(self.tokenizer.word_index.items())[:15])\n",
        "    print ('uncommon',list(self.tokenizer.word_index.items())[-15:])\n",
        "  \n",
        "    \n",
        "    num_words= 10000\n",
        "    print ('CAPPING. keeping ',num_words,'of',len(self.tokenizer.word_index))\n",
        "    \n",
        "    num_words= min(num_words,len(self.styles)+1+len(self.tokenizer.word_index))\n",
        "    print (num_words,num_words,num_words)    \n",
        "    word2index = dict(list(self.tokenizer.word_index.items())[:num_words-len(self.styles)-2])\n",
        "    word2index['<s>']=0  #keras tokenizer keeps 0 unused\n",
        "    for i,style in enumerate(self.styles):\n",
        "      word2index[style]=num_words-1-len(self.styles)+i  #if num_words=100 . [96,97,98] \n",
        "    word2index['<oov>']=num_words-1                     #<oov> is [99]\n",
        "    print ('word2index',len(word2index))\n",
        "    \n",
        "    #FOR NOW the start and end are both ZERO. maybe not good???\n",
        "    \n",
        "    num_encoder_tokens = num_decoder_tokens= num_words # len(self.tokenizer.word_index)\n",
        "    self.word2index = word2index\n",
        "    self.index2word = {index:word for (word,index) in self.word2index.items()}\n",
        "    self.MAX_SEQUENCE_LENGTH=20  #100\n",
        "    \n",
        "    verbose=5\n",
        "    result = []\n",
        "    for rows in self.parsed:\n",
        "\n",
        "      encoder_input_data  = np.zeros( (len(rows), self.MAX_SEQUENCE_LENGTH),    dtype='float32')\n",
        "      decoder_input_data  = np.zeros( (len(rows), self.MAX_SEQUENCE_LENGTH),    dtype='float32') # shifted by 1\n",
        "      decoder_target_data = None #np.zeros((len(rows),  self.MAX_SEQUENCE_LENGTH, num_decoder_tokens),    dtype='float32')\n",
        "      style_data          = np.zeros((len(rows),  len(self.styles)),    dtype='float32') #one-hot\n",
        "      \n",
        "      #input to decoder   <s> hello world\n",
        "      #target of decoder: hello world <s>\n",
        "      \n",
        "      for i, (input_text,style) in enumerate(rows):\n",
        "        input_text = input_text.split(' ') #BUG: we need to use tokenizer here!!!!\n",
        "        #pad with end token  hello world <end> <end> <end>\n",
        "        end_token='<s>'\n",
        "        input_text += [end_token for _ in range(self.MAX_SEQUENCE_LENGTH - len(input_text)+1)]\n",
        "        if verbose:\n",
        "          print ('input_text',input_text)\n",
        "          verbose-=1\n",
        "        # out : hello  world  <end>  (MAX_SEQUENCE_LENGTH=2)  <-encoder_input+ decoder_output(but one-hot)\n",
        "        #\n",
        "        # in: : <s>   hello   world  <- decoder-input\n",
        "         \n",
        "        for t, word in enumerate(([style]+input_text)[:self.MAX_SEQUENCE_LENGTH]):\n",
        "            one_hot = word2index['<oov>'] if word not in word2index else word2index[word]\n",
        "            decoder_input_data[i, t ] = one_hot\n",
        "            \n",
        "        for t,word in enumerate(input_text[:self.MAX_SEQUENCE_LENGTH]):  #last must be <end>=<s> token\n",
        "            one_hot = word2index['<oov>'] if word not in word2index else word2index[word]\n",
        "            encoder_input_data[i,t]=one_hot\n",
        "            #decoder_target_data[i, t, one_hot] = 1. \n",
        "            \n",
        "        style_data[i,self.style2index[style]]= 1\n",
        "        \n",
        "      #print (decoder_target_data.sum(),len(rows)*self.MAX_SEQUENCE_LENGTH)\n",
        "      #assert int(decoder_target_data.sum())==len(rows)*self.MAX_SEQUENCE_LENGTH #one-hot-encoding must always include one\n",
        "      \n",
        "      result.append( (encoder_input_data,decoder_input_data,decoder_target_data,style_data))\n",
        "\n",
        "    self.result= TVT(*result)\n",
        "\n",
        "  def one_x_as_text(self,x):\n",
        "    \"\"\" 1x20 or 20 input\"\"\"\n",
        "    if len(x.shape)==2: \n",
        "      assert x.shape[0] ==1  #can only work on batch of 1\n",
        "      x= x[0]\n",
        "    return ' '.join([self.index2word[index] for index in x])\n",
        "\n",
        "  def one_y_as_text(self,y):\n",
        "    \"\"\" 1x20x2000 or 20x2000 input, in case of first will work on y[0]\"\"\"\n",
        "    if len(y.shape)==3: \n",
        "      assert y.shape[0] ==1  #can only work on batch of 1\n",
        "      y=y[0]\n",
        "      \n",
        "    best_token = np.argmax(y,1)\n",
        "    return ' '.join([self.index2word[index] for index in best_token])\n",
        "\n",
        "  \n",
        "cache_dir='cache' \n",
        "#dataset('quora_dups','http://qim.ec.quoracdn.net/quora_duplicate_questions.tsv',False,cache_dir) \n",
        "#dataset('bible4','https://codeload.github.com/keithecarlson/Zero-Shot-Style-Transfer/zip/master',extract=True,cache_dir=cache_dir\n",
        "#       pattern=('Zero-Shot-Style-Transfer-master/Data/Bibles/ASV/*/*.txt','Zero-Shot-Style-Transfer-master/Data/Bibles/BBE/*/*.txt')\n",
        "\n",
        "#x,y,z,t,and good, will happen , here\n",
        "row_parser= lambda file_name,line: (','.join(line.split(',')[4:]),\n",
        "                                    file_name.split('/')[-1]) #map x to x,style_file\n",
        "dataset = Dataset('bible_csv','https://codeload.github.com/ashual/style-transfer/zip/master',extract=True,cache_dir=cache_dir,\n",
        "                  \n",
        "                  pattern='style-transfer-master/datasets/bible-corpus/t_[yb]*.csv',skip_first=True,row_parser=row_parser)    #kbd\n",
        "dataset.fit()        \n",
        "x_train, x_train_d, y_train,style_train = dataset.result.train\n",
        "x_val, x_val_d,y_val ,style_val= dataset.result.val\n",
        "x_test,x_test_d,y_test ,style_test= dataset.result.test\n",
        "\n",
        "print ('train',x_train.shape,x_train_d.shape,y_train,style_train.shape)\n",
        "print('val',x_val.shape)\n",
        "print ('train in MB x,y',x_train.nbytes/1e6)\n",
        "\n",
        "\n",
        "#,t_bbe,BBE,english,Bible in Basic English,,http://en.wikipedia.org/wiki/Bible_in_Basic_English,,Public Domain,\n",
        "                  #,t_dby,DARBY,english,Darby English Bible,,http://en.wikipedia.org/wiki/Darby_Bible,,Public Domain,\n",
        "                  #,t_kjv,KJV,english,King James Version,,http://en.wikipedia.org/wiki/King_James_Version,,Public Domain,\n"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "fpath cache/datasets/bible_csv\n",
            "HARDCODED MAX LINES = 10000\n",
            "['cache/datasets/style-transfer-master/datasets/bible-corpus/t_bbe.csv', 'cache/datasets/style-transfer-master/datasets/bible-corpus/t_ylt.csv'] #lines 10000 first 3 lines\n",
            "('At the first God made the heaven and the earth.', 't_bbe.csv') \n",
            " ('And the earth was waste and without form; and it was dark on the face of the deep: and the Spirit of God was moving on the face of the waters.', 't_bbe.csv') \n",
            " ('\"And God said, Let there be light: and there was light.\"', 't_bbe.csv')\n",
            "(val_count,test_count) 8000 9000\n",
            "HARDCODED MAX LINES = 10000\n",
            "['cache/datasets/style-transfer-master/datasets/bible-corpus/t_bbe.csv', 'cache/datasets/style-transfer-master/datasets/bible-corpus/t_ylt.csv'] #lines 10000 first 3 lines\n",
            "(\"In the beginning of God's preparing the heavens and the earth --\", 't_ylt.csv') \n",
            " ('\"the earth hath existed waste and void, and darkness `is\\' on the face of the deep, and the Spirit of God fluttering on the face of the waters,\"', 't_ylt.csv') \n",
            " ('\"and God saith, `Let light be;\\' and light is.\"', 't_ylt.csv')\n",
            "(val_count,test_count) 8000 9000\n",
            "train: 16000 val 2000 test 2000\n",
            "limiting num_words in Tokenizer due to MEMORY BOUNDS\n",
            "\n",
            "REPLACE ME . BAD TOKENIZER!!!\n",
            "styles {'t_bbe.csv', 't_ylt.csv'}\n",
            "{'t_bbe.csv': 0, 't_ylt.csv': 1} {0: 't_bbe.csv', 1: 't_ylt.csv'}\n",
            "common [('the', 1), ('and', 2), ('of', 3), ('to', 4), ('in', 5), ('\"And', 6), ('a', 7), ('for', 8), ('his', 9), ('he', 10), ('is', 11), ('on', 12), ('have', 13), ('with', 14), ('your', 15)]\n",
            "uncommon [(\"ephod;'\", 19352), ('`Pursue,', 19353), ('deliver.\\'\"', 19354), ('pursueth,', 19355), ('Besor),\"', 19356), ('forsaketh', 19357), ('Cherethite,', 19358), (\"troop?'\", 19359), ('troop.\\'\"', 19360), ('feasting,', 19361), ('twilight', 19362), ('delivered.', 19363), (\"`anything',\", 19364), ('approacheth', 19365), ('<oov>', 19366)]\n",
            "CAPPING. keeping  10000 of 19366\n",
            "10000 10000 10000\n",
            "word2index 10000\n",
            "input_text ['At', 'the', 'first', 'God', 'made', 'the', 'heaven', 'and', 'the', 'earth.', '<s>', '<s>', '<s>', '<s>', '<s>', '<s>', '<s>', '<s>', '<s>', '<s>', '<s>']\n",
            "input_text ['And', 'the', 'earth', 'was', 'waste', 'and', 'without', 'form;', 'and', 'it', 'was', 'dark', 'on', 'the', 'face', 'of', 'the', 'deep:', 'and', 'the', 'Spirit', 'of', 'God', 'was', 'moving', 'on', 'the', 'face', 'of', 'the', 'waters.']\n",
            "input_text ['\"And', 'God', 'said,', 'Let', 'there', 'be', 'light:', 'and', 'there', 'was', 'light.\"', '<s>', '<s>', '<s>', '<s>', '<s>', '<s>', '<s>', '<s>', '<s>', '<s>']\n",
            "input_text ['\"And', 'God,', 'looking', 'on', 'the', 'light,', 'saw', 'that', 'it', 'was', 'good:', 'and', 'God', 'made', 'a', 'division', 'between', 'the', 'light', 'and', 'the', 'dark,\"']\n",
            "input_text ['\"Naming', 'the', 'light,', 'Day,', 'and', 'the', 'dark,', 'Night.', 'And', 'there', 'was', 'evening', 'and', 'there', 'was', 'morning,', 'the', 'first', 'day.\"', '<s>', '<s>']\n",
            "train (16000, 20) (16000, 20) None (16000, 2)\n",
            "val (2000, 20)\n",
            "train in MB x,y 1.28\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "9GT06VNk7vSN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 530
        },
        "outputId": "44972321-1acb-4600-cb05-277653765a41"
      },
      "cell_type": "code",
      "source": [
        "#!head -50 cache/datasets/style-transfer-master/datasets/bible-corpus/bible_version_key.csv\n",
        "#!ls -lh cache/datasets/style-transfer-master/datasets/bible-corpus\n",
        "\n",
        "for i in [2,3,4,998,999,1000,1001]: # good:[5000, 2002,3001]:\n",
        "  print ('\\n',i)\n",
        "  for j in ['ylt','bbe']:#['ylt','kjv','wbt','asv','web','bbe','dby']:\n",
        "    !sed -n -e {i}p cache/datasets/style-transfer-master/datasets/bible-corpus/t_{j}.csv\n",
        "\n",
        "# differences: \n",
        "# very old: ylt\n",
        "# very dynamic: bbe\n",
        "# middle ground (5 similiar wbt)"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            " 2\n",
            "1001001,1,1,1,In the beginning of God's preparing the heavens and the earth --\n",
            "1001001,1,1,1,At the first God made the heaven and the earth.\n",
            "\n",
            " 3\n",
            "1001002,1,1,2,\"the earth hath existed waste and void, and darkness `is' on the face of the deep, and the Spirit of God fluttering on the face of the waters,\"\n",
            "1001002,1,1,2,And the earth was waste and without form; and it was dark on the face of the deep: and the Spirit of God was moving on the face of the waters.\n",
            "\n",
            " 4\n",
            "1001003,1,1,3,\"and God saith, `Let light be;' and light is.\"\n",
            "1001003,1,1,3,\"And God said, Let there be light: and there was light.\"\n",
            "\n",
            " 998\n",
            "1034016,1,34,16,\"then we have given our daughters to you, and your daughters we take to ourselves, and we have dwelt with you, and have become one people;\"\n",
            "1034016,1,34,16,Then we will give our daughters to you and take your daughters to us and go on living with you as one people.\n",
            "\n",
            " 999\n",
            "1034017,1,34,17,\"and if ye hearken not unto us to be circumcised, then we have taken our daughter, and have gone.'\"\n",
            "1034017,1,34,17,\"But if you will not undergo circumcision as we say, then we will take our daughter and go.\"\n",
            "\n",
            " 1000\n",
            "1034018,1,34,18,\"And their words are good in the eyes of Hamor, and in the eyes of Shechem, Hamor's son;\"\n",
            "1034018,1,34,18,And their words were pleasing to Hamor and his son Shechem.\n",
            "\n",
            " 1001\n",
            "1034019,1,34,19,\"and the young man delayed not to do the thing, for he had delight in Jacob's daughter, and he is honourable above all the house of his father.\"\n",
            "1034019,1,34,19,\"And without loss of time the young man did as they said, because he had delight in Jacob's daughter, and he was the noblest of his father's house.\"\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "S_v9vKqIcTn6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        },
        "outputId": "b5686ecb-1f1f-4df2-b7a8-e9158f642d74"
      },
      "cell_type": "code",
      "source": [
        "#show a sample of x_train\n",
        "for i in range(1150,1152):\n",
        "  print ('\\ntokens  :' , x_train_d[i])\n",
        "  print ('as words:',[dataset.index2word[index] for index in x_train_d[i] ])\n",
        "  print ('original:',dataset.parsed.train[i][0].split(' '))\n",
        "  print (dataset.one_x_as_text(x_train_d[i]))\n",
        "  #print (dataset.one_y_as_text(y_train[i]))"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "tokens  : [9.997e+03 2.170e+02 2.130e+02 4.600e+01 1.440e+02 1.240e+02 4.000e+00\n",
            " 1.121e+03 2.000e+00 9.999e+03 1.000e+00 2.158e+03 7.000e+00 1.566e+03\n",
            " 3.000e+00 5.920e+02 9.250e+02 5.000e+00 8.390e+02 2.950e+02]\n",
            "as words: ['t_bbe.csv', '\"Now', 'Joseph', 'was', 'taken', 'down', 'to', 'Egypt;', 'and', '<oov>', 'the', 'Egyptian,', 'a', 'captain', 'of', 'high', 'position', 'in', \"Pharaoh's\", 'house,']\n",
            "original: ['\"Now', 'Joseph', 'was', 'taken', 'down', 'to', 'Egypt;', 'and', 'Potiphar', 'the', 'Egyptian,', 'a', 'captain', 'of', 'high', 'position', 'in', \"Pharaoh's\", 'house,', 'got', 'him', 'for', 'a', 'price', 'from', 'the', 'Ishmaelites', 'who', 'had', 'taken', 'him', 'there.\"']\n",
            "t_bbe.csv \"Now Joseph was taken down to Egypt; and <oov> the Egyptian, a captain of high position in Pharaoh's house,\n",
            "\n",
            "tokens  : [9.997e+03 6.000e+00 1.000e+00 3.500e+01 4.600e+01 1.400e+01 4.580e+02\n",
            " 2.000e+00 1.000e+01 1.680e+02 5.038e+03 2.000e+00 1.000e+01 4.600e+01\n",
            " 1.570e+02 5.000e+00 1.000e+00 1.390e+02 3.000e+00 9.000e+00]\n",
            "as words: ['t_bbe.csv', '\"And', 'the', 'Lord', 'was', 'with', 'Joseph,', 'and', 'he', 'did', 'well;', 'and', 'he', 'was', 'living', 'in', 'the', 'house', 'of', 'his']\n",
            "original: ['\"And', 'the', 'Lord', 'was', 'with', 'Joseph,', 'and', 'he', 'did', 'well;', 'and', 'he', 'was', 'living', 'in', 'the', 'house', 'of', 'his', 'master', 'the', 'Egyptian.\"']\n",
            "t_bbe.csv \"And the Lord was with Joseph, and he did well; and he was living in the house of his\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "BWVEcaeF6DBR",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Model defintion\n",
        "\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "1uUNdIO5pPfE",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## G"
      ]
    },
    {
      "metadata": {
        "id": "kqkLdFGl0FMB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 545
        },
        "outputId": "1e26ac9a-ad3f-483f-e456-eca04d625dfe"
      },
      "cell_type": "code",
      "source": [
        "from keras.models import Model\n",
        "from keras.layers import Input, LSTM, Dense, Embedding,CuDNNLSTM,Bidirectional,Concatenate,Dropout\n",
        "\n",
        "# size of tokenizer indexes\n",
        "\n",
        "num_decoder_tokens = num_encoder_tokens = len(dataset.word2index) \n",
        "print (num_decoder_tokens)\n",
        "\n",
        "\n",
        "\n",
        "# Define an input sequence and process it.  \n",
        "# input: batch,num-of-words of integers (not-one-hot)\n",
        "# each batch should be of the size and padded, but between batches size can be different\n",
        "# batch 1:   len 7,8,9,10(max)  inside the same batch, size is similiar (less waste on GPU)\n",
        "# batch 2 :    len 97-100(max)  between batches size is different.\n",
        "# order is random... sometime small batch sometime large \n",
        "\n",
        "encoder_inputs = Input(shape=(None,),name='encoder_inputs')\n",
        "\n",
        "shared_embedding = Embedding(num_encoder_tokens, \n",
        "                     embedding_dim, \n",
        "                     #weights=[word_embedding_matrix], if there is one (word2vec)\n",
        "                     #trainable=False,                            \n",
        "                     #input_length=MAX_SEQUENCE_LENGTH, if there is one\n",
        "                     )\n",
        "#see dropout disucssion: https://github.com/keras-team/keras/issues/7290. iliaschalkidis \n",
        "#Dropout(noise_shape=(batch_size, 1, features))\n",
        "x = shared_embedding(encoder_inputs) \n",
        "if (cuddlstm):\n",
        "  encoder_lstm=CuDNNLSTM(latent_dim, return_state=True)\n",
        "else:\n",
        "  print ('using LSTM with dropout!')\n",
        "  #need to tune the dropout values (maybe fast.ai tips) , just invented those value\n",
        "  encoder_lstm=LSTM(latent_dim, return_state=True,dropout=0.3,recurrent_dropout=0.3)\n",
        "if (bidi_encoder):\n",
        "  encoder_lstm=Bidirectional(encoder_lstm,merge_mode='concat')\n",
        "  x, forward_h, forward_c, backward_h, backward_c = encoder_lstm(x) #output,h1,c1,h2,c2\n",
        "  state_h = Concatenate()([forward_h, backward_h])\n",
        "  state_c = Concatenate()([forward_c, backward_c])\n",
        "else:  \n",
        "  x, state_h, state_c = encoder_lstm(x)\n",
        "\n",
        "  \n",
        "  \n",
        "#sentence embedding LSTM: h,c  \n",
        "encoder_states = [state_h, state_c]\n",
        "\n",
        "# Set up the decoder, using `encoder_states` as initial state.\n",
        "#looks similiar to  \n",
        "#gold decoder_ouputs: [1,0,0] [0,1,0] one-hot of the below\n",
        "#encoder_inputs:      hello   world <end> <end>\n",
        "#decoder_input      : <style> hello world <end>   | style = bible1,bible2,(maybe-generic for pertraining)\n",
        " \n",
        "decoder_inputs = Input(shape=(None,),name='decoder_inputs')  \n",
        "\n",
        "decoder_latent_dim = latent_dim*2 if bidi_encoder else latent_dim #bi-di pass merge of h1+h2, c1+c2\n",
        "if (cuddlstm):\n",
        "  decoder_lstm = CuDNNLSTM(decoder_latent_dim, return_sequences=True,return_state=True) #returned state used in inference\n",
        "else:\n",
        "  decoder_lstm = LSTM(decoder_latent_dim, return_sequences=True,return_state=True)\n",
        "decoder_outputs, _, _  = decoder_lstm(shared_embedding(decoder_inputs), initial_state=encoder_states)\n",
        "decoder_dense  = Dense(num_decoder_tokens, activation='softmax',name='decoder_softmax')\n",
        "decoder_outputs = decoder_dense(decoder_outputs)\n",
        "\n",
        "# Define the model that will turn\n",
        "# `encoder_input_data` & `decoder_input_data` into `decoder_target_data`\n",
        "model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
        "\n",
        "# Compile & run training\n",
        "print (model.summary())\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# now for the INFER models (re-arrangement of the prev one)\n",
        "# Remember that the training model varaibles were:\n",
        "#                                        decoder_outputs\n",
        "#encoder   --->    encoder_states  -->   decoder_lstm  \n",
        "#shared_embedding                        shared_embeddings  \n",
        "#encoder_inputs                          decdoer_inputs                  \n",
        "encoder_model = Model(encoder_inputs, encoder_states)\n",
        "\n",
        "decoder_states_inputs = [Input(shape=(decoder_latent_dim,)), Input(shape=(decoder_latent_dim,))]\n",
        "\n",
        "decoder_outputs2, state_h, state_c = decoder_lstm(shared_embedding(decoder_inputs), initial_state=decoder_states_inputs)\n",
        "\n",
        "decoder_states = [state_h, state_c]\n",
        "decoder_outputs2 = decoder_dense(decoder_outputs2)\n",
        "\n",
        "decoder_model = Model(\n",
        "    [decoder_inputs] + decoder_states_inputs,\n",
        "    [decoder_outputs2] + decoder_states)\n",
        "\n",
        "\n",
        "\n",
        "    \n"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "10000\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "decoder_inputs (InputLayer)     (None, None)         0                                            \n",
            "__________________________________________________________________________________________________\n",
            "encoder_inputs (InputLayer)     (None, None)         0                                            \n",
            "__________________________________________________________________________________________________\n",
            "embedding_3 (Embedding)         (None, None, 300)    3000000     encoder_inputs[0][0]             \n",
            "                                                                 decoder_inputs[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bidirectional_3 (Bidirectional) [(None, 512), (None, 1142784     embedding_3[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_5 (Concatenate)     (None, 512)          0           bidirectional_3[0][1]            \n",
            "                                                                 bidirectional_3[0][3]            \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_6 (Concatenate)     (None, 512)          0           bidirectional_3[0][2]            \n",
            "                                                                 bidirectional_3[0][4]            \n",
            "__________________________________________________________________________________________________\n",
            "cu_dnnlstm_6 (CuDNNLSTM)        [(None, None, 512),  1667072     embedding_3[1][0]                \n",
            "                                                                 concatenate_5[0][0]              \n",
            "                                                                 concatenate_6[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "decoder_softmax (Dense)         (None, None, 10000)  5130000     cu_dnnlstm_6[0][0]               \n",
            "==================================================================================================\n",
            "Total params: 10,939,856\n",
            "Trainable params: 10,939,856\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "S983Fs2WYshb",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "VTobPYftYvQC",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "##  classifier\n",
        "\n",
        "**Intro**\n",
        "\n",
        "(1) We start with regukar seq2seq is encoder->embedding->decoder and trained with reconstruction-loss\n",
        "\n",
        "(2)We can build style-discriminator where the target is to classify author-style from the sentence-embedding.\n",
        "When training it you need to freeze the encoder and decoder parts of the model, then:\n",
        "input1: sentence --freezed encoder--> embedding    (no need to run decoder)\n",
        "input2: style (one-hot)\n",
        "output: style (one-hot)  \n",
        "The discriminator can be a simple classifier (dense-based) with simple minimize cross-entropy target.\n",
        "\n",
        "(3) The smart-part: We want to train the encoder to create an embedding which will fool the discriminator.\n",
        "We will freeze the discriminator weights, and train the encoder-decoder similiarly to (1) with extra objective.\n",
        "That the loss from the discriminator will be Maximized. \n"
      ]
    },
    {
      "metadata": {
        "id": "2BIl7v9DnM5j",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 562
        },
        "outputId": "426856ee-1595-4d84-ca1c-74a1e0ea9bce"
      },
      "cell_type": "code",
      "source": [
        "\n",
        "#### Classifier model #############################\n",
        "# works on the embedding itself\n",
        "style_concat= Concatenate(name='d__concat1')(encoder_states)\n",
        "\n",
        "a = Dropout(0.1,name='d__dropout1')(style_concat)                          \n",
        "# if your inputs have shape  (batch_size, timesteps, features) and you want the dropout mask to be the same for all timesteps, you can use noise_shape=(batch_size, 1, features).\n",
        "a = Dense(100,activation='relu',name='d__dense1')(a) \n",
        "#a = keras.layers.LeakyReLU()(a) #LeakyReLU  #why leaky? see: how to train your GAN - BUT IT FAILED TO LEARN (accuracy always 0.5)\n",
        "a = Dropout(0.1,name='d__dropout2')(a)\n",
        "style_outputs = Dense(len(dataset.style2index),activation='softmax',name='d__dense_softmax')(a)\n",
        "\n",
        "d = Model(encoder_inputs,style_outputs)  #style_outputs : batch , one-hot-encoding-of-style\n",
        "print (d.summary())\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "encoder_inputs (InputLayer)     (None, None)         0                                            \n",
            "__________________________________________________________________________________________________\n",
            "embedding_3 (Embedding)         (None, None, 300)    3000000     encoder_inputs[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bidirectional_3 (Bidirectional) [(None, 512), (None, 1142784     embedding_3[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_5 (Concatenate)     (None, 512)          0           bidirectional_3[0][1]            \n",
            "                                                                 bidirectional_3[0][3]            \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_6 (Concatenate)     (None, 512)          0           bidirectional_3[0][2]            \n",
            "                                                                 bidirectional_3[0][4]            \n",
            "__________________________________________________________________________________________________\n",
            "d__concat1 (Concatenate)        (None, 1024)         0           concatenate_5[0][0]              \n",
            "                                                                 concatenate_6[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "d__dropout1 (Dropout)           (None, 1024)         0           d__concat1[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "d__dense1 (Dense)               (None, 100)          102500      d__dropout1[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "d__dropout2 (Dropout)           (None, 100)          0           d__dense1[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "d__dense_softmax (Dense)        (None, 2)            202         d__dropout2[0][0]                \n",
            "==================================================================================================\n",
            "Total params: 4,245,486\n",
            "Trainable params: 4,245,486\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "9TBO_5dXv40K",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## adverserial model"
      ]
    },
    {
      "metadata": {
        "id": "owHJkiERHsG1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 721
        },
        "outputId": "ecdbaf74-d174-44bc-8ca3-90dd3c02ac58"
      },
      "cell_type": "code",
      "source": [
        "from keras import backend as K\n",
        "############################# Adv model\n",
        "# Note that it does not have new layers, just combining all of them with new loss\n",
        "def inverse_categorical_crossentropy(y_true, y_pred):\n",
        "  #need to implement it better , sum(1/categorical_crossentropy_per_sample)\n",
        "  # if discriminator is random, on 2 styles, if expect 50% which should mean logloss of 1. so 1/1= 1\n",
        "  # if discriminator is great, 99%, log-loss close to 0 , so 1/0 is big.\n",
        "  # so expeceted range is GREAT=1 , BAD=BIGGG\n",
        "  \n",
        "  return 1/(K.categorical_crossentropy(y_true, y_pred)+0.0001)\n",
        "#style_outputs\n",
        "adv_model = Model([encoder_inputs, decoder_inputs],[decoder_outputs,style_outputs])\n",
        "\n",
        "print (adv_model.summary())\n"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "decoder_inputs (InputLayer)     (None, None)         0                                            \n",
            "__________________________________________________________________________________________________\n",
            "encoder_inputs (InputLayer)     (None, None)         0                                            \n",
            "__________________________________________________________________________________________________\n",
            "embedding_3 (Embedding)         (None, None, 300)    3000000     encoder_inputs[0][0]             \n",
            "                                                                 decoder_inputs[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bidirectional_3 (Bidirectional) [(None, 512), (None, 1142784     embedding_3[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_5 (Concatenate)     (None, 512)          0           bidirectional_3[0][1]            \n",
            "                                                                 bidirectional_3[0][3]            \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_6 (Concatenate)     (None, 512)          0           bidirectional_3[0][2]            \n",
            "                                                                 bidirectional_3[0][4]            \n",
            "__________________________________________________________________________________________________\n",
            "d__concat1 (Concatenate)        (None, 1024)         0           concatenate_5[0][0]              \n",
            "                                                                 concatenate_6[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "d__dropout1 (Dropout)           (None, 1024)         0           d__concat1[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "d__dense1 (Dense)               (None, 100)          102500      d__dropout1[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "cu_dnnlstm_6 (CuDNNLSTM)        [(None, None, 512),  1667072     embedding_3[1][0]                \n",
            "                                                                 concatenate_5[0][0]              \n",
            "                                                                 concatenate_6[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "d__dropout2 (Dropout)           (None, 100)          0           d__dense1[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "decoder_softmax (Dense)         (None, None, 10000)  5130000     cu_dnnlstm_6[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "d__dense_softmax (Dense)        (None, 2)            202         d__dropout2[0][0]                \n",
            "==================================================================================================\n",
            "Total params: 11,042,558\n",
            "Trainable params: 11,042,558\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "9fOJf8SLX_Xd",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# compile"
      ]
    },
    {
      "metadata": {
        "id": "YjI-3lfJv62T",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 668
        },
        "outputId": "572e7abc-bc27-4c09-9c39-4c32b15b650c"
      },
      "cell_type": "code",
      "source": [
        "# compile it all\n",
        "def print_trainable(model):\n",
        "  for layer in model.layers:\n",
        "    print (layer.name,layer,layer.trainable)\n",
        "    \n",
        "\n",
        "def set_trainable(model,trainable) :\n",
        "  \"\"\" set all layers of the model (ignores Input) to trainable True/False\"\"\"\n",
        "  for layer in model.layers:\n",
        "    if type(layer)==keras.engine.topology.InputLayer:\n",
        "      pass\n",
        "    else:\n",
        "      layer.trainable = trainable \n",
        "\n",
        "#optimizer = ''#clipvalue=0.5,clipnorm=1.0) #TODO: values!!!!!    \n",
        "######################################3\n",
        "#compile all, set trainable parts (as keras hold it before compilation)\n",
        "set_trainable(model,True)\n",
        "model.trainable = True\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy')  #30peocs loss: 0.2836 - val_loss: 0.4428\n",
        "print ('\\nmodel compiled with:')\n",
        "print_trainable(model)\n",
        "\n",
        "\n",
        "# when training d, the encoder should not change.\n",
        "# impl. detail: instead of choose layers one by one, we first set all d True then override part with False\n",
        "set_trainable(d,True)    \n",
        "set_trainable(model,False) #setting it back(it's parts of d)\n",
        "d.trainable = True\n",
        "d.compile(optimizer='adam', loss='categorical_crossentropy',metrics=['accuracy'])\n",
        "print ('\\nd compiled with:')\n",
        "print_trainable(d)\n",
        "\n",
        "# when training adv_model, the decoder should not change\n",
        "set_trainable(adv_model,False)\n",
        "set_trainable(model,True)  #so d is still false\n",
        "adv_model.trainable = True\n",
        "adv_model.compile(optimizer='adam', \n",
        "                  loss=['categorical_crossentropy',inverse_categorical_crossentropy],\n",
        "                  loss_weights=[1, 1])\n",
        "print ('\\nadv compiled with:')\n",
        "print_trainable(adv_model)\n"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "model compiled with:\n",
            "decoder_inputs <keras.engine.topology.InputLayer object at 0x7fb019293978> False\n",
            "encoder_inputs <keras.engine.topology.InputLayer object at 0x7faf530894e0> False\n",
            "embedding_3 <keras.layers.embeddings.Embedding object at 0x7fb0192937f0> True\n",
            "bidirectional_3 <keras.layers.wrappers.Bidirectional object at 0x7fb018bc75f8> True\n",
            "concatenate_5 <keras.layers.merge.Concatenate object at 0x7fb018bc7d68> True\n",
            "concatenate_6 <keras.layers.merge.Concatenate object at 0x7fb018bc7e48> True\n",
            "cu_dnnlstm_6 <keras.layers.cudnn_recurrent.CuDNNLSTM object at 0x7fb018bc7dd8> True\n",
            "decoder_softmax <keras.layers.core.Dense object at 0x7faf53fca940> True\n",
            "\n",
            "d compiled with:\n",
            "encoder_inputs <keras.engine.topology.InputLayer object at 0x7faf530894e0> False\n",
            "embedding_3 <keras.layers.embeddings.Embedding object at 0x7fb0192937f0> False\n",
            "bidirectional_3 <keras.layers.wrappers.Bidirectional object at 0x7fb018bc75f8> False\n",
            "concatenate_5 <keras.layers.merge.Concatenate object at 0x7fb018bc7d68> False\n",
            "concatenate_6 <keras.layers.merge.Concatenate object at 0x7fb018bc7e48> False\n",
            "d__concat1 <keras.layers.merge.Concatenate object at 0x7faf52f83a90> True\n",
            "d__dropout1 <keras.layers.core.Dropout object at 0x7faf52f83b00> True\n",
            "d__dense1 <keras.layers.core.Dense object at 0x7faf52f83ac8> True\n",
            "d__dropout2 <keras.layers.core.Dropout object at 0x7faf52f83f98> True\n",
            "d__dense_softmax <keras.layers.core.Dense object at 0x7faf52f83dd8> True\n",
            "\n",
            "adv compiled with:\n",
            "decoder_inputs <keras.engine.topology.InputLayer object at 0x7fb019293978> False\n",
            "encoder_inputs <keras.engine.topology.InputLayer object at 0x7faf530894e0> False\n",
            "embedding_3 <keras.layers.embeddings.Embedding object at 0x7fb0192937f0> True\n",
            "bidirectional_3 <keras.layers.wrappers.Bidirectional object at 0x7fb018bc75f8> True\n",
            "concatenate_5 <keras.layers.merge.Concatenate object at 0x7fb018bc7d68> True\n",
            "concatenate_6 <keras.layers.merge.Concatenate object at 0x7fb018bc7e48> True\n",
            "d__concat1 <keras.layers.merge.Concatenate object at 0x7faf52f83a90> False\n",
            "d__dropout1 <keras.layers.core.Dropout object at 0x7faf52f83b00> False\n",
            "d__dense1 <keras.layers.core.Dense object at 0x7faf52f83ac8> False\n",
            "cu_dnnlstm_6 <keras.layers.cudnn_recurrent.CuDNNLSTM object at 0x7fb018bc7dd8> True\n",
            "d__dropout2 <keras.layers.core.Dropout object at 0x7faf52f83f98> False\n",
            "decoder_softmax <keras.layers.core.Dense object at 0x7faf53fca940> True\n",
            "d__dense_softmax <keras.layers.core.Dense object at 0x7faf52f83dd8> False\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "xh5FwdLGU2n3",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Sample and show sample"
      ]
    },
    {
      "metadata": {
        "id": "_ZC94QpK1bcw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "6aaa8ff3-a0fa-4961-8d97-f5650dc94e8b"
      },
      "cell_type": "code",
      "source": [
        "max_decoder_seq_length=dataset.MAX_SEQUENCE_LENGTH\n",
        "print (max_decoder_seq_length)\n",
        "# TODO: now it's greedy and use argmax\n",
        "# maybe to choose randomly by distribution\n",
        "# and maybe to implement BEAM SEARCH\n",
        "def decode_sequence(input_seq,style,verbose=False):\n",
        "    assert input_seq.shape == (1, max_decoder_seq_length )\n",
        "    if verbose: print ('input_seq',input_seq.shape)\n",
        "    # Encode the input as state vectors.\n",
        "    states_value = encoder_model.predict(input_seq)\n",
        "    if verbose: print ('encoder result states_value','h',states_value[0].shape,states_value[0].mean(),'c',states_value[1].shape,states_value[1].mean())\n",
        "    \n",
        "    # Generate empty target sequence of length 1.\n",
        "    #                      batch,word-number value is token (0 /122)\n",
        "    target_seq = np.zeros((1, 1))\n",
        "    # Populate the first character of target sequence with the start character.\n",
        "    target_seq[0, 0] = dataset.word2index[style]\n",
        "\n",
        "    # Sampling loop for a batch of sequences\n",
        "    # (to simplify, here we assume a batch of size 1).\n",
        "    stop_condition = False\n",
        "    decoded_sentence = []\n",
        "    while not stop_condition:\n",
        "        #start with encoder-state then change to self state\n",
        "        output_tokens, h, c = decoder_model.predict( [target_seq] + states_value) \n",
        "        if verbose: print ('output_tokens',output_tokens.shape,output_tokens.mean(),'h',h.shape,'c',c.shape)\n",
        "\n",
        "        # Sample a token\n",
        "        sampled_token_index = np.argmax(output_tokens)# [0, -1, :])\n",
        "        if verbose: print ('sampled_token_index',sampled_token_index.shape,output_tokens.max(),sampled_token_index)\n",
        "        decoded_sentence.append(sampled_token_index)\n",
        "\n",
        "        # Exit condition: either hit max length\n",
        "        # or find stop character.\n",
        "        if (sampled_token_index == dataset.word2index['<s>'] or\n",
        "           len(decoded_sentence) > max_decoder_seq_length):\n",
        "          stop_condition = True\n",
        "\n",
        "        # Update the target sequence (of length 1).\n",
        "        target_seq = np.zeros((1, 1))\n",
        "        target_seq[0, 0] = sampled_token_index\n",
        "\n",
        "        # Update states\n",
        "        states_value = [h, c]\n",
        "\n",
        "    res= np.array(decoded_sentence) #[dataset.index2word[index] for index in decoded_sentence]\n",
        "    return res\n",
        "\n",
        "  \n",
        "\n",
        "def show_sample(data_type='val',teacher_forcing=False,sample_id=[],replace_style=['t_bbe.csv','t_ylt.csv'],show_other_style=True):\n",
        "  \"\"\" \n",
        "    data_type - train/val/test\n",
        "    teacher_forcing : default False, sample argmax as for normal test. If true, feed decode-input from the dataset itself\n",
        "    sample_id : verse-id to sample (list)\n",
        "    replace_style: if true, will pass a different style\n",
        "  \"\"\"\n",
        "  for i in sample_id:\n",
        "    print ('#'*30,'verb',i,'#'*30)\n",
        "    data={'train': dataset.result.train,'val':dataset.result.val , 'test':dataset.result.test}\n",
        "\n",
        "    # extract the i`th row data\n",
        "    one_x= data[data_type][0][i:i+1]\n",
        "    if one_x.shape[0]==0:\n",
        "      print ('sample out of range',data[data_type][0].shape)\n",
        "    one_x_d= data[data_type][1][i:i+1]\n",
        "    style_as_text = dataset.index2word[one_x_d[0,0]]\n",
        "\n",
        "\n",
        "    print (f'encoder_input  [{style_as_text}]:',dataset.one_x_as_text(one_x))\n",
        "    if (show_other_style):\n",
        "      #temp , currently +8000/+2000 as half the size of data TODO: in other case different way\n",
        "      other_i=i + int(len(data[data_type][0])/2)\n",
        "      other_x= data[data_type][0][other_i]\n",
        "      other_style=  dataset.index2word[data[data_type][1][other_i][0]]\n",
        "      print (f'encoder_input  [{other_style}]:',dataset.one_x_as_text(other_x))\n",
        "\n",
        "    for replace_style in ['t_bbe.csv','t_ylt.csv']:\n",
        "      # always replace_style:\n",
        "      one_x_d= np.copy(one_x_d)\n",
        "      one_x_d[0,0]=dataset.word2index[replace_style]\n",
        "\n",
        "      if teacher_forcing:\n",
        "        p = model.predict([one_x,one_x_d])\n",
        "        print (f'decoder TF     [{replace_style}]:',dataset.one_y_as_text(p))\n",
        "      else:\n",
        "        p = decode_sequence(one_x,style_as_text)\n",
        "        print (f'decoder sample [{replace_style}]:',dataset.one_x_as_text(p))\n",
        "          \n",
        "          \n",
        "# please see more in error-anlysis section\n",
        "#show_sample('train',sample_id=[0,1,2],teacher_forcing=True) \n",
        "#show_sample('val',sample_id=[0,1,2],teacher_forcing=True) \n",
        "\n",
        "    "
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "20\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "9s0-8EJi6AG1",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# TRAINING"
      ]
    },
    {
      "metadata": {
        "id": "0_0G8_Dr2bMM",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import keras\n",
        "from keras.callbacks import ReduceLROnPlateau\n",
        "class LossHistory(keras.callbacks.Callback):\n",
        "    def __init__(self):\n",
        "      self.losses = {'loss':[],'val_loss':[]}\n",
        "      \n",
        "    #def on_train_begin(self, logs={}):\n",
        "    #  pass  \n",
        "    \n",
        "    def on_epoch_end(self, batch, logs={}):\n",
        "      for loss in ['loss','val_loss']:\n",
        "        self.losses[loss].append(logs.get(loss))\n",
        "        \n",
        "np.random.seed(42)\n",
        "\n",
        "\n",
        "def gen(t,batch_size,gen_type):\n",
        "    \"\"\"grn_type = g/d/adv\"\"\"\n",
        "    x_encoder,x_decoder,y_one_hot_decoder,y_style = t\n",
        "    WORDS=x_encoder.shape[1]\n",
        "    while 1:\n",
        "      ind=np.array(np.random.randint(len(x_encoder),size=(batch_size) ))\n",
        "      \n",
        "      #build decoder target data on the fly\n",
        "      one_hot = np.zeros((batch_size,WORDS,len(dataset.index2word)))\n",
        "      for row in range(batch_size):\n",
        "         for t in range(WORDS):\n",
        "            one_hot[row,t,int(x_encoder[ind][row,t])] = 1\n",
        "      \n",
        "      if gen_type=='g':\n",
        "        yield ([x_encoder[ind],x_decoder[ind]],one_hot)\n",
        "      elif gen_type=='d':\n",
        "        yield (x_encoder[ind],y_style[ind])\n",
        "      elif gen_type=='adv':\n",
        "        yield ([x_encoder[ind],x_decoder[ind]],[one_hot,y_style[ind]]) #y_one_hot_decoder[ind]\n",
        "      else:\n",
        "        raise ValueError('gen_type unkown',gen_type)\n",
        "\n",
        "\n",
        "\n",
        "import matplotlib.pyplot as plt \n",
        "\n",
        "# summarize history for loss\n",
        "def plt_losses(loss_history,title,with_val=False):\n",
        "  plt.plot(loss_history.losses['loss'][:])\n",
        "  if with_val:\n",
        "    plt.plot(loss_history.losses['val_loss'][:])\n",
        "  plt.title(title)\n",
        "  med=0.1 if len(loss_history.losses['loss'])<1 else np.median(loss_history.losses['loss'])\n",
        "  plt.ylim(ymax=med+1.5)\n",
        "  plt.ylabel('loss')\n",
        "  plt.xlabel('epoch')\n",
        "  plt.legend(['train', 'val'], loc='upper right')\n",
        "  \n",
        "\n",
        "def plt_all():  \n",
        "  plt.figure(figsize=(14,4))\n",
        "  plt.subplot(131) #numrows, numcols, fignum\n",
        "  plt_losses(loss_history,'g loss')  \n",
        "  plt.subplot(132)\n",
        "  plt_losses(loss_history_d,'d loss')  \n",
        "  plt.subplot(133)\n",
        "  plt_losses(loss_history_adv,'adv loss') \n",
        "  plt.show()\n",
        "\n",
        "\n",
        "  \n",
        "loss_history = LossHistory()\n",
        "loss_history_d = LossHistory()\n",
        "loss_history_adv = LossHistory()  \n",
        "\n",
        "\n",
        "def train_g(steps,validation_steps=1):\n",
        "    #set_trainable(model,True)  \n",
        "    \n",
        "    model.fit_generator(gen(dataset.result.train,batch_size,'g'),\n",
        "                        steps,\n",
        "                        validation_steps=validation_steps,\n",
        "                        validation_data=gen(dataset.result.val,batch_size,'g'),\n",
        "                        callbacks=[loss_history],\n",
        "                        verbose=0 if steps<50 else 1,\n",
        "                        #max_queue_size=10,\n",
        "                        #workers=2\n",
        "                       )\n",
        "    #model.fit([x_train, x_train_d], y_train,\n",
        "\n",
        "    \n",
        "def train_d(steps,validation_steps=1):\n",
        "  #set_trainable(d,True)  #only for warning\n",
        "  #set_trainable(model,False)  \n",
        "  #d.trainable=True\n",
        "  d.fit_generator(gen(dataset.result.train,batch_size,'d'),\n",
        "                        steps,\n",
        "                        validation_steps=validation_steps,\n",
        "                        validation_data=gen(dataset.result.val,batch_size,'d'),\n",
        "                        verbose=0 if steps<50 else 1,\n",
        "                        callbacks=[loss_history_d])\n",
        "\n",
        "  # d.fit(x_train, style_train,\n",
        "\n",
        "  \n",
        "def train_adv(steps,validation_steps=1):\n",
        "  #adv_model.fit([x_train, x_train_d], [y_train,style_train],\n",
        "  #set_trainable(d,False) \n",
        "  #set_trainable(model,True)  \n",
        "  adv_model.fit_generator(gen(dataset.result.train,batch_size,'adv'),\n",
        "                        steps,\n",
        "                        validation_steps=validation_steps,\n",
        "                        validation_data=gen(dataset.result.val,batch_size,'adv'),\n",
        "                        verbose=0 if steps<50 else 1,\n",
        "                        callbacks=[loss_history_adv])\n",
        "  \n",
        " \n",
        "  \n",
        "#gener=gen(dataset.result.train,10,'d')\n",
        "#x1,y=next(gener)\n",
        "#print ('test gen batch 2',x1.shape,y.shape,y)\n",
        "\n",
        "#plt_all()     \n",
        "#print_trainable(d)\n",
        "#train_d(500,10)\n",
        "#train_g(50,10)  # THIS KILLS train_d after it\n",
        "#train_adv(50,10)  # THIS KILLS train_d after it\n",
        "#train_d(500,10)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "hUJbmXe5GW2t",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        },
        "outputId": "4615807b-6523-4d12-cc35-5937d7e389d7"
      },
      "cell_type": "code",
      "source": [
        "steps=50\n",
        "validation_steps=1\n",
        "d.fit_generator(gen(dataset.result.train,batch_size,'d'),\n",
        "                        steps,\n",
        "                        validation_steps=validation_steps,\n",
        "                        validation_data=gen(dataset.result.val,batch_size,'d'),\n",
        "                        callbacks=[loss_history],\n",
        "                        verbose=0 if steps<50 else 1,\n",
        "                       )\n",
        "\n",
        "model.fit_generator(gen(dataset.result.train,batch_size,'g'),\n",
        "                        steps,\n",
        "                        validation_steps=validation_steps,\n",
        "                        validation_data=gen(dataset.result.val,batch_size,'g'),\n",
        "                        callbacks=[loss_history],\n",
        "                        verbose=0 if steps<50 else 1,\n",
        "                       )\n",
        "d.fit_generator(gen(dataset.result.train,batch_size,'d'),\n",
        "                        steps,\n",
        "                        validation_steps=500,\n",
        "                        validation_data=gen(dataset.result.val,batch_size,'d'),\n",
        "                        callbacks=[loss_history],\n",
        "                        verbose=0 if steps<50 else 1,\n",
        "                       )\n",
        "\n",
        "\n",
        "\n",
        "#set_trainable(model,False)  \n",
        "#d.trainable=True\n",
        "#print_trainable(d)\n",
        "#train_d(50,10)\n",
        "#train_g(1,10)\n",
        "#train_d(50,10)\n"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/1\n",
            " 5/50 [==>...........................] - ETA: 1s - loss: 0.6930 - acc: 0.5281"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/keras/engine/training.py:975: UserWarning: Discrepancy between trainable weights and collected trainable weights, did you set `model.trainable` without calling `model.compile` after ?\n",
            "  'Discrepancy between trainable weights and collected trainable'\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "50/50 [==============================] - 2s 33ms/step - loss: 0.6932 - acc: 0.5009 - val_loss: 0.6934 - val_acc: 0.4062\n",
            "Epoch 1/1\n",
            "50/50 [==============================] - 7s 142ms/step - loss: 5.5131 - val_loss: 5.2851\n",
            "Epoch 1/1\n",
            "50/50 [==============================] - 14s 273ms/step - loss: 0.6932 - acc: 0.4997 - val_loss: 0.6931 - val_acc: 0.5023\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7faf51e3aac8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 52
        }
      ]
    },
    {
      "metadata": {
        "id": "Sm05AY862pem",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1278
        },
        "outputId": "bdf072a0-164e-440a-f1ec-875c4d3185dd"
      },
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "          \n",
        "\n",
        "\n",
        "\n",
        "epoc = int(len(dataset.result.train[0])/batch_size)\n",
        "\n",
        "# start with a good pretraining for few epocs\n",
        "\n",
        "\n",
        "for i in range(20):\n",
        "  train_g(epoc*1,validation_steps=100)  #pretrain\n",
        "  l=loss_history.losses['loss'][-1:][0]\n",
        "  if l<1.0:\n",
        "    print ('early break at break at',l,'epoc',i)\n",
        "    break\n",
        "show_sample('train',sample_id=[0,1,2],teacher_forcing=True)   #,8000+0\n",
        "\n",
        "for i in range(20):\n",
        "  train_d(epoc,validation_steps=100)\n",
        "  l=loss_history_d.losses['loss'][-1:][0]\n",
        "  if l<2:\n",
        "    print ('early break at break at',l,'epoc',i)\n",
        "\n",
        "\n",
        "small_steps=5\n",
        "for e in range(10):\n",
        "  print ('epocs',e)\n",
        "  for i in range(int(epoc/small_steps)):\n",
        "    print ('expect to wait a minute here...')\n",
        "    train_d(small_steps)\n",
        "    train_adv(small_steps)\n",
        "  show_sample('train',sample_ids=[0],teacher_forcing=True)   #,8000+0\n",
        "  plt_all()\n",
        "  \n",
        "print ('done')\n",
        "\n",
        "\n",
        "# Expect to see nice results on G with 10 words , when loss is <2. If not continue training a bit"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/1\n",
            "  6/250 [..............................] - ETA: 2:22 - loss: 9.1770"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-39-d0ac37b909ad>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m   \u001b[0mtrain_g\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoc\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m#pretrain\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m   \u001b[0ml\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mloss_history\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlosses\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'loss'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m<\u001b[0m\u001b[0;36m1.0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-38-e1fd0d1bdb15>\u001b[0m in \u001b[0;36mtrain_g\u001b[0;34m(steps, validation_steps)\u001b[0m\n\u001b[1;32m     79\u001b[0m                         \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mval\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'g'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m                         \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mloss_history\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 81\u001b[0;31m                         \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0msteps\u001b[0m\u001b[0;34m<\u001b[0m\u001b[0;36m50\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     82\u001b[0m                         \u001b[0;31m#max_queue_size=10,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m                         \u001b[0;31m#workers=2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/legacy/interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name +\n\u001b[1;32m     90\u001b[0m                               '` call to the Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 91\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   2228\u001b[0m                     outs = self.train_on_batch(x, y,\n\u001b[1;32m   2229\u001b[0m                                                \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2230\u001b[0;31m                                                class_weight=class_weight)\n\u001b[0m\u001b[1;32m   2231\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2232\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(self, x, y, sample_weight, class_weight)\u001b[0m\n\u001b[1;32m   1881\u001b[0m             \u001b[0mins\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1882\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1883\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1884\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1885\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2480\u001b[0m         \u001b[0msession\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2481\u001b[0m         updated = session.run(fetches=fetches, feed_dict=feed_dict,\n\u001b[0;32m-> 2482\u001b[0;31m                               **self.session_kwargs)\n\u001b[0m\u001b[1;32m   2483\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2484\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    898\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    899\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 900\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    901\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    902\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1102\u001b[0m             \u001b[0mfeed_handles\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msubfeed_t\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msubfeed_val\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1103\u001b[0m           \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1104\u001b[0;31m             \u001b[0mnp_val\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msubfeed_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msubfeed_dtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1105\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1106\u001b[0m           if (not is_tensor_handle_feed and\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/numpy/core/numeric.py\u001b[0m in \u001b[0;36masarray\u001b[0;34m(a, dtype, order)\u001b[0m\n\u001b[1;32m    490\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    491\u001b[0m     \"\"\"\n\u001b[0;32m--> 492\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    493\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    494\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "lkRifQNB2sMa",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        },
        "outputId": "28bc4d10-c9c7-4ec4-95b8-c6e703f8a912"
      },
      "cell_type": "code",
      "source": [
        "train_d(epoc,validation_steps=100) # IF ran after train_g NOT WORKING\n",
        "train_g(5,validation_steps=5)\n",
        "train_d(epoc,validation_steps=100) # IF ran after train_g NOT WORKING"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-11-3f112fa19be5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain_d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# IF ran after train_g NOT WORKING\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mtrain_g\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mtrain_d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# IF ran after train_g NOT WORKING\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'epoc' is not defined"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "XvIkFOWy55ov",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Error analysis"
      ]
    },
    {
      "metadata": {
        "id": "Ob6kDbRUBJki",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 776
        },
        "outputId": "7274e673-4547-4ebc-9cc6-4bcb17596e78"
      },
      "cell_type": "code",
      "source": [
        "\n",
        "for i in [1,2,3]:\n",
        "  print ('\\n','#'*10,'VAL hope for modest results','verb',i,'#'*30)\n",
        "  show_sample('val',sample_id=i,teacher_forcing=False)      \n",
        "    \n",
        "\n",
        "for i in [0,1,2,3]:\n",
        "  print ('\\n','# TRAIN - expect good results '*30,'verb',i,'#'*30)\n",
        "  show_sample('train',sample_id=i,teacher_forcing=False)   \n",
        "    "
      ],
      "execution_count": 379,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            " ########## VAL hope for modest results verb 1 ##############################\n",
            "encoder_input  [t_bbe.csv]: \"Then David said, You are not to do this, my brothers, after what the Lord has given us, who has\n",
            "encoder_input  [t_ylt.csv]: \"And David saith, `Ye do not do so, my brethren, with that which Jehovah hath given to us, and He\n",
            "decoder sample [t_bbe.csv]: \"Then David said, You are not to do what my heart up on the day of my lord's ears, so that\n",
            "decoder sample [t_ylt.csv]: \"Then David said, You are not to do what my heart up on the day of my lord's ears, so that\n",
            "\n",
            " ########## VAL hope for modest results verb 2 ##############################\n",
            "encoder_input  [t_bbe.csv]: Who is going to give any attention to you in this <oov> for an equal part will be given to\n",
            "encoder_input  [t_ylt.csv]: \"and who doth hearken to you in this thing? for as the portion of him who was brought down into\n",
            "decoder sample [t_bbe.csv]: Who is not able to give honour to the children of Israel, but any other god for Israel: only in the\n",
            "decoder sample [t_ylt.csv]: Who is not able to give honour to the children of Israel, but any other god for Israel: only in the\n",
            "\n",
            " ########## VAL hope for modest results verb 3 ##############################\n",
            "encoder_input  [t_bbe.csv]: And so he made it a rule and an order for Israel from that day till <oov> <s> <s> <s>\n",
            "encoder_input  [t_ylt.csv]: \"And it cometh to pass from that day and forward, that he appointeth it for a statute and for an\n",
            "decoder sample [t_bbe.csv]: And so he made it a division between the Lord: let them be come back from my <oov> <s>\n",
            "decoder sample [t_ylt.csv]: And so he made it a division between the Lord: let them be come back from my <oov> <s>\n",
            "\n",
            " # TRAIN - expect good results # TRAIN - expect good results # TRAIN - expect good results # TRAIN - expect good results # TRAIN - expect good results # TRAIN - expect good results # TRAIN - expect good results # TRAIN - expect good results # TRAIN - expect good results # TRAIN - expect good results # TRAIN - expect good results # TRAIN - expect good results # TRAIN - expect good results # TRAIN - expect good results # TRAIN - expect good results # TRAIN - expect good results # TRAIN - expect good results # TRAIN - expect good results # TRAIN - expect good results # TRAIN - expect good results # TRAIN - expect good results # TRAIN - expect good results # TRAIN - expect good results # TRAIN - expect good results # TRAIN - expect good results # TRAIN - expect good results # TRAIN - expect good results # TRAIN - expect good results # TRAIN - expect good results # TRAIN - expect good results  verb 0 ##############################\n",
            "encoder_input  [t_bbe.csv]: At the first God made the heaven and the earth. <s> <s> <s> <s> <s> <s> <s> <s> <s> <s>\n",
            "encoder_input  [t_ylt.csv]: In the beginning of God's preparing the heavens and the earth -- <s> <s> <s> <s> <s> <s> <s> <s>\n",
            "decoder sample [t_bbe.csv]: At the first God made the heaven and the earth. <s>\n",
            "decoder sample [t_ylt.csv]: At the first God made the heaven and the earth. <s>\n",
            "\n",
            " # TRAIN - expect good results # TRAIN - expect good results # TRAIN - expect good results # TRAIN - expect good results # TRAIN - expect good results # TRAIN - expect good results # TRAIN - expect good results # TRAIN - expect good results # TRAIN - expect good results # TRAIN - expect good results # TRAIN - expect good results # TRAIN - expect good results # TRAIN - expect good results # TRAIN - expect good results # TRAIN - expect good results # TRAIN - expect good results # TRAIN - expect good results # TRAIN - expect good results # TRAIN - expect good results # TRAIN - expect good results # TRAIN - expect good results # TRAIN - expect good results # TRAIN - expect good results # TRAIN - expect good results # TRAIN - expect good results # TRAIN - expect good results # TRAIN - expect good results # TRAIN - expect good results # TRAIN - expect good results # TRAIN - expect good results  verb 1 ##############################\n",
            "encoder_input  [t_bbe.csv]: And the earth was waste and without form; and it was dark on the face of the <oov> and the\n",
            "encoder_input  [t_ylt.csv]: \"the earth hath <oov> waste and <oov> and darkness `is' on the face of the deep, and the Spirit of\n",
            "decoder sample [t_bbe.csv]: And the earth was waste and without form; and it was dark on the face of the <oov> and the land\n",
            "decoder sample [t_ylt.csv]: And the earth was waste and without form; and it was dark on the face of the <oov> and the land\n",
            "\n",
            " # TRAIN - expect good results # TRAIN - expect good results # TRAIN - expect good results # TRAIN - expect good results # TRAIN - expect good results # TRAIN - expect good results # TRAIN - expect good results # TRAIN - expect good results # TRAIN - expect good results # TRAIN - expect good results # TRAIN - expect good results # TRAIN - expect good results # TRAIN - expect good results # TRAIN - expect good results # TRAIN - expect good results # TRAIN - expect good results # TRAIN - expect good results # TRAIN - expect good results # TRAIN - expect good results # TRAIN - expect good results # TRAIN - expect good results # TRAIN - expect good results # TRAIN - expect good results # TRAIN - expect good results # TRAIN - expect good results # TRAIN - expect good results # TRAIN - expect good results # TRAIN - expect good results # TRAIN - expect good results # TRAIN - expect good results  verb 2 ##############################\n",
            "encoder_input  [t_bbe.csv]: \"And God said, Let there be light: and there was light.\" <s> <s> <s> <s> <s> <s> <s> <s> <s>\n",
            "encoder_input  [t_ylt.csv]: \"and God saith, `Let light <oov> and light is.\" <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s>\n",
            "decoder sample [t_bbe.csv]: \"And God said, Let there be light: and there was light.\" <s>\n",
            "decoder sample [t_ylt.csv]: \"And God said, Let there be light: and there was light.\" <s>\n",
            "\n",
            " # TRAIN - expect good results # TRAIN - expect good results # TRAIN - expect good results # TRAIN - expect good results # TRAIN - expect good results # TRAIN - expect good results # TRAIN - expect good results # TRAIN - expect good results # TRAIN - expect good results # TRAIN - expect good results # TRAIN - expect good results # TRAIN - expect good results # TRAIN - expect good results # TRAIN - expect good results # TRAIN - expect good results # TRAIN - expect good results # TRAIN - expect good results # TRAIN - expect good results # TRAIN - expect good results # TRAIN - expect good results # TRAIN - expect good results # TRAIN - expect good results # TRAIN - expect good results # TRAIN - expect good results # TRAIN - expect good results # TRAIN - expect good results # TRAIN - expect good results # TRAIN - expect good results # TRAIN - expect good results # TRAIN - expect good results  verb 3 ##############################\n",
            "encoder_input  [t_bbe.csv]: \"And God, looking on the light, saw that it was good: and God made a division between the light and\n",
            "encoder_input  [t_ylt.csv]: \"And God seeth the light that `it is' good, and God separateth between the light and the <oov> <s> <s>\n",
            "decoder sample [t_bbe.csv]: \"And God, looking on the light, saw that it was good: and God made a division between the light and the\n",
            "decoder sample [t_ylt.csv]: \"And God, looking on the light, saw that it was good: and God made a division between the light and the\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "TkFXxinr0fNo",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 627
        },
        "outputId": "b3ae0eec-c0e3-450d-f947-6aaed5fff1be"
      },
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "\n",
        "#a= model.predict([x_train[s:e], x_train_d[s:e]])\n",
        "#for i in range(dataset.MAX_SEQUENCE_LENGTH):\n",
        "#  best=np.argmax(a[0,i])\n",
        "#  print (i,best,dataset.index2word[best],a[0,i,best],a[0,i,0])\n",
        "\n",
        "#NEED TO FIX CODE HERE\n",
        "from keras.losses import categorical_crossentropy\n",
        "p=model.predict([x_val,x_val_d])\n",
        "scores=K.eval(K.sum(categorical_crossentropy(K.constant(p), K.constant(y_val) ),axis=1))\n",
        "worse_10 = scores.argsort()[::-1][:10]\n",
        "\n",
        "for i in range(len(worse_10)):\n",
        "  bad=worse_10[i]\n",
        "  print (i,'arg',bad,'score',scores[bad],show_sample('val',False,bad))\n",
        "  \n"
      ],
      "execution_count": 287,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-287-1e4d70dec522>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlosses\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcategorical_crossentropy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx_val\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mx_val_d\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mscores\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcategorical_crossentropy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconstant\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconstant\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_val\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mworse_10\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscores\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margsort\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36mconstant\u001b[0;34m(value, dtype, shape, name)\u001b[0m\n\u001b[1;32m    422\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    423\u001b[0m         \u001b[0mdtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfloatx\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 424\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconstant\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    425\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    426\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/constant_op.py\u001b[0m in \u001b[0;36mconstant\u001b[0;34m(value, dtype, shape, name, verify_shape)\u001b[0m\n\u001b[1;32m    194\u001b[0m   tensor_value.tensor.CopyFrom(\n\u001b[1;32m    195\u001b[0m       tensor_util.make_tensor_proto(\n\u001b[0;32m--> 196\u001b[0;31m           value, dtype=dtype, shape=shape, verify_shape=verify_shape))\n\u001b[0m\u001b[1;32m    197\u001b[0m   \u001b[0mdtype_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mattr_value_pb2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAttrValue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtensor_value\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m   const_tensor = g.create_op(\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/tensor_util.py\u001b[0m in \u001b[0;36mmake_tensor_proto\u001b[0;34m(values, dtype, shape, verify_shape)\u001b[0m\n\u001b[1;32m    422\u001b[0m   \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    423\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mvalues\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 424\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"None values not supported.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    425\u001b[0m     \u001b[0;31m# if dtype is provided, forces numpy array to be the type\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    426\u001b[0m     \u001b[0;31m# provided if possible.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: None values not supported."
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "8QaOXXjUAwVH",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Error of style disc."
      ]
    },
    {
      "metadata": {
        "id": "t_YnBS4fAr1M",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 298
        },
        "outputId": "13b22ceb-be41-422f-8589-ce8bc7cdfc26"
      },
      "cell_type": "code",
      "source": [
        "### Error of style discriminator\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "i=100\n",
        "\n",
        "#print (style_val[i:i+10])\n",
        "#print(d.predict(x_val[i:i+10]))#, style_train,\n",
        "\n",
        "p=1900 #switch point between style in db\n",
        "print('train',d.evaluate(x_train[i:i+p],style_train[i:i+p]))\n",
        "print('val',d.evaluate(x_val[i:i+p],style_val[i:i+p]))\n",
        "\n",
        "print_trainable(d)\n"
      ],
      "execution_count": 438,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1900/1900 [==============================] - 0s 161us/step\n",
            "train [1.1920930376163597e-07, 1.0]\n",
            "1900/1900 [==============================] - 0s 159us/step\n",
            "val [8.483208160400398, 0.47368421052631576]\n",
            "-0.0010554983 b 0.0\n",
            "Epoch 1/1\n",
            "100/100 [==============================] - 3s 27ms/step - loss: 8.2328 - acc: 0.4892 - val_loss: 8.8146 - val_acc: 0.4531\n",
            "-0.0010554983 b 0.0\n",
            "encoder_inputs <keras.engine.topology.InputLayer object at 0x7fd81e9e82e8> False\n",
            "embedding_9 <keras.layers.embeddings.Embedding object at 0x7fd81e9e8198> True\n",
            "cu_dnnlstm_17 <keras.layers.cudnn_recurrent.CuDNNLSTM object at 0x7fd81ecdca58> True\n",
            "concatenate_16 <keras.layers.merge.Concatenate object at 0x7fd81ea1d240> False\n",
            "dropout_29 <keras.layers.core.Dropout object at 0x7fd81ea1d1d0> False\n",
            "d_dense1 <keras.layers.core.Dense object at 0x7fd81ea1d390> False\n",
            "dropout_30 <keras.layers.core.Dropout object at 0x7fd81ea1d550> False\n",
            "d_dense_softmax <keras.layers.core.Dense object at 0x7fd81ea1d128> False\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "E2yLpQu4mvAS",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# FAQ and wierd exceptions\n",
        "\n",
        "* If you get exceptions related to cuda-lstm , inside the show_sample, but you actially not using it at all.  You will need to restart the notebook (thinking it's TF issue/bug)"
      ]
    },
    {
      "metadata": {
        "id": "y-9778X3mqOC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 160
        },
        "outputId": "68f1d5db-30e7-4006-f7dd-d6bbf20a2eac"
      },
      "cell_type": "code",
      "source": [
        "# If d not training (accuracy close to 0.5): check this. from som reason, it is not trainlable\n",
        "# solution is to recompile, and redefine train_d . TODO: find source of problem\n",
        "#  Discrepancy between trainable weights and collected trainable weights, did you set `model.trainable` without calling `model.compile` after ?\n",
        "#  'Discrepancy between trainable weights and collected trainable'\n",
        "def print_d_mean():\n",
        "  print(d.get_layer('d__dense_softmax').get_weights()[0].mean(),'b',d.get_layer('d__dense_softmax').get_weights()[1].mean())\n",
        "print_d_mean()\n",
        "\n",
        "#set_trainable(d,True)    \n",
        "#set_trainable(model,False) #setting it back(it's parts of d)\n",
        "#d.compile(optimizer='adam', loss='categorical_crossentropy',metrics=['accuracy'])\n",
        "\n",
        "\n",
        "#def train_d(steps,validation_steps=1):\n",
        "#set_trainable(d,True)  #only for warning\n",
        "#set_trainable(model,False)\n",
        "#d.trainable=True\n",
        "\n",
        "print_d_mean()\n",
        "\n",
        "d.fit_generator(gen(dataset.result.train,batch_size,'d'),\n",
        "                      250,\n",
        "                      validation_steps=50,\n",
        "                      validation_data=gen(dataset.result.val,batch_size,'d'),\n",
        "                      verbose=1,\n",
        "                      callbacks=[loss_history_d])\n",
        "\n",
        "print_d_mean()\n",
        "\n",
        "\n"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.017797627 b 0.0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/keras/engine/training.py:975: UserWarning: Discrepancy between trainable weights and collected trainable weights, did you set `model.trainable` without calling `model.compile` after ?\n",
            "  'Discrepancy between trainable weights and collected trainable'\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/1\n",
            "250/250 [==============================] - 10s 42ms/step - loss: 8.0752 - acc: 0.4990 - val_loss: 7.8576 - val_acc: 0.5125\n",
            "0.017797627 b 0.0\n",
            "0.017797627 b 0.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "d3dYES7JhysJ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}
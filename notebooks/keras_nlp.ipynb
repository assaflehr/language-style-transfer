{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "keras_nlp.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "[View in Colaboratory](https://colab.research.google.com/github/assaflehr/language-style-transfer/blob/master/notebooks/keras_nlp.ipynb)"
      ]
    },
    {
      "metadata": {
        "id": "vR_wGTR6szDb",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Keras accuracy/performace limitations\n",
        "\n",
        "### CuDNNLSTM vs LSTM \n",
        "The former trains very fast on GPU, but does not support the attributes: dropout,recurrent_dropout,which are the STOA regulaizers. This is cuda problem, and even native TF does not support it\n",
        "\n",
        "### Tip to self:\n",
        "* manually check loss value on one sample (predict vs gt). From doing this, I saw <s> was not given one-hot-value"
      ]
    },
    {
      "metadata": {
        "id": "OrKzdh71sBKm",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        ""
      ]
    },
    {
      "metadata": {
        "id": "UbJwZjyhsDvP",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# adaptation of: https://blog.keras.io/a-ten-minute-introduction-to-sequence-to-sequence-learning-in-keras.html\n",
        "# first Dataset class to load bible-data\n",
        "# then copy of the model, but working with words instead of chars"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "PcPSCDUrx3B8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 776
        },
        "outputId": "d5e3c20a-b9c6-43af-961b-6d52c8b306e8"
      },
      "cell_type": "code",
      "source": [
        "## NLP preprocessing for text\n",
        "# has few parts:\n",
        "# 1. load zip files and then use glob to filter part of them (data/*/*.txt)\n",
        "# 2. parse each row into (x,y) by passing a parser method. it can be simple as lambda line:line:x, or if you use tab delimited lambda line: line.split(',')[4]\n",
        "# 3. tokenize - split by spaces, but also by ., and be smart about it.  ('...' should be one token , \"ai'nt\" one token. then; should be two 'token' and ';')\n",
        "#    you should also build vocabulary, keep X words and throw away rare ones, they will be replaced by <oov> flag.\n",
        "# 4. transform text to sequences for the result. for words there are usually two different types: ['s>','hello', 'world'] -> [0,5,6] but there is also \n",
        "#     a one-hot-econding version where 5 is actaully a vector of size voc-length full of zeros, with 5th index==1.\n",
        "#    The one-hot ecoding is used as output for text-generation and has a HUGE MEMORY requirement.  100K sentences of size 20 words need 2M floats = 8MB\n",
        "#    But for the one-hot-encoding multiply this by vocab-size. for char-encoding it's ~30 , for good vocab of 10K words, we need 80GB(!)\n",
        "#    The simple, and only , way to solve this , is to never keep one-hot-encoding in memory, just use a generator to make it one-hot in runtime\n",
        "\n",
        "\n",
        "\n",
        "from __future__ import print_function\n",
        "\n",
        "import numpy as np\n",
        "import os\n",
        "import glob\n",
        "import csv, json\n",
        "from collections import namedtuple\n",
        "from zipfile import ZipFile\n",
        "from os.path import expanduser, exists\n",
        "from keras.utils.data_utils import get_file\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.utils.data_utils import get_file\n",
        "from keras.utils import to_categorical\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "\n",
        "TVT = namedtuple('TVT',['train','val','test'])\n",
        "\n",
        "class Dataset:\n",
        "  #Dataset for COPY encoder-decoder\n",
        "  # to David: generator x,y where x is batch,max-words of type integer. (            <s>   hello word)\n",
        "  #                               y is batch,max-words,one-hot-encoding (offset one: hello world <end>)\n",
        "  # tokenizer is currently very bad. replace it\n",
        "  # vocabulary (training-only) , don't use 666 , use large number (10K?)\n",
        "  \n",
        "  # Dataset2 for style, x is sentence + STYLE(one-hot-encoding of integer) , y is one hot encoding \n",
        "  \n",
        "  # Dataset3 for classifier: x is sentence + STYLE(one-hot-encoding of integer),  output: STYLE(one-hot-encoding of integer)\n",
        "  \n",
        "  \n",
        "  \n",
        "  def __init__(self,unique_name,url,extract,cache_dir,pattern,skip_first,row_parser,validation_pattern=0.1,test_pattern=0.1):\n",
        "    '''\n",
        "    unique_name will be used for the dataset source(or zip) file. \n",
        "    pattern need to include path inside zip (including zip root)\n",
        "    extract - is it zipped/tarred or not\n",
        "    cache_dir - under which the files be downloaded <cache_dir>/datasets/<unique_name>\n",
        "    pattern - glob will be done to choose only those files ,for example data*.txt. This should incldude both train and test\n",
        "    validation - subset glob pattern to use. If it's a float like 0.1, use it as split of one file\n",
        "    test - see above\n",
        "    '''\n",
        "    if not extract and pattern:\n",
        "      raise ValueError('pattern must be empty if extract=False chooses a subset of the files (data/*.txt). but you downloaded only one file')\n",
        "\n",
        "    if not os.path.exists(cache_dir):\n",
        "       os.makedirs(cache_dir)\n",
        "\n",
        "    fpath=get_file(unique_name, url,extract=True, cache_dir=cache_dir)\n",
        "    print ('fpath',fpath)\n",
        "    files = [fpath] if not pattern else glob.glob(f'{cache_dir}/datasets/{pattern}')\n",
        "\n",
        "    train,val,test=[],[],[]\n",
        "    for f in files:\n",
        "      lines = [row_parser(f,line.rstrip()) for line in open(f,encoding=\"latin-1\").readlines()] \n",
        "      lines = lines[1 if skip_first else 0:][:10000]\n",
        "      print ('HARDCODED MAX LINES = 10000')\n",
        "      \n",
        "      print (files,'#lines',len(lines),'first 3 lines')\n",
        "      print (lines[0],'\\n',lines[1],'\\n',lines[2])\n",
        "      \n",
        "      if isinstance(validation_pattern,float) and isinstance(test_pattern,float):\n",
        "        test_count = int(len(lines)*(1-validation_pattern))\n",
        "        val_count =  int(len(lines)*(1-test_pattern-validation_pattern))\n",
        "        print ('(val_count,test_count)',val_count,test_count)\n",
        "        train+= lines[:val_count]\n",
        "        val+=   lines[val_count:test_count]\n",
        "        test+=  lines[test_count:]\n",
        "        \n",
        "    self.tvt_lines = TVT(train, val, test)\n",
        "    print ('train:',len(self.tvt_lines.train),'val',len(self.tvt_lines.val),'test',len(self.tvt_lines.test))\n",
        "    self.parsed= self.tvt_lines\n",
        "  \n",
        "  \n",
        "  def fit(self):\n",
        "    \"\"\" the current implementation is quite bad, hello world! will be 2 tokens world! is the second. \n",
        "    \"\"\"\n",
        "    print ('limiting num_words in Tokenizer due to MEMORY BOUNDS')  #num_words =100*1000\n",
        "\n",
        "    \n",
        "    # I use here tokenizer only to count freq. of words, then manually choose most freq. and manually split\n",
        "    # this is bad. There are better ways to do it (probably library/code which do it in one line)\n",
        "    print ('\\nREPLACE ME . BAD TOKENIZER!!!')\n",
        "    self.tokenizer = Tokenizer(num_words=100000, filters='', lower=False, split=' ', char_level=False, oov_token='<oov>')\n",
        "    \n",
        "    # self.parsed.train is a list , each value is tuple text_string,file_name\n",
        "    self.tokenizer.fit_on_texts([x for x,style in self.parsed.train])\n",
        "    self.styles = set([style for x,style in self.parsed.train])\n",
        "    print ('styles',self.styles)\n",
        "    self.style2index = {style:i for i,style in enumerate(self.styles)}\n",
        "    self.index2style = {index:style for style,index in self.style2index.items() }\n",
        "    print (self.style2index,self.index2style)\n",
        "    \n",
        "    print ('\\n word_index',len(self.tokenizer.word_index),'<oov>',self.tokenizer.word_index['<oov>'])\n",
        "    print ('common',list(self.tokenizer.word_index.items())[:15])\n",
        "    print ('uncommon',list(self.tokenizer.word_index.items())[-15:])\n",
        "  \n",
        "    num_words= 2000\n",
        "    print ('keeping only ',num_words,'of',len(self.tokenizer.word_index))\n",
        "           \n",
        "           \n",
        "    word2index = dict(list(self.tokenizer.word_index.items())[:num_words-len(self.styles)-2])\n",
        "    word2index['<s>']=0  #keras tokenizer keeps 0 unused\n",
        "    for i,style in enumerate(self.styles):\n",
        "      word2index[style]=num_words-1-len(self.styles)+i  #if num_words=100 . [96,97,98] \n",
        "    word2index['<oov>']=num_words-1                   #<oov> is [99]\n",
        "    print ('word2index',len(word2index))\n",
        "    \n",
        "    #FOR NOW the start and end are both ZERO. maybe not good???\n",
        "    \n",
        "    num_encoder_tokens = num_decoder_tokens= num_words # len(self.tokenizer.word_index)\n",
        "    self.word2index = word2index\n",
        "    self.index2word = {index:word for (word,index) in self.word2index.items()}\n",
        "    self.MAX_SEQUENCE_LENGTH=10\n",
        "    \n",
        "    verbose=5\n",
        "    result = []\n",
        "    for rows in self.parsed:\n",
        "\n",
        "      encoder_input_data  = np.zeros( (len(rows), self.MAX_SEQUENCE_LENGTH),    dtype='float32')\n",
        "      decoder_input_data  = np.zeros( (len(rows), self.MAX_SEQUENCE_LENGTH),    dtype='float32') # shifted by 1\n",
        "      decoder_target_data = np.zeros((len(rows),  self.MAX_SEQUENCE_LENGTH, num_decoder_tokens),    dtype='float32')\n",
        "      style_data          = np.zeros((len(rows),  len(self.styles)),    dtype='float32') #one-hot\n",
        "      \n",
        "      #input to decoder   <s> hello world\n",
        "      #target of decoder: hello world <s>\n",
        "      \n",
        "      for i, (input_text,style) in enumerate(rows):\n",
        "        input_text = input_text.split(' ') #BUG: we need to use tokenizer here!!!!\n",
        "        #pad with end token  hello world <end> <end> <end>\n",
        "        end_token='<s>'\n",
        "        input_text += [end_token for _ in range(self.MAX_SEQUENCE_LENGTH - len(input_text)+1)]\n",
        "        if verbose:\n",
        "          print ('input_text',input_text)\n",
        "          verbose-=1\n",
        "        # out : hello  world  <end>  (MAX_SEQUENCE_LENGTH=2)  <-encoder_input+ decoder_output(but one-hot)\n",
        "        #\n",
        "        # in: : <s>   hello   world  <- decoder-input\n",
        "         \n",
        "        for t, word in enumerate(([style]+input_text)[:self.MAX_SEQUENCE_LENGTH]):\n",
        "            one_hot = word2index['<oov>'] if word not in word2index else word2index[word]\n",
        "            decoder_input_data[i, t ] = one_hot\n",
        "            \n",
        "        for t,word in enumerate(input_text[:self.MAX_SEQUENCE_LENGTH]):  #last must be <end>=<s> token\n",
        "            one_hot = word2index['<oov>'] if word not in word2index else word2index[word]\n",
        "            encoder_input_data[i,t]=one_hot\n",
        "            decoder_target_data[i, t, one_hot] = 1. \n",
        "            \n",
        "        style_data[i,self.style2index[style]]= 1\n",
        "        \n",
        "      print (decoder_target_data.sum(),len(rows)*self.MAX_SEQUENCE_LENGTH)\n",
        "      assert int(decoder_target_data.sum())==len(rows)*self.MAX_SEQUENCE_LENGTH #one-hot-encoding must always include one\n",
        "      \n",
        "      result.append( (encoder_input_data,decoder_input_data,decoder_target_data,style_data))\n",
        "\n",
        "    self.result= TVT(*result)\n",
        "\n",
        "  def one_x_as_text(self,x):\n",
        "    \"\"\" 1x20 or 20 input\"\"\"\n",
        "    if len(x.shape)==2: \n",
        "      assert x.shape[0] ==1  #can only work on batch of 1\n",
        "      x= x[0]\n",
        "    return [self.index2word[index] for index in x]\n",
        "\n",
        "  def one_y_as_text(self,y):\n",
        "    \"\"\" 1x20x2000 or 20x2000 input, in case of first will work on y[0]\"\"\"\n",
        "    if len(y.shape)==3: \n",
        "      assert y.shape[0] ==1  #can only work on batch of 1\n",
        "      y=y[0]\n",
        "      \n",
        "    best_token = np.argmax(y,1)\n",
        "    return [self.index2word[index] for index in best_token]\n",
        "\n",
        "  \n",
        "cache_dir='cache' \n",
        "#dataset('quora_dups','http://qim.ec.quoracdn.net/quora_duplicate_questions.tsv',False,cache_dir) \n",
        "#dataset('bible4','https://codeload.github.com/keithecarlson/Zero-Shot-Style-Transfer/zip/master',extract=True,cache_dir=cache_dir\n",
        "#       pattern=('Zero-Shot-Style-Transfer-master/Data/Bibles/ASV/*/*.txt','Zero-Shot-Style-Transfer-master/Data/Bibles/BBE/*/*.txt')\n",
        "\n",
        "row_parser= lambda file_name,line: (line.split(',')[4],file_name.split('/')[-1]) #map x to x,style_file\n",
        "dataset = Dataset('bible_csv','https://codeload.github.com/ashual/style-transfer/zip/master',extract=True,cache_dir=cache_dir,\n",
        "                  #,t_bbe,BBE,english,Bible in Basic English,,http://en.wikipedia.org/wiki/Bible_in_Basic_English,,Public Domain,\n",
        "                  #,t_dby,DARBY,english,Darby English Bible,,http://en.wikipedia.org/wiki/Darby_Bible,,Public Domain,\n",
        "                  #,t_kjv,KJV,english,King James Version,,http://en.wikipedia.org/wiki/King_James_Version,,Public Domain,\n",
        "                  pattern='style-transfer-master/datasets/bible-corpus/t_[kbd]*.csv',skip_first=True,row_parser=row_parser)    #kbd\n",
        "dataset.fit()        \n",
        "x_train, x_train_d, y_train,style_train = dataset.result.train\n",
        "x_val, x_val_d,y_val ,style_val= dataset.result.val\n",
        "x_test,x_test_d,y_test ,style_test= dataset.result.test\n",
        "\n",
        "print ('train',x_train.shape,x_train_d.shape,y_train.shape,style_train.shape)\n",
        "print('val',x_val.shape,y_val.shape)\n",
        "print ('train in MB x,y',x_train.nbytes/1e6,y_train.nbytes/1e6)\n"
      ],
      "execution_count": 170,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "fpath cache/datasets/bible_csv\n",
            "HARDCODED MAX LINES = 10000\n",
            "['cache/datasets/style-transfer-master/datasets/bible-corpus/t_kjv.csv', 'cache/datasets/style-transfer-master/datasets/bible-corpus/t_bbe.csv', 'cache/datasets/style-transfer-master/datasets/bible-corpus/t_dby.csv'] #lines 10000 first 3 lines\n",
            "('In the beginning God created the heaven and the earth.', 't_kjv.csv') \n",
            " ('\"And the earth was without form', 't_kjv.csv') \n",
            " ('\"And God said', 't_kjv.csv')\n",
            "(val_count,test_count) 8000 9000\n",
            "HARDCODED MAX LINES = 10000\n",
            "['cache/datasets/style-transfer-master/datasets/bible-corpus/t_kjv.csv', 'cache/datasets/style-transfer-master/datasets/bible-corpus/t_bbe.csv', 'cache/datasets/style-transfer-master/datasets/bible-corpus/t_dby.csv'] #lines 10000 first 3 lines\n",
            "('At the first God made the heaven and the earth.', 't_bbe.csv') \n",
            " ('And the earth was waste and without form; and it was dark on the face of the deep: and the Spirit of God was moving on the face of the waters.', 't_bbe.csv') \n",
            " ('\"And God said', 't_bbe.csv')\n",
            "(val_count,test_count) 8000 9000\n",
            "HARDCODED MAX LINES = 10000\n",
            "['cache/datasets/style-transfer-master/datasets/bible-corpus/t_kjv.csv', 'cache/datasets/style-transfer-master/datasets/bible-corpus/t_bbe.csv', 'cache/datasets/style-transfer-master/datasets/bible-corpus/t_dby.csv'] #lines 10000 first 3 lines\n",
            "('In the beginning God created the heavens and the earth.', 't_dby.csv') \n",
            " ('\"And the earth was waste and empty', 't_dby.csv') \n",
            " ('\"And God said', 't_dby.csv')\n",
            "(val_count,test_count) 8000 9000\n",
            "train: 24000 val 3000 test 3000\n",
            "limiting num_words in Tokenizer due to MEMORY BOUNDS\n",
            "\n",
            "REPLACE ME . BAD TOKENIZER!!!\n",
            "styles {'t_dby.csv', 't_bbe.csv', 't_kjv.csv'}\n",
            "{'t_dby.csv': 0, 't_bbe.csv': 1, 't_kjv.csv': 2} {0: 't_dby.csv', 1: 't_bbe.csv', 2: 't_kjv.csv'}\n",
            "\n",
            " word_index 9045 <oov> 9045\n",
            "common [('the', 1), ('of', 2), ('\"And', 3), ('to', 4), ('and', 5), ('said', 6), ('in', 7), ('he', 8), ('his', 9), ('a', 10), ('shall', 11), ('that', 12), ('for', 13), ('be', 14), ('they', 15)]\n",
            "uncommon [('Jizreel;', 9031), ('encamped;', 9032), ('anointed!', 9033), ('[my]', 9034), ('belongs', 9035), ('warfare', 9036), ('Aphek;', 9037), ('Jizreel.', 9038), ('thousands;', 9039), ('rearward', 9040), ('small:', 9041), ('fig-cake', 9042), ('raisin-cakes', 9043), ('missed', 9044), ('<oov>', 9045)]\n",
            "keeping only  2000 of 9045\n",
            "word2index 2000\n",
            "input_text ['In', 'the', 'beginning', 'God', 'created', 'the', 'heaven', 'and', 'the', 'earth.', '<s>']\n",
            "input_text ['\"And', 'the', 'earth', 'was', 'without', 'form', '<s>', '<s>', '<s>', '<s>', '<s>']\n",
            "input_text ['\"And', 'God', 'said', '<s>', '<s>', '<s>', '<s>', '<s>', '<s>', '<s>', '<s>']\n",
            "input_text ['\"And', 'God', 'saw', 'the', 'light', '<s>', '<s>', '<s>', '<s>', '<s>', '<s>']\n",
            "input_text ['\"And', 'God', 'called', 'the', 'light', 'Day', '<s>', '<s>', '<s>', '<s>', '<s>']\n",
            "240000.0 240000\n",
            "30000.0 30000\n",
            "30000.0 30000\n",
            "train (24000, 10) (24000, 10) (24000, 10, 2000) (24000, 3)\n",
            "val (3000, 10) (3000, 10, 2000)\n",
            "train in MB x,y 0.96 1920.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "9GT06VNk7vSN",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#!head -50 cache/datasets/style-transfer-master/datasets/bible-corpus/bible_version_key.csv\n",
        "#!ls -lh cache/datasets/style-transfer-master/datasets/bible-corpus\n",
        "#!head -5 cache/datasets/style-transfer-master/datasets/bible-corpus/t_kjv.csv\n",
        "#!head -5 cache/datasets/style-transfer-master/datasets/bible-corpus/t_bbe.csv\n",
        "#!head -5 cache/datasets/style-transfer-master/datasets/bible-corpus/t_dby.csv\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "S_v9vKqIcTn6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 246
        },
        "outputId": "8e473e6d-5ec1-4d98-d337-63c27f97a07b"
      },
      "cell_type": "code",
      "source": [
        "#show a sample of x_train\n",
        "for i in range(1150,1152):\n",
        "  print ('\\ntokens  :' , x_train_d[i])\n",
        "  print ('as words:',[dataset.index2word[index] for index in x_train_d[i] ])\n",
        "  print ('original:',dataset.parsed.train[i][0].split(' '))\n",
        "  print (dataset.one_x_as_text(x_train_d[i]))\n",
        "  print (dataset.one_y_as_text(y_train[i]))"
      ],
      "execution_count": 171,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "tokens  : [1998.    3.  115.   20.  167.  119.    4.  741.    5. 1999.]\n",
            "as words: ['t_kjv.csv', '\"And', 'Joseph', 'was', 'brought', 'down', 'to', 'Egypt;', 'and', '<oov>']\n",
            "original: ['\"And', 'Joseph', 'was', 'brought', 'down', 'to', 'Egypt;', 'and', 'Potiphar']\n",
            "['t_kjv.csv', '\"And', 'Joseph', 'was', 'brought', 'down', 'to', 'Egypt;', 'and', '<oov>']\n",
            "['\"And', 'Joseph', 'was', 'brought', 'down', 'to', 'Egypt;', 'and', '<oov>', '<s>']\n",
            "\n",
            "tokens  : [1.998e+03 3.000e+00 1.000e+00 3.700e+01 2.000e+01 2.400e+01 1.150e+02\n",
            " 0.000e+00 0.000e+00 0.000e+00]\n",
            "as words: ['t_kjv.csv', '\"And', 'the', 'LORD', 'was', 'with', 'Joseph', '<s>', '<s>', '<s>']\n",
            "original: ['\"And', 'the', 'LORD', 'was', 'with', 'Joseph']\n",
            "['t_kjv.csv', '\"And', 'the', 'LORD', 'was', 'with', 'Joseph', '<s>', '<s>', '<s>']\n",
            "['\"And', 'the', 'LORD', 'was', 'with', 'Joseph', '<s>', '<s>', '<s>', '<s>']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "BWVEcaeF6DBR",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Model defintion\n"
      ]
    },
    {
      "metadata": {
        "id": "kqkLdFGl0FMB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 791
        },
        "outputId": "93687ee4-fbaf-4586-f968-8f539263bebb"
      },
      "cell_type": "code",
      "source": [
        "from keras.models import Model\n",
        "from keras.layers import Input, LSTM, Dense, Embedding,CuDNNLSTM,Bidirectional,Concatenate\n",
        "\n",
        "# size of tokenizer indexes\n",
        "\n",
        "num_decoder_tokens = num_encoder_tokens = len(dataset.word2index) \n",
        "print (num_decoder_tokens)\n",
        "\n",
        "embedding_dim=300\n",
        "latent_dim = 256\n",
        "batch_size=64\n",
        "epochs=30\n",
        "\n",
        "bidi_encoder=False\n",
        "cuddlstm=True  #on bidi , diff in time is 20s vs 32 se\n",
        "\n",
        "# Define an input sequence and process it.\n",
        "encoder_inputs = Input(shape=(None,))\n",
        "\n",
        "shared_embedding = Embedding(num_encoder_tokens, \n",
        "                     embedding_dim, \n",
        "                     #weights=[word_embedding_matrix], if there is one\n",
        "                     #trainable=False,                            \n",
        "                     #input_length=MAX_SEQUENCE_LENGTH, if there is one\n",
        "                     )\n",
        "x = shared_embedding(encoder_inputs) \n",
        "if (cuddlstm):\n",
        "  encoder_lstm=CuDNNLSTM(latent_dim, return_state=True)\n",
        "else:\n",
        "  print ('using LSTM with dropout!')\n",
        "  #need to tune the dropout values (maybe fast.ai tips) , just invented those value\n",
        "  encoder_lstm=LSTM(latent_dim, return_state=True,dropout=0.3,recurrent_dropout=0.3)\n",
        "if (bidi_encoder):\n",
        "  encoder_lstm=Bidirectional(encoder_lstm,merge_mode='concat')\n",
        "  x, forward_h, forward_c, backward_h, backward_c = encoder_lstm(x) #output,h1,c1,h2,c2\n",
        "  state_h = Concatenate()([forward_h, backward_h])\n",
        "  state_c = Concatenate()([forward_c, backward_c])\n",
        "else:  \n",
        "  \n",
        "  x, state_h, state_c = encoder_lstm(x)\n",
        "\n",
        "encoder_states = [state_h, state_c]\n",
        "\n",
        "# Set up the decoder, using `encoder_states` as initial state.\n",
        "decoder_inputs = Input(shape=(None,))\n",
        "\n",
        "decoder_latent_dim = latent_dim*2 if bidi_encoder else latent_dim #bi-di pass merge of h1+h2, c1+c2\n",
        "if (cuddlstm):\n",
        "  decoder_lstm = CuDNNLSTM(decoder_latent_dim, return_sequences=True,return_state=True) #returned state used in inference\n",
        "else:\n",
        "  decoder_lstm = LSTM(decoder_latent_dim, return_sequences=True,return_state=True)\n",
        "decoder_outputs, _, _  = decoder_lstm(shared_embedding(decoder_inputs), initial_state=encoder_states)\n",
        "decoder_dense  = Dense(num_decoder_tokens, activation='softmax')\n",
        "decoder_outputs = decoder_dense(decoder_outputs)\n",
        "\n",
        "# Define the model that will turn\n",
        "# `encoder_input_data` & `decoder_input_data` into `decoder_target_data`\n",
        "model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
        "\n",
        "# Compile & run training\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy')  #30peocs loss: 0.2836 - val_loss: 0.4428\n",
        "print (model.summary())\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# now for the INFER models (re-arrangement of the prev one)\n",
        "# Remember that the training model varaibles were:\n",
        "#                                        decoder_outputs\n",
        "#encoder   --->    encoder_states  -->   decoder_lstm  \n",
        "#shared_embedding                        shared_embeddings  \n",
        "#encoder_inputs                          decdoer_inputs                  \n",
        "encoder_model = Model(encoder_inputs, encoder_states)\n",
        "\n",
        "decoder_states_inputs = [Input(shape=(decoder_latent_dim,)), Input(shape=(decoder_latent_dim,))]\n",
        "\n",
        "decoder_outputs, state_h, state_c = decoder_lstm(shared_embedding(decoder_inputs), initial_state=decoder_states_inputs)\n",
        "\n",
        "decoder_states = [state_h, state_c]\n",
        "decoder_outputs = decoder_dense(decoder_outputs)\n",
        "\n",
        "decoder_model = Model(\n",
        "    [decoder_inputs] + decoder_states_inputs,\n",
        "    [decoder_outputs] + decoder_states)\n",
        "\n",
        "\n",
        "\n",
        "#### Classifier model #############################\n",
        "# works on the embedding itself\n",
        "style_concat= Concatenate()(encoder_states)\n",
        "classifier_dense = Dense(len(dataset.style2index),activation='softmax')\n",
        "style_outputs = classifier_dense(style_concat)\n",
        "\n",
        "style_classifier_model = Model(encoder_inputs,style_outputs)\n",
        "# Compile & run training\n",
        "style_classifier_model.compile(optimizer='adam', loss='categorical_crossentropy')\n",
        "print (style_classifier_model.summary())\n",
        "\n",
        "print (x_train.shape,style_train.shape)\n",
        "\n",
        "######################################\n",
        "    \n"
      ],
      "execution_count": 172,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2000\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_46 (InputLayer)           (None, None)         0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_45 (InputLayer)           (None, None)         0                                            \n",
            "__________________________________________________________________________________________________\n",
            "embedding_12 (Embedding)        (None, None, 300)    600000      input_45[0][0]                   \n",
            "                                                                 input_46[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "cu_dnnlstm_9 (CuDNNLSTM)        [(None, 256), (None, 571392      embedding_12[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "cu_dnnlstm_10 (CuDNNLSTM)       [(None, None, 256),  571392      embedding_12[1][0]               \n",
            "                                                                 cu_dnnlstm_9[0][1]               \n",
            "                                                                 cu_dnnlstm_9[0][2]               \n",
            "__________________________________________________________________________________________________\n",
            "dense_30 (Dense)                (None, None, 2000)   514000      cu_dnnlstm_10[0][0]              \n",
            "==================================================================================================\n",
            "Total params: 2,256,784\n",
            "Trainable params: 2,256,784\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "None\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_45 (InputLayer)           (None, None)         0                                            \n",
            "__________________________________________________________________________________________________\n",
            "embedding_12 (Embedding)        (None, None, 300)    600000      input_45[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "cu_dnnlstm_9 (CuDNNLSTM)        [(None, 256), (None, 571392      embedding_12[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_34 (Concatenate)    (None, 512)          0           cu_dnnlstm_9[0][1]               \n",
            "                                                                 cu_dnnlstm_9[0][2]               \n",
            "__________________________________________________________________________________________________\n",
            "dense_31 (Dense)                (None, 3)            1539        concatenate_34[0][0]             \n",
            "==================================================================================================\n",
            "Total params: 1,172,931\n",
            "Trainable params: 1,172,931\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "None\n",
            "(24000, 10) (24000, 3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "8ceIddxbqWdD",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# classifier"
      ]
    },
    {
      "metadata": {
        "id": "2BIl7v9DnM5j",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "_ZC94QpK1bcw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 565
        },
        "outputId": "0d113f4d-9b55-40a4-d177-40e68b60f1c2"
      },
      "cell_type": "code",
      "source": [
        "max_decoder_seq_length=dataset.MAX_SEQUENCE_LENGTH\n",
        "\n",
        "\n",
        "def decode_sequence(input_seq,style,verbose=False):\n",
        "    assert input_seq.shape == (1, max_decoder_seq_length )\n",
        "    if verbose: print ('input_seq',input_seq.shape)\n",
        "    # Encode the input as state vectors.\n",
        "    states_value = encoder_model.predict(input_seq)\n",
        "    if verbose: print ('encoder result states_value','h',states_value[0].shape,states_value[0].mean(),'c',states_value[1].shape,states_value[1].mean())\n",
        "    \n",
        "    # Generate empty target sequence of length 1.\n",
        "    #                      batch,word-number value is token (0 /122)\n",
        "    target_seq = np.zeros((1, 1))\n",
        "    # Populate the first character of target sequence with the start character.\n",
        "    target_seq[0, 0] = dataset.word2index[style]\n",
        "\n",
        "    # Sampling loop for a batch of sequences\n",
        "    # (to simplify, here we assume a batch of size 1).\n",
        "    stop_condition = False\n",
        "    decoded_sentence = []\n",
        "    while not stop_condition:\n",
        "        #start with encoder-state then change to self state\n",
        "        output_tokens, h, c = decoder_model.predict( [target_seq] + states_value) \n",
        "        if verbose: print ('output_tokens',output_tokens.shape,output_tokens.mean(),'h',h.shape,'c',c.shape)\n",
        "\n",
        "        # Sample a token\n",
        "        sampled_token_index = np.argmax(output_tokens)# [0, -1, :])\n",
        "        if verbose: print ('sampled_token_index',sampled_token_index.shape,output_tokens.max(),sampled_token_index)\n",
        "        decoded_sentence.append(sampled_token_index)\n",
        "\n",
        "        # Exit condition: either hit max length\n",
        "        # or find stop character.\n",
        "        if (sampled_token_index == dataset.word2index['<s>'] or\n",
        "           len(decoded_sentence) > max_decoder_seq_length):\n",
        "          stop_condition = True\n",
        "\n",
        "        # Update the target sequence (of length 1).\n",
        "        target_seq = np.zeros((1, 1))\n",
        "        target_seq[0, 0] = sampled_token_index\n",
        "\n",
        "        # Update states\n",
        "        states_value = [h, c]\n",
        "\n",
        "    res= np.array(decoded_sentence) #[dataset.index2word[index] for index in decoded_sentence]\n",
        "    return res\n",
        "\n",
        "\n",
        "def show_sample(data_type='val',teacher_forcing=False,sample_ids=[1000],replace_style=None):\n",
        "  \"\"\" \n",
        "    teacher_forcing : should we simulate training and feed the input. default False, as for test\n",
        "  \"\"\"\n",
        "  for i in sample_ids:\n",
        "      data={'train': dataset.result.train,'val':dataset.result.val , 'test':dataset.result.test}\n",
        "      \n",
        "      \n",
        "      one_x= data[data_type][0][i:i+1]\n",
        "\n",
        "      one_x_d= data[data_type][1][i:i+1]\n",
        "      if replace_style:\n",
        "        style_as_text = replace_style\n",
        "        one_x_d= np.copy(one_x_d)\n",
        "        one_x_d[0,0]=dataset.word2index[replace_style]\n",
        "      else:\n",
        "        style_as_text = dataset.index2word[one_x_d[0][0]]\n",
        "        \n",
        "      one_y= data[data_type][2][i:i+1]\n",
        "      if one_x.shape[0]==0:\n",
        "        print ('sample out of range',data[data_type][0].shape)\n",
        "      print ('\\ngold  x: ',dataset.one_x_as_text(one_x))\n",
        "      print ('gold_styl:',dataset.one_x_as_text(one_x_d))\n",
        "      print ('gold y: ',dataset.one_y_as_text(one_y))\n",
        "      \n",
        "      \n",
        "      \n",
        "      \n",
        "      \n",
        "      if teacher_forcing:\n",
        "        p = model.predict([one_x,one_x_d])\n",
        "        print ('actual y:',dataset.one_y_as_text(p))   \n",
        "      else:\n",
        "        p = decode_sequence(one_x,style_as_text)\n",
        "        print ('actual y:',dataset.one_x_as_text(p))   \n",
        "\n",
        "\n",
        "show_sample(data_type='train',sample_ids=[0,8000,16000])#,replace_style='t_bbe.csv')    \n",
        "show_sample(data_type='train',sample_ids=[1,8001,16001])#,replace_style='t_bbe.csv')  \n",
        "    "
      ],
      "execution_count": 173,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "gold  x:  ['In', 'the', 'beginning', 'God', 'created', 'the', 'heaven', 'and', 'the', 'earth.']\n",
            "gold_styl: ['t_kjv.csv', 'In', 'the', 'beginning', 'God', 'created', 'the', 'heaven', 'and', 'the']\n",
            "gold y:  ['In', 'the', 'beginning', 'God', 'created', 'the', 'heaven', 'and', 'the', 'earth.']\n",
            "actual y: ['I', 'faith', 'servant', 'servant', 'months', 'establish', 'everything', 'him.', 'Beth-el', 'days;', 'night']\n",
            "\n",
            "gold  x:  ['At', 'the', 'first', 'God', 'made', 'the', 'heaven', 'and', 'the', 'earth.']\n",
            "gold_styl: ['t_bbe.csv', 'At', 'the', 'first', 'God', 'made', 'the', 'heaven', 'and', 'the']\n",
            "gold y:  ['At', 'the', 'first', 'God', 'made', 'the', 'heaven', 'and', 'the', 'earth.']\n",
            "actual y: ['Er', 'above', 'takes', 'base', 'part', 'hasted', 'hasted', 'made.', 'road', 'road', 'cup']\n",
            "\n",
            "gold  x:  ['In', 'the', 'beginning', 'God', 'created', 'the', 'heavens', 'and', 'the', 'earth.']\n",
            "gold_styl: ['t_dby.csv', 'In', 'the', 'beginning', 'God', 'created', 'the', 'heavens', 'and', 'the']\n",
            "gold y:  ['In', 'the', 'beginning', 'God', 'created', 'the', 'heavens', 'and', 'the', 'earth.']\n",
            "actual y: ['copper', 'help', 'life', 'Boaz', 'command', 'Gideon', \"man's\", 'hollow', 'bag', 'young', '\"After']\n",
            "\n",
            "gold  x:  ['\"And', 'the', 'earth', 'was', 'without', 'form', '<s>', '<s>', '<s>', '<s>']\n",
            "gold_styl: ['t_kjv.csv', '\"And', 'the', 'earth', 'was', 'without', 'form', '<s>', '<s>', '<s>']\n",
            "gold y:  ['\"And', 'the', 'earth', 'was', 'without', 'form', '<s>', '<s>', '<s>', '<s>']\n",
            "actual y: ['keep', 'ways', 'ways', 'until', 'myself', 'thing', 'assembly', 'able', 'Adam', '\"the', \"Jehovah's\"]\n",
            "\n",
            "gold  x:  ['And', 'the', 'earth', 'was', 'waste', 'and', 'without', '<oov>', 'and', 'it']\n",
            "gold_styl: ['t_bbe.csv', 'And', 'the', 'earth', 'was', 'waste', 'and', 'without', '<oov>', 'and']\n",
            "gold y:  ['And', 'the', 'earth', 'was', 'waste', 'and', 'without', '<oov>', 'and', 'it']\n",
            "actual y: ['ought', 'putting', 'window', 'get', 'get', 'many', '\"Say', 'Dinah', 'brethren', 'meeting:', 'brethren']\n",
            "\n",
            "gold  x:  ['\"And', 'the', 'earth', 'was', 'waste', 'and', '<oov>', '<s>', '<s>', '<s>']\n",
            "gold_styl: ['t_dby.csv', '\"And', 'the', 'earth', 'was', 'waste', 'and', '<oov>', '<s>', '<s>']\n",
            "gold y:  ['\"And', 'the', 'earth', 'was', 'waste', 'and', '<oov>', '<s>', '<s>', '<s>']\n",
            "actual y: ['Thou', 'Thou', 'leprosy', 'ye', 'ye', 'me', 'brothers', 'people.', 'reward', 'altar.', 'wind']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "9s0-8EJi6AG1",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# TRAINING"
      ]
    },
    {
      "metadata": {
        "id": "0_0G8_Dr2bMM",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import keras\n",
        "from keras.callbacks import ReduceLROnPlateau\n",
        "class LossHistory(keras.callbacks.Callback):\n",
        "    def __init__(self):\n",
        "      self.losses = {'loss':[],'val_loss':[]}\n",
        "      \n",
        "    #def on_train_begin(self, logs={}):\n",
        "    #  pass  \n",
        "    \n",
        "    def on_epoch_end(self, batch, logs={}):\n",
        "      for loss in ['loss','val_loss']:\n",
        "        self.losses[loss].append(logs.get(loss))\n",
        "        \n",
        "        \n",
        "loss_history = LossHistory()\n",
        "loss_history_adv = LossHistory()\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Sm05AY862pem",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        },
        "outputId": "d5407509-d044-47dc-d95e-4ad9ee5a0aec"
      },
      "cell_type": "code",
      "source": [
        "from keras import backend as K\n",
        "epochs = 1\n",
        "for i in range(5):\n",
        "  print ('lr',K.eval(model.optimizer.lr))\n",
        "  \n",
        "  model.fit([x_train, x_train_d], y_train,\n",
        "            batch_size=batch_size,\n",
        "            epochs=epochs,\n",
        "            validation_data=([x_val, x_val_d], y_val),callbacks=[loss_history,\n",
        "                                                                ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=2, verbose=1, mode='auto', min_delta=0.0001, cooldown=3)])\n",
        "  \n",
        "  style_classifier_model.fit(x_train, style_train,\n",
        "            batch_size=batch_size,\n",
        "            epochs=epochs,\n",
        "            #validation_data=(x_val,style_val),\n",
        "            callbacks=[loss_history_adv,\n",
        "            ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=2, verbose=1, mode='auto', min_delta=0.0001, cooldown=3)])\n",
        "\n",
        "\n",
        "  \n",
        "  #show_sample('train',sample_ids=[5,8005,16005])      \n",
        "  #show_sample('val',False) "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "lr 0.001\n",
            "Train on 24000 samples, validate on 3000 samples\n",
            "Epoch 1/1\n",
            " 7552/24000 [========>.....................] - ETA: 35s - loss: 4.4097"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "R_OBmX182djj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1696
        },
        "outputId": "59439476-5c3a-48be-96eb-1a590b6f9bc9"
      },
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "for i in range(5):\n",
        "  show_sample('train',sample_ids=[i,8000+i,16000+i],replace_style='t_dby.csv') \n",
        "  \n",
        "# summarize history for loss\n",
        "plt.plot(loss_history.losses['loss'][3:])\n",
        "plt.plot(loss_history.losses['val_loss'][3:])\n",
        "plt.title('model loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'val'], loc='upper left')\n",
        "plt.show()\n"
      ],
      "execution_count": 124,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "gold  x:  ['In', '<oov>', 'beginning', 'God', 'created', '<oov>', 'heaven', 'and', '<oov>', 'earth.']\n",
            "gold_styl: ['t_dby.csv', 'In', '<oov>', 'beginning', 'God', 'created', '<oov>', 'heaven', 'and', '<oov>']\n",
            "gold y:  ['In', '<oov>', 'beginning', 'God', 'created', '<oov>', 'heaven', 'and', '<oov>', 'earth.']\n",
            "actual y: ['In', '<oov>', 'beginning', 'God', 'created', '<oov>', 'heaven', 'and', '<oov>', 'earth.', 'and']\n",
            "\n",
            "gold  x:  ['At', '<oov>', 'first', 'God', 'made', '<oov>', 'heaven', 'and', '<oov>', 'earth.']\n",
            "gold_styl: ['t_dby.csv', 'At', '<oov>', 'first', 'God', 'made', '<oov>', 'heaven', 'and', '<oov>']\n",
            "gold y:  ['At', '<oov>', 'first', 'God', 'made', '<oov>', 'heaven', 'and', '<oov>', 'earth.']\n",
            "actual y: ['At', '<oov>', 'first', 'God', 'made', '<oov>', 'heaven', 'and', '<oov>', 'earth.', 'and']\n",
            "\n",
            "gold  x:  ['In', '<oov>', 'beginning', 'God', 'created', '<oov>', 'heavens', 'and', '<oov>', 'earth.']\n",
            "gold_styl: ['t_dby.csv', 'In', '<oov>', 'beginning', 'God', 'created', '<oov>', 'heavens', 'and', '<oov>']\n",
            "gold y:  ['In', '<oov>', 'beginning', 'God', 'created', '<oov>', 'heavens', 'and', '<oov>', 'earth.']\n",
            "actual y: ['In', '<oov>', 'beginning', 'God', 'created', '<oov>', 'heavens', 'and', '<oov>', 'earth.', 'widow']\n",
            "\n",
            "gold  x:  ['\"And', '<oov>', 'earth', 'was', 'without', 'form', '<s>', '<s>', '<s>', '<s>']\n",
            "gold_styl: ['t_dby.csv', '\"And', '<oov>', 'earth', 'was', 'without', 'form', '<s>', '<s>', '<s>']\n",
            "gold y:  ['\"And', '<oov>', 'earth', 'was', 'without', 'form', '<s>', '<s>', '<s>', '<s>']\n",
            "actual y: ['\"And', '<oov>', 'earth', 'was', 'without', 'form', '<s>']\n",
            "\n",
            "gold  x:  ['And', '<oov>', 'earth', 'was', 'waste', 'and', 'without', '<oov>', 'and', 'it']\n",
            "gold_styl: ['t_dby.csv', 'And', '<oov>', 'earth', 'was', 'waste', 'and', 'without', '<oov>', 'and']\n",
            "gold y:  ['And', '<oov>', 'earth', 'was', 'waste', 'and', 'without', '<oov>', 'and', 'it']\n",
            "actual y: ['And', '<oov>', 'earth', 'was', 'waste', 'and', 'without', '<oov>', 'and', 'it', '<s>']\n",
            "\n",
            "gold  x:  ['\"And', '<oov>', 'earth', 'was', 'waste', 'and', '<oov>', '<s>', '<s>', '<s>']\n",
            "gold_styl: ['t_dby.csv', '\"And', '<oov>', 'earth', 'was', 'waste', 'and', '<oov>', '<s>', '<s>']\n",
            "gold y:  ['\"And', '<oov>', 'earth', 'was', 'waste', 'and', '<oov>', '<s>', '<s>', '<s>']\n",
            "actual y: ['\"And', '<oov>', 'earth', 'was', 'waste', 'and', '<oov>', '<s>']\n",
            "\n",
            "gold  x:  ['\"And', 'God', 'said', '<s>', '<s>', '<s>', '<s>', '<s>', '<s>', '<s>']\n",
            "gold_styl: ['t_dby.csv', '\"And', 'God', 'said', '<s>', '<s>', '<s>', '<s>', '<s>', '<s>']\n",
            "gold y:  ['\"And', 'God', 'said', '<s>', '<s>', '<s>', '<s>', '<s>', '<s>', '<s>']\n",
            "actual y: ['\"And', 'God', 'said', '<s>']\n",
            "\n",
            "gold  x:  ['\"And', 'God', 'said', '<s>', '<s>', '<s>', '<s>', '<s>', '<s>', '<s>']\n",
            "gold_styl: ['t_dby.csv', '\"And', 'God', 'said', '<s>', '<s>', '<s>', '<s>', '<s>', '<s>']\n",
            "gold y:  ['\"And', 'God', 'said', '<s>', '<s>', '<s>', '<s>', '<s>', '<s>', '<s>']\n",
            "actual y: ['\"And', 'God', 'said', '<s>']\n",
            "\n",
            "gold  x:  ['\"And', 'God', 'said', '<s>', '<s>', '<s>', '<s>', '<s>', '<s>', '<s>']\n",
            "gold_styl: ['t_dby.csv', '\"And', 'God', 'said', '<s>', '<s>', '<s>', '<s>', '<s>', '<s>']\n",
            "gold y:  ['\"And', 'God', 'said', '<s>', '<s>', '<s>', '<s>', '<s>', '<s>', '<s>']\n",
            "actual y: ['\"And', 'God', 'said', '<s>']\n",
            "\n",
            "gold  x:  ['\"And', 'God', 'saw', '<oov>', 'light', '<s>', '<s>', '<s>', '<s>', '<s>']\n",
            "gold_styl: ['t_dby.csv', '\"And', 'God', 'saw', '<oov>', 'light', '<s>', '<s>', '<s>', '<s>']\n",
            "gold y:  ['\"And', 'God', 'saw', '<oov>', 'light', '<s>', '<s>', '<s>', '<s>', '<s>']\n",
            "actual y: ['\"And', 'God', 'saw', '<oov>', 'light', '<s>']\n",
            "\n",
            "gold  x:  ['\"And', 'God', '<s>', '<s>', '<s>', '<s>', '<s>', '<s>', '<s>', '<s>']\n",
            "gold_styl: ['t_dby.csv', '\"And', 'God', '<s>', '<s>', '<s>', '<s>', '<s>', '<s>', '<s>']\n",
            "gold y:  ['\"And', 'God', '<s>', '<s>', '<s>', '<s>', '<s>', '<s>', '<s>', '<s>']\n",
            "actual y: ['\"And', 'God', '<s>']\n",
            "\n",
            "gold  x:  ['And', 'God', 'saw', '<oov>', 'light', 'that', 'it', 'was', '<oov>', 'and']\n",
            "gold_styl: ['t_dby.csv', 'And', 'God', 'saw', '<oov>', 'light', 'that', 'it', 'was', '<oov>']\n",
            "gold y:  ['And', 'God', 'saw', '<oov>', 'light', 'that', 'it', 'was', '<oov>', 'and']\n",
            "actual y: ['And', 'God', 'saw', '<oov>', 'light', 'that', 'it', 'was', '<oov>', 'and', 'salt']\n",
            "\n",
            "gold  x:  ['\"And', 'God', 'called', '<oov>', 'light', '<oov>', '<s>', '<s>', '<s>', '<s>']\n",
            "gold_styl: ['t_dby.csv', '\"And', 'God', 'called', '<oov>', 'light', '<oov>', '<s>', '<s>', '<s>']\n",
            "gold y:  ['\"And', 'God', 'called', '<oov>', 'light', '<oov>', '<s>', '<s>', '<s>', '<s>']\n",
            "actual y: ['\"And', 'God', 'called', '<oov>', 'light', '<oov>', '<s>']\n",
            "\n",
            "gold  x:  ['<oov>', '<oov>', 'light', '<s>', '<s>', '<s>', '<s>', '<s>', '<s>', '<s>']\n",
            "gold_styl: ['t_dby.csv', '<oov>', '<oov>', 'light', '<s>', '<s>', '<s>', '<s>', '<s>', '<s>']\n",
            "gold y:  ['<oov>', '<oov>', 'light', '<s>', '<s>', '<s>', '<s>', '<s>', '<s>', '<s>']\n",
            "actual y: ['<oov>', '<oov>', 'light', '<s>']\n",
            "\n",
            "gold  x:  ['\"And', 'God', 'called', '<oov>', 'light', '<oov>', '<s>', '<s>', '<s>', '<s>']\n",
            "gold_styl: ['t_dby.csv', '\"And', 'God', 'called', '<oov>', 'light', '<oov>', '<s>', '<s>', '<s>']\n",
            "gold y:  ['\"And', 'God', 'called', '<oov>', 'light', '<oov>', '<s>', '<s>', '<s>', '<s>']\n",
            "actual y: ['\"And', 'God', 'called', '<oov>', 'light', '<oov>', '<s>']\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAe8AAAFnCAYAAACPasF4AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<matplotlib.figure.Figure at 0x7f395ef0fa58>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "I2NGxSQb2dxD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 210
        },
        "outputId": "d43bf76b-4ec3-4261-e96e-012ce2fc21ff"
      },
      "cell_type": "code",
      "source": [
        "#print ('eval on train:',model.evaluate([x_train, x_train_d], y_train))\n",
        "#print ('eval on val:',model.evaluate([x_val, x_val_d], y_val))\n",
        "\n",
        "s=20\n",
        "e=s+1\n",
        "print ('score',model.evaluate([x_train[s:e], x_train_d[s:e]], y_train[s:e],batch_size=batch_size,verbose=0))\n",
        "\n",
        "show_sample('train',False,s) \n",
        "\n",
        "\n",
        "print ('\\n COMPARE TO VAL:\\n')\n",
        "print('score',model.evaluate([x_val[s:e], x_val_d[s:e]], y_val[s:e],batch_size=batch_size,verbose=0))\n",
        "show_sample('val',False,s) \n"
      ],
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "score 0.2516933083534241\n",
            "\n",
            "gold  x:  ['\"And', 'God', 'created', 'great', '<oov>', '<s>', '<s>', '<s>', '<s>', '<s>']\n",
            "actual y: ['\"And', 'God', 'created', 'great', '<oov>', '<oov>', '<s>']\n",
            "\n",
            " COMPARE TO VAL:\n",
            "\n",
            "score 1.7120778560638428\n",
            "\n",
            "gold  x:  ['And', 'when', '<oov>', 'inhabitants', 'of', '<oov>', 'heard', 'of', 'that', 'which']\n",
            "actual y: ['when', 'all', '<oov>', 'chief', '<oov>', 'which', 'Moses', 'of', '<oov>', 'hand', 'of']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "XvIkFOWy55ov",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Error analysis"
      ]
    },
    {
      "metadata": {
        "id": "TkFXxinr0fNo",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 721
        },
        "outputId": "abd524fc-2806-4705-c157-275c5c3ee549"
      },
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "#a= model.predict([x_train[s:e], x_train_d[s:e]])\n",
        "#for i in range(dataset.MAX_SEQUENCE_LENGTH):\n",
        "#  best=np.argmax(a[0,i])\n",
        "#  print (i,best,dataset.index2word[best],a[0,i,best],a[0,i,0])\n",
        "\n",
        "from keras.losses import categorical_crossentropy\n",
        "p=model.predict([x_val,x_val_d])\n",
        "scores=K.eval(K.sum(categorical_crossentropy(K.constant(p), K.constant(y_val) ),axis=1))\n",
        "worse_10 = scores.argsort()[::-1][:10]\n",
        "\n",
        "for i in range(len(worse_10)):\n",
        "  bad=worse_10[i]\n",
        "  print (i,'arg',bad,'score',scores[bad],show_sample('val',False,bad))\n",
        "  \n"
      ],
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "gold  x:  ['In', 'Hebron', 'he', 'reigned', 'over', 'Judah', 'seven', 'years', 'and', 'six']\n",
            "actual y: ['was', 'forty', 'years', 'therefore', 'and', 'Nahor', 'lived', '<oov>', 'edge', 'of', '<oov>']\n",
            "0 arg 2137 score 143.88416 None\n",
            "\n",
            "gold  x:  ['In', 'Hebron', 'he', 'reigned', 'over', 'Judah', 'seven', 'years', 'and', 'six']\n",
            "actual y: ['was', 'forty', 'years', 'therefore', 'and', 'Nahor', 'lived', '<oov>', 'edge', 'of', '<oov>']\n",
            "1 arg 137 score 143.2021 None\n",
            "\n",
            "gold  x:  ['For', 'all', 'my', \"father's\", 'family', 'were', 'only', 'dead', 'men', 'before']\n",
            "actual y: ['that', 'may', 'be', '<oov>', 'right', 'offering', 'and', 'give', 'his', 'heart', '<oov>']\n",
            "2 arg 1539 score 131.63153 None\n",
            "\n",
            "gold  x:  ['David', 'was', 'king', 'over', 'Israel', 'for', 'forty', 'years:', 'for', 'seven']\n",
            "actual y: ['was', '\"And', 'come', 'up', 'out', '<oov>', 'out', 'of', 'which', 'he', 'said;']\n",
            "3 arg 1781 score 125.8354 None\n",
            "\n",
            "gold  x:  ['\"And', 'more', 'than', '<oov>', 'where', 'is', 'my', 'place', 'as', 'a']\n",
            "actual y: ['\"And', 'as', '<oov>', 'Lord', 'was', 'living', 'in', '<oov>', 'ox', 'or', 'who']\n",
            "4 arg 1445 score 125.44391 None\n",
            "\n",
            "gold  x:  ['For', 'all', 'my', \"father's\", 'house', 'were', 'but', 'dead', 'men', 'before']\n",
            "actual y: ['that', 'day', 'thy', 'brothers', 'will', 'keep', 'his', 'eyes', 'in', 'heaven', 'and']\n",
            "5 arg 2539 score 125.171326 None\n",
            "\n",
            "gold  x:  ['\"Give', 'therefore', 'thy', 'servant', 'an', '<oov>', 'heart', 'to', 'judge', 'thy']\n",
            "actual y: ['now', 'didst', 'have', '<oov>', 'unto', 'Abraham', 'from', 'his', '<oov>', 'tree', 'your']\n",
            "6 arg 825 score 124.08656 None\n",
            "\n",
            "gold  x:  ['He', 'makes', 'me', 'free', 'from', 'my', '<oov>', 'I', 'am', 'lifted']\n",
            "actual y: ['whose', 'heart', 'be', 'turned', 'to', 'his', '<oov>', 'so', 'before', 'you', 'for']\n",
            "7 arg 1651 score 123.036385 None\n",
            "\n",
            "gold  x:  ['Then', 'made', 'he', 'ten', '<oov>', 'of', '<oov>', 'one', 'laver', '<oov>']\n",
            "actual y: ['he', 'made', 'fifty', 'oblation', 'of', '<oov>', 'two', '<oov>', 'cloud', 'shall', '<oov>']\n",
            "8 arg 972 score 121.723404 None\n",
            "\n",
            "gold  x:  ['For', 'all', 'of', 'my', \"father's\", 'house', 'were', 'but', 'dead', 'men']\n",
            "actual y: ['in', 'all', 'that', '<oov>', 'Lord', 'will', 'be', 'a', 'people', '<oov>', 'from']\n",
            "9 arg 539 score 121.56691 None\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}